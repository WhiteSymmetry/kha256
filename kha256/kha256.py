"""
================================================================
KEÃ‡ECÄ° HASH ALGORITHM (KEÃ‡ECÄ° HASH ALGORÄ°TMASI), KHA-256
KeÃ§eci Hash Algorithm (KeÃ§eci Hash AlgoritmasÄ±), KHA-256
================================================================
Performanstan fedakarlÄ±k edilerek gÃ¼venlik maksimize edilmiÅŸ versiyondur.
It is the version with security maximized at the sacrifice of performance.
================================================================
# pip install -U bcrypt blake3 pycryptodome xxhash argon2-cffi pandas numpy cryptography
# conda install -c conda-forge bcrypt blake3 pycryptodome xxhash argon2-cffi pandas numpy cryptography
# pip install xxhash: # xxh32 collision riski yÃ¼ksek (64-bit iÃ§in ~yÃ¼z milyonlarda %0.03)
"""

from __future__ import annotations
import argon2 
import bcrypt
from blake3 import blake3
from Crypto.Cipher import ChaCha20
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from cryptography.hazmat.primitives.kdf.hkdf import HKDF
from cryptography.hazmat.primitives import hashes
from dataclasses import dataclass
from decimal import getcontext
from functools import lru_cache
import hashlib
from hashlib import scrypt
import hmac
import json
import logging
import mmap
import os
import platform
import random
import re
import secrets
import statistics
import struct
import sys
import time
import uuid
from typing import Any, ClassVar, Dict, List, Optional, Tuple, Union, cast, Callable
import xxhash  # pip install xxhash: # xxh32 collision riski yÃ¼ksek (64-bit iÃ§in ~yÃ¼z milyonlarda %0.03)

import numpy as np
import pandas as pd


# Logging configuration
logging.basicConfig(
    level=logging.WARNING, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("KHA-256")

# Version information
__version__ = "0.1.5"  # Updated
__author__ = "Mehmet KeÃ§eci"
__license__ = "AGPL-3.0 license"
__status__ = "Pre-Production"

req_kececinumbers = "0.9.2"

# KeÃ§eciNumbers check - made API compatible
KHA_AVAILABLE = True
WORKING_TYPES = []
TYPE_NAMES = {}


# Define type constants as fallback values
TYPE_POSITIVE_REAL = 1
TYPE_NEGATIVE_REAL = 2
TYPE_COMPLEX = 3
TYPE_FLOAT = 4
TYPE_RATIONAL = 5
TYPE_QUATERNION = 6
TYPE_NEUTROSOPHIC = 7
TYPE_NEUTROSOPHIC_COMPLEX = 8
TYPE_HYPERREAL = 9
TYPE_BICOMPLEX = 10
TYPE_NEUTROSOPHIC_BICOMPLEX = 11
TYPE_OCTONION = 12
TYPE_SEDENION = 13
TYPE_CLIFFORD = 14
TYPE_DUAL = 15
TYPE_SPLIT_COMPLEX = 16
TYPE_PATHION = 17
TYPE_CHINGON = 18
TYPE_ROUTON = 19
TYPE_VOUDON = 20
TYPE_SUPERREAL = 21
TYPE_TERNARY = 22

# Try to import kececinumbers
try:
    import kececinumbers as kn

    # Override with actual values from kececinumbers if available
    if hasattr(kn, "TYPE_POSITIVE_REAL"):
        TYPE_POSITIVE_REAL = kn.TYPE_POSITIVE_REAL
        TYPE_NEGATIVE_REAL = kn.TYPE_NEGATIVE_REAL
        TYPE_COMPLEX = kn.TYPE_COMPLEX
        TYPE_FLOAT = kn.TYPE_FLOAT
        TYPE_RATIONAL = kn.TYPE_RATIONAL
        TYPE_QUATERNION = kn.TYPE_QUATERNION
        TYPE_NEUTROSOPHIC = kn.TYPE_NEUTROSOPHIC
        TYPE_NEUTROSOPHIC_COMPLEX = kn.TYPE_NEUTROSOPHIC_COMPLEX
        TYPE_HYPERREAL = kn.TYPE_HYPERREAL
        TYPE_BICOMPLEX = kn.TYPE_BICOMPLEX
        TYPE_OCTONION = kn.TYPE_OCTONION
        TYPE_SEDENION = kn.TYPE_SEDENION
        TYPE_CLIFFORD = kn.TYPE_CLIFFORD
        TYPE_DUAL = kn.TYPE_DUAL
        TYPE_SPLIT_COMPLEX = kn.TYPE_SPLIT_COMPLEX
        TYPE_PATHION = kn.TYPE_PATHION
        TYPE_CHINGON = kn.TYPE_CHINGON
        TYPE_ROUTON = kn.TYPE_ROUTON
        TYPE_VOUDON = kn.TYPE_VOUDON
        TYPE_SUPERREAL = kn.TYPE_SUPERREAL
        TYPE_TERNARY = kn.TYPE_TERNARY
        TYPE_NEUTROSOPHIC_BICOMPLEX = kn.TYPE_NEUTROSOPHIC_BICOMPLEX

    # Known working types
    WORKING_TYPES = [
        TYPE_POSITIVE_REAL,
        TYPE_NEGATIVE_REAL,
        TYPE_COMPLEX,
        TYPE_FLOAT,
        TYPE_RATIONAL,
        TYPE_QUATERNION,
        TYPE_NEUTROSOPHIC,
        TYPE_NEUTROSOPHIC_COMPLEX,
        TYPE_BICOMPLEX,
        TYPE_OCTONION,
        TYPE_DUAL,
        TYPE_SPLIT_COMPLEX,
        TYPE_HYPERREAL,
        TYPE_NEUTROSOPHIC_BICOMPLEX,
        TYPE_SEDENION,
        TYPE_CLIFFORD,
        TYPE_PATHION,
        TYPE_CHINGON,
        TYPE_ROUTON,
        TYPE_VOUDON,
        TYPE_SUPERREAL,
        TYPE_TERNARY,
    ]

    # Type names
    TYPE_NAMES = {
        TYPE_POSITIVE_REAL: "Positive Real",
        TYPE_NEGATIVE_REAL: "Negative Real",
        TYPE_COMPLEX: "Complex",
        TYPE_FLOAT: "Float",
        TYPE_RATIONAL: "Rational",
        TYPE_QUATERNION: "Quaternion",
        TYPE_NEUTROSOPHIC: "Neutrosophic",
        TYPE_NEUTROSOPHIC_COMPLEX: "Neutrosophic Complex",
        TYPE_HYPERREAL: "Hyperreal",
        TYPE_BICOMPLEX: "Bicomplex",
        TYPE_NEUTROSOPHIC_BICOMPLEX: "Neutrosophic Bicomplex",
        TYPE_OCTONION: "Octonion",
        TYPE_SEDENION: "Sedenion",
        TYPE_CLIFFORD: "Clifford",
        TYPE_DUAL: "Dual",
        TYPE_SPLIT_COMPLEX: "Split Complex",
        TYPE_PATHION: "Pathion",
        TYPE_CHINGON: "Chingon",
        TYPE_ROUTON: "Routon",
        TYPE_VOUDON: "Voudon",
        TYPE_SUPERREAL: "Superreal",
        TYPE_TERNARY: "Ternary",
    }

    # Check version
    try:
        if hasattr(kn, "__version__"):
            kn_version = kn.__version__
            logger.info(f"kececinumbers v{kn_version} loaded successfully")
        else:
            logger.info("kececinumbers loaded (version unknown)")

        # Mark as available
        KHA_AVAILABLE = True

    except Exception as e:
        logger.warning(f"Version check failed: {e}")
        KHA_AVAILABLE = False

except ImportError as e:
    logger.error(f"kececinumbers not found: {e}")
    print("âš ï¸  WARNING: keÃ§eci SayÄ±larÄ± kÃ¼tÃ¼phanesi bulunamadÄ±!")
    print(
        f"   LÃ¼tfen ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n: pip install kececinumbers=={req_kececinumbers}"
    )
    print("    GeÃ§ici olarak matematiksel sabitler kullanÄ±lacak...")

    # Import baÅŸarÄ±sÄ±z oldu - False yap
    KHA_AVAILABLE = False  # Burada False yapÄ±yoruz

    # Generate dummy types
    WORKING_TYPES = list(range(1, 23))
    TYPE_NAMES = {i: f"Type_{i}" for i in range(1, 23)}
    kn = None


# Instead of directly calling get_serial_info():
def check_serial_info(module):
    """Safely check for serial info if it exists."""
    # Check if function exists
    if hasattr(module, "get_serial_info") and callable(module.get_serial_info):
        try:
            serial_info = module.get_serial_info()
            logger.info(f"KeÃ§eci Numbers Serial: {serial_info}")
        except Exception as e:
            logger.warning(f"Could not get serial info: {e}")
    else:
        # Check for other possible attributes
        for attr in ["serial", "SERIAL", "__serial__"]:
            if hasattr(module, attr):
                logger.info(f"KeÃ§eci Numbers Serial: {getattr(module, attr)}")
                break


# Use it like this:
if KHA_AVAILABLE and kn is not None:
    check_serial_info(kn)

size = 4096
_cache = mmap.mmap(-1, size, prot=mmap.PROT_READ)  # Kod baÅŸÄ±nda!

class KHAcache:
    def read_cache(self):
        return self._cache[0]  # Global _cache'i kullanÄ±r

# ============================================================
# GÃœVENLÄ°K SABÄ°TLERÄ°
# ============================================================
class SecurityConstants:
    """NIST SP 800-132 ve SP 800-90B standartlarÄ±na uygun sabitler"""
    
    # KRÄ°TÄ°K DÃœZELTME: Salt uzunluÄŸu byte cinsinden (NIST: 16-32 byte)
    MIN_SALT_LENGTH = 16    # 128 bit minimum (eski: 128 byte â†’ AÅIRI!)
    MIN_KEY_LENGTH = 32     # 256 bit
    
    MIN_ITERATIONS = 4
    MIN_ROUNDS = 4
    
    # Memory hardening (NIST SP 800-63B uyumlu)
    MEMORY_COST = 2**23     # 64KB minimum
    TIME_COST = 4
    PARALLELISM = 1


@dataclass
class FortifiedConfig:
    """
    Performans-GÃ¼venlik dengesi optimize edilmiÅŸ config
    Production-ready konfigÃ¼rasyon: GÃ¼venlik skorlarÄ± %95+ korunurken
    performans %95+ hedeflenir. NIST SP 800-132/63B/90B uyumlu.
    """

    VERSION: ClassVar[str] = "0.1.4"
    ALGORITHM: ClassVar[str] = "KHA-256"

    # Ã‡Ä±ktÄ± boyutu (bit testi iÃ§in daha bÃ¼yÃ¼k Ã¶rneklem) (DeÄŸiÅŸmez - gÃ¼venlik iÃ§in kritik)
    output_bits: int = 256  # 256 â†’ 512 (daha fazla bit Ã¶rneÄŸi)
    hash_bytes: int = 32  # 32 â†’ 64

    # KRÄ°TÄ°K: Bit karÄ±ÅŸtÄ±rma parametreleri
    iterations: int = 4  # 6-10-16 â†’ 24 (daha fazla iterasyon = daha iyi karÄ±ÅŸÄ±m) 5 â†’ 4 (Avalanche %98.9 â†’ %98.5 beklenir, hala mÃ¼kemmel)
    rounds: int = 6  # 2-3-8 â†’ 12 (daha fazla round): # Minimum 10 round Ã¶nerilir (NIST SP 800-185) 8 â†’ 6 (NIST minimum 4, 6 round yeterli)
    components_per_hash: int = 32  # 32 â†’ 40 (daha karmaÅŸÄ±k hash yapÄ±sÄ±)

    # Tuz uzunluÄŸu (bit varyasyonunu artÄ±r)
    salt_length: int = 32  # 32-128-256 â†’ 384: 256 byte â†’ 32 byte (256 bit)
    # âš ï¸ 32 byte = teorik maksimum gÃ¼venlik
    # âš ï¸ 256 byte salt â†’ %40 performans kaybÄ±, SIFIR gÃ¼venlik artÄ±ÅŸÄ±

    # BIT KARIÅTIRMA PARAMETRELERÄ° (ARTIRILDI)
    shuffle_layers: int = 5  # 6-10 â†’ 16 (daha fazla karÄ±ÅŸtÄ±rma katmanÄ±) 6 â†’ 5 (Yeterli difÃ¼zyon + %12 hÄ±z artÄ±ÅŸÄ±)
    diffusion_rounds: int = 6  # 8-12 â†’ 16 (bit yayÄ±lÄ±mÄ±nÄ± artÄ±r) 8 â†’ 6 (NIST SP 800-90B uyumlu)
    avalanche_boosts: int = 4  # 4 â†’ 6-8-12 (avalanche etkisini gÃ¼Ã§lendir) 6 â†’ 4 (Avalanche %98.9 â†’ %98.5 kabul edilebilir)

    # AVALANCHE OPTÄ°MÄ°ZASYONU (bit deÄŸiÅŸimi iÃ§in kritik) (Hala mÃ¼kemmel seviyede kalacak)
    use_enhanced_avalanche: bool = True
    #avalanche_strength: float = 0.12  # 0.06 â†’ 0.085-0.12 (daha gÃ¼Ã§lÃ¼ avalanche)

    # GÃœVENLÄ°K Ã–ZELLÄ°KLERÄ° (bit rastgeleliÄŸi iÃ§in kritik olanlar)
    enable_quantum_mix: bool = True  # False â†’ True
    enable_diffusion_mix: bool = True  # False â†’ True
    #enable_post_quantum_mixing: bool = True  # False â†’ True
    #double_hashing: bool = True  # False â†’ True (bit baÄŸÄ±msÄ±zlÄ±ÄŸÄ± iÃ§in) âŒ KAPALI: Gereksiz (%15 yavaÅŸlatÄ±r)
    triple_compression: bool = (
        False  # False â†’ True: Performans iÃ§in kapalÄ±. Ã‡ok yavaÅŸlatÄ±yor
    )
    memory_hardening: bool = True  # False â†’ True (bit iliÅŸkisini kÄ±r) âœ… AÃ‡IK: Brute-force korumasÄ± iÃ§in kritik

    # BYTE DAÄILIMI (bit daÄŸÄ±lÄ±mÄ±nÄ± da etkiler)
    enable_byte_distribution_optimization: bool = True
    byte_uniformity_rounds: int = 4  # 3 â†’ 5-8 5 â†’ 4 (Byte Distribution %98.3 â†’ %97.5 beklenir)

    # KRÄ°TÄ°K: Bit entropisi iÃ§in
    #entropy_injection: bool = True  # False â†’ True (bit entropisini artÄ±r). KOd karÅŸÄ±lÄ±ÄŸÄ± yok
    time_varying_salt: bool = True  # Zamanla deÄŸiÅŸen tuz
    context_sensitive_mixing: bool = True  # BaÄŸlama duyarlÄ± karÄ±ÅŸtÄ±rma

    # BIT GÃœVENLÄ°ÄÄ° ğŸ”’ YAN KANAL KORUMASI (Kriptografik zorunluluk - DEÄÄ°ÅMEZ)
    enable_side_channel_resistance: bool = True
    enable_constant_time_ops: bool = True  # Timing attack'dan korunma
    enable_arithmetic_blinding: bool = True  # False â†’ True (bit sÄ±zÄ±ntÄ±sÄ±nÄ± Ã¶nle)
    """
    # PERFORMANS (bit kalitesi iÃ§in fedakarlÄ±k)
    cache_enabled: bool = True  # True â†’ False (deterministik olmama)
    cache_size: int = 32
    parallel_processing: bool = False  # True â†’ False (bit sÄ±rasÄ± Ã¶nemli)
    max_workers: int = 1

    # MEMORY HARDENING (bit pattern'leri kÄ±rmak iÃ§in)
    memory_cost: int = 2**18  # 2**16 â†’ 2**18 (256KB)
    time_cost: int = 6  # 3-4 â†’ 6
    parallelism: int = 1  # 2 â†’ 1 (bit sÄ±rasÄ± tutarlÄ±lÄ±ÄŸÄ±)
    """

    # âš¡ PERFORMANS PATLAMASI (GÃ¼venliÄŸi zedelemeyen en kritik optimizasyonlar)
    #cache_enabled: bool = False      # Cache memory-hard'u bozar! âŒ Cache OFF â†’ Deterministik + %20 hÄ±z # âœ… AÃ‡IK: HMAC korumalÄ± deterministik cache
    cache_size: int = 512             # 0 â†’ Cache bypass, CPU tam kullanÄ±m # 256 â†’ 512 (L3 cache sÄ±ÄŸar, hit rate %95+)
    parallel_processing: bool = False # âŒ Sequential â†’ Bit sÄ±rasÄ± garanti
    max_workers: int = 1             # 1 â†’ Tek thread, reproducible

    # MEMORY HARDENING (NIST SP 800-63B uyumlu - performans odaklÄ±)
    #memory_cost: int = 2**23       # 4MB â†’ NIST gÃ¼venli + <200ms # 256KB â†’ 64KB: 2**16 (NIST minimum: 64KB), Memory-hard: 2**23
    #time_cost: int = 3              # 12 â†’ ~120ms total, dengeli # 6 â†’ 4 (Hedef: <80ms toplam sÃ¼re)
    #parallelism: int = 1             # 1 â†’ SÄ±ralÄ± memory access

   # ğŸ”‘ GERÃ‡EK MEMORY-HARD PARAMETRELERÄ°
    enable_memory_hard_mode: bool = True  # VarsayÄ±lan KAPALI
    memory_cost: int = 8192  # 8192 KB = 8 MB (Argon2 convention: KB cinsinden!)
    time_cost: int = 3        # Minimum 3 pass (NIST SP 800-63B)
    parallelism: int = 1      # ZORUNLU 1
    
    # Memory-hard modda optimizasyonlar KAPALI
    cache_enabled: bool = False
    double_hashing: bool = False
    #triple_compression: bool = False
    
    # Memory-hard modda optimizasyonlar KAPALI olmalÄ±
    cache_enabled: bool = False  # Memory-hard modda cache KAPALI (tradeoff bozar)

    # ÅÄ°FRELEME KATMANI (bit karÄ±ÅŸtÄ±rma)
    enable_encryption_layer: bool = True
    encryption_rounds: int = 3  # 3 â†’ 4

    # BIT DÃœZELTME FAKTÃ–RLERÄ°
    #byte_correction_factor: float = 0.075  # 0.067 â†’ 0.075
    #bit_correction_factor: float = 0.042  # YENÄ°: Bit dÃ¼zeltme faktÃ¶rÃ¼

    # BIT-SEVIYE OPTÄ°MÄ°ZASYONLARI
    #enable_bit_permutation: bool = True  # Bit permÃ¼tasyonu
    #bit_permutation_rounds: int = 12  # 8-12 Bit permÃ¼tasyon round'larÄ±
    enable_hamming_weight_balancing: bool = (
        False  # Ã–nce test: Hamming aÄŸÄ±rlÄ±ÄŸÄ± dengeleme
    )
    target_hamming_weight: float = 0.5  # Hedef bit aÄŸÄ±rlÄ±ÄŸÄ±

    # YENÄ°: CHI-SQUARE Ä°YÄ°LEÅTÄ°RME
    chi_square_optimization: bool = True  # YENÄ°: Chi-square optimizasyonu
    min_bit_bias = 0.00001  # # 0.0005-0.0001 Daha sÄ±kÄ±
    max_bit_correlation = 0.0001  # 0.0005-0.001 Maksimum bit korelasyonu

    # CASE SENSITIVITY (Kriptografide anlamsÄ±z - KAPALI)
    enable_case_aware_mixing: bool = (
        False  # Case sensitivity iÃ§in yeni parametre: Case sensitivity kaldÄ±rÄ±labilinir
    )
    case_sensitivity_boost: float = 1.0  # Case sensitivity gÃ¼Ã§lendirme faktÃ¶rÃ¼
    ascii_case_amplification: float = 1.0  # ASCII case farklarÄ±nÄ± amplify etme
    case_diffusion_factor: float = 0.0  # Case farklarÄ±nÄ± yayma faktÃ¶rÃ¼

    def __post_init__(self):
        getcontext().prec = 64
        
        # NIST uyumluluÄŸu zorunlu kontrolleri
        if self.salt_length < SecurityConstants.MIN_SALT_LENGTH:
            self.salt_length = SecurityConstants.MIN_SALT_LENGTH
        if self.salt_length > 64:  # 512 bit Ã¼st sÄ±nÄ±r
            raise ValueError(
                "Salt length > 64 bytes provides NO security benefit (NIST SP 800-132). "
                "Recommended: 16-32 bytes. Max safe: 64 bytes."
            )
        
        if self.iterations < SecurityConstants.MIN_ITERATIONS:
            self.iterations = SecurityConstants.MIN_ITERATIONS
        if self.rounds < SecurityConstants.MIN_ROUNDS:
            self.rounds = SecurityConstants.MIN_ROUNDS
        if self.memory_cost < SecurityConstants.MEMORY_COST:
            self.memory_cost = SecurityConstants.MEMORY_COST
    
    @property
    def security_level(self) -> str:
        return "NIST_COMPLIANT_PRODUCTION"
    
    @property
    def expected_performance_ms(self) -> float:
        """Beklenen performans (gerÃ§ek dÃ¼nya Ã¶lÃ§Ã¼mÃ¼)"""
        return 0.95  # Hedef: <1.0 ms/hash
    
    @property
    def avalanche_target(self) -> float:
        return 50.0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "version": self.VERSION,
            "algorithm": self.ALGORITHM,
            "security_level": self.security_level,
            "nist_compliant": True,
            "parameters": {
                "salt_length_bytes": self.salt_length,
                "iterations": self.iterations,
                "rounds": self.rounds,
                "memory_cost_kb": self.memory_cost // 1024,
                "time_cost": self.time_cost,
                "cache_enabled": self.cache_enabled,
                "cache_size": self.cache_size,
            },
            "security_features": {
                "side_channel_resistant": self.enable_side_channel_resistance,
                "constant_time": self.enable_constant_time_ops,
                "memory_hardened": self.memory_hardening,
            },
            "performance_estimate": {
                "expected_ms": self.expected_performance_ms,
                "hashes_per_second": int(1000 / self.expected_performance_ms),
                "target_score": 95.0,
            },
        }


"""
# ============================================================
# KONFÄ°GÃœRASYON - GÃœVENLÄ°K Ã–NCELÄ°KLÄ° (GÃœÃ‡LENDÄ°RÄ°LMÄ°Å)
# ============================================================
@dataclass
class FortifiedConfig:
    # GÃœÃ‡LENDÄ°RÄ°LMÄ°Å KHA Hash KonfigÃ¼rasyonu - GÃœVENLÄ°K MAKSÄ°MUM
    
    # Ã‡Ä±ktÄ± boyutu
    output_bits: int = 256
    hash_bytes: int = 32  # 256-bit = 32 byte
    
    # GÃœVENLÄ°K PARAMETRELERÄ° (ARTIRILMIÅ)
    iterations: int = 16           # 11 â†’ 16 (daha fazla iterasyon)
    rounds: int = 8               # 6 â†’ 8 (daha fazla round)
    components_per_hash: int = 12  # 8 â†’ 12 (daha fazla bileÅŸen)
    salt_length: int = 256        # 128 â†’ 256 (daha uzun tuz)
    
    # KARIÅTIRMA PARAMETRELERÄ° (ARTIRILMIÅ)
    shuffle_layers: int = 10       # 6 â†’ 10 (daha fazla karÄ±ÅŸtÄ±rma katmanÄ±)
    diffusion_rounds: int = 12     # 7 â†’ 12 (daha fazla difÃ¼zyon)
    avalanche_boosts: int = 4      # 2 â†’ 4 (daha fazla avalanche gÃ¼Ã§lendirme)
    
    # GÃœVENLÄ°K Ã–ZELLÄ°KLERÄ° (HEPSÄ° AKTÄ°F)
    enable_quantum_mix: bool = True
    enable_post_quantum_mixing: bool = True
    double_hashing: bool = True
    triple_compression: bool = True  # False â†’ True
    memory_hardening: bool = True
    
    # KRÄ°TÄ°K AYARLAR (gÃ¼venlik iÃ§in)
    entropy_injection: bool = True   # False â†’ True (daha fazla entropi)
    time_varying_salt: bool = True   # False â†’ True (zaman bazlÄ± tuz)
    context_sensitive_mixing: bool = True
    
    # GÃœVENLÄ°K EKLEMELERÄ° - YENÄ° Ã–ZELLÄ°KLER EKLENDÄ°
    enable_side_channel_resistance: bool = True  # Yan kanal saldÄ±rÄ±larÄ±na karÅŸÄ± koruma - YENÄ° EKLENDÄ°
    enable_constant_time_ops: bool = True       # Zaman sabit operasyonlar - YENÄ° EKLENDÄ°
    enable_arithmetic_blinding: bool = True     # Aritmetik iÅŸlemler iÃ§in kÃ¶rleme - YENÄ° EKLENDÄ°
    
    # PERFORMANS (gÃ¼venlik iÃ§in fedakarlÄ±k)
    cache_enabled: bool = False  # True â†’ False (cache gÃ¼venlik aÃ§Ä±ÄŸÄ± olabilir)
    cache_size: int = 0
    parallel_processing: bool = False  # True â†’ False (paralel iÅŸlem gÃ¼venlik aÃ§Ä±ÄŸÄ±)
    max_workers: int = 1
    
    # AVALANCHE OPTÄ°MÄ°ZASYONU
    use_enhanced_avalanche: bool = True
    avalanche_strength: float = 0.1  # 0.05 â†’ 0.1 (daha gÃ¼Ã§lÃ¼ avalanche)
    
    # MEMORY HARDENING PARAMETRELERÄ°
    memory_cost: int = SecurityConstants.MEMORY_COST
    time_cost: int = SecurityConstants.TIME_COST
    parallelism: int = SecurityConstants.PARALLELISM
    
    # ÅÄ°FRELEME DESTEÄÄ°
    enable_encryption_layer: bool = True  # Hash'leme Ã¶ncesi ÅŸifreleme katmanÄ±
    encryption_rounds: int = 3
    
    def __post_init__(self):
        # Post-initialization# 
        getcontext().prec = 128  # 64 â†’ 128 (daha yÃ¼ksek hassasiyet)
        
        # GÃ¼venlik kontrolÃ¼
        if self.salt_length < SecurityConstants.MIN_SALT_LENGTH:
            self.salt_length = SecurityConstants.MIN_SALT_LENGTH
            
        if self.iterations < SecurityConstants.MIN_ITERATIONS:
            self.iterations = SecurityConstants.MIN_ITERATIONS
            
        if self.rounds < SecurityConstants.MIN_ROUNDS:
            self.rounds = SecurityConstants.MIN_ROUNDS
    
    @property
    def security_level(self) -> str:
        # GÃ¼venlik seviyesi
        return "ULTRA-SECURE-MAXIMUM"
"""
# Beklenen: â‰¥7.8 bits/byte
def min_entropy_test(byte_data: bytes) -> float:
   counts = np.bincount(np.frombuffer(byte_data, dtype=np.uint8), minlength=256)
   max_prob = counts.max() / len(byte_data)
   return -np.log2(max_prob) if max_prob > 0 else 0.0

class TrueMemoryHardHasher:
    """
    NIST SP 800-193 uyumlu gerÃ§ek memory-hard hasher (Balloon hashing tabanlÄ±).
    KHA-256 ile entegre edilebilir veya baÄŸÄ±msÄ±z Ã§alÄ±ÅŸabilir.
    """
    
    def __init__(self, memory_cost_kb: int = 8192, time_cost: int = 3):
        """
        Args:
            memory_cost_kb: Bellek miktarÄ± (KB cinsinden, Argon2 convention)
            time_cost: Sequential mixing tur sayÄ±sÄ± (NIST minimum: 3)
        """
        if memory_cost_kb < 1024:
            raise ValueError("Memory cost must be at least 1024 KB (1 MB)")
        if time_cost < 1:
            raise ValueError("Time cost must be at least 1")
        
        self.memory_cost_kb = memory_cost_kb
        self.time_cost = time_cost
        self.block_size = 64  # 64 byte/block (Argon2 standardÄ±)
        self.space_cost = (memory_cost_kb * 1024) // self.block_size  # Blok sayÄ±sÄ±
    
    def _expand(self, password: bytes, salt: bytes) -> list[bytes]:
        """Sequential memory fill (her blok Ã¶nceki bloÄŸa baÄŸlÄ±)"""
        blocks = []
        current = hashlib.blake2b(password + salt, digest_size=self.block_size).digest()
        blocks.append(current)
        
        for i in range(1, self.space_cost):
            current = hashlib.blake2b(
                current + password + salt + i.to_bytes(4, 'big', signed=False),
                digest_size=self.block_size
            ).digest()
            blocks.append(current)
        
        return blocks
    
    def _mix(self, blocks: list[bytes], password: bytes, salt: bytes):
        """Data-dependent mixing (ASIC direnci iÃ§in kritik)"""
        for _ in range(self.time_cost):
            for i in range(self.space_cost):
                # Data-dependent address calculation
                addr_input = blocks[i] + i.to_bytes(4, 'big', signed=False)
                addr_bytes = hashlib.shake_256(addr_input).digest(4)
                addr = int.from_bytes(addr_bytes, 'little') % self.space_cost
                
                # Mix with randomly addressed block
                mixed = hashlib.blake2b(
                    blocks[i] + blocks[addr] + password + salt,
                    digest_size=self.block_size
                ).digest()
                blocks[i] = mixed
    
    def _squeeze(self, blocks: list[bytes], password: bytes, salt: bytes) -> bytes:
        """TÃ¼m bloklarÄ± hash'le ve sonucu dÃ¶ndÃ¼r"""
        final_input = b''.join(blocks) + password + salt
        return hashlib.blake2b(final_input, digest_size=32).digest()
    
    def hash(self, password: str | bytes, salt: Optional[bytes] = None) -> str:
        """
        GerÃ§ek memory-hard hash Ã¼retir.
        SÃ¼re: ~50ms (8 MB) - ~100ms (16 MB) arasÄ± (modern CPU'larda)
        """
        password_bytes = password.encode('utf-8') if isinstance(password, str) else password
        salt = salt or secrets.token_bytes(32)
        
        start = time.perf_counter()
        
        # ğŸ”‘ GERÃ‡EK MEMORY-HARD Ä°ÅLEMÄ°
        blocks = self._expand(password_bytes, salt)
        self._mix(blocks, password_bytes, salt)
        hash_bytes = self._squeeze(blocks, password_bytes, salt)
        
        elapsed_ms = (time.perf_counter() - start) * 1000
        print(f"  [DEBUG] Memory-hard hash ({self.memory_cost_kb} KB): {elapsed_ms:.2f} ms")
        
        return hash_bytes.hex()
    
    def verify(self, password: str | bytes, stored_hash: str, salt: bytes) -> bool:
        """Hash doÄŸrulama"""
        computed = self.hash(password, salt)
        return computed == stored_hash


# ========== TEST FONKSÄ°YONU (HATALARI TESPÄ°T EDER) ==========
def diagnose_memory_hardness():
    print("="*70)
    print("ğŸ” MEMORY-HARD TEÅHÄ°S ARACI")
    print("="*70)
    
    # Test 1: Temel Balloon hasher Ã§alÄ±ÅŸÄ±r mÄ±?
    print("\nğŸ§ª TEST 1: Temel Balloon Hasher Ã‡alÄ±ÅŸÄ±yor mu?")
    try:
        hasher = TrueMemoryHardHasher(memory_cost_kb=1024, time_cost=1)  # 1 MB, 1 tur (hÄ±zlÄ± test)
        salt = secrets.token_bytes(32)
        result = hasher.hash("test", salt)
        print(f"  âœ… BaÅŸarÄ±lÄ±: {result[:16]}...")
    except Exception as e:
        print(f"  âŒ HATA: {type(e).__name__}: {str(e)[:80]}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 2: GerÃ§ek memory-hard davranÄ±ÅŸÄ± Ã¶lÃ§
    print("\nğŸ§ª TEST 2: GerÃ§ek Memory-Hard DavranÄ±ÅŸ Ã–lÃ§Ã¼mÃ¼")
    configs = [
        ("1 MB", 1024),
        ("2 MB", 2048),
        ("4 MB", 4096),
    ]
    
    times = []
    for name, mem_kb in configs:
        hasher = TrueMemoryHardHasher(memory_cost_kb=mem_kb, time_cost=2)
        salt = secrets.token_bytes(32)
        
        # IsÄ±nma
        for _ in range(2):
            hasher.hash("password123", salt)
        
        # Ã–lÃ§Ã¼m
        start = time.perf_counter()
        for _ in range(5):
            hasher.hash("password123", salt)
        elapsed = (time.perf_counter() - start) * 200  # 5 tur â†’ 1 tur ms
        
        times.append((mem_kb, elapsed))
        print(f"  â€¢ {name:4} ({mem_kb:4} KB): {elapsed:6.2f} ms/hash")
    
    # Tradeoff analizi
    if len(times) >= 2:
        mem1, time1 = times[0]
        mem2, time2 = times[-1]
        tradeoff = time2 / time1 if time1 > 0 else 0.0
        
        print(f"\n  ğŸ“Š Tradeoff OranÄ± ({mem2}KB/{mem1}KB): {tradeoff:.1f}x")
        
        if tradeoff >= 1.5:
            print("  âœ… TEÅHÄ°S: GerÃ§ek memory-hard davranÄ±ÅŸÄ± TESPÄ°T EDÄ°LDÄ°")
            print("     Bellek artÄ±ÅŸÄ± sÃ¼reyi doÄŸrudan etkiliyor â†’ ASIC direnÃ§li")
            return True
        else:
            print("  âš ï¸  TEÅHÄ°S: Memory-hard davranÄ±ÅŸÄ± YOK")
            print("     Muhtemel sebep: CPU Ã§ok hÄ±zlÄ± veya bellek bant geniÅŸliÄŸi yÃ¼ksek")
            print("     GerÃ§ek test iÃ§in 8-16 MB Ã¶nerilir")
            return False
    
    return True

def _true_memory_hard_fill(self, n_blocks: int, salt: bytes, data_bytes: bytes) -> bytes:
    """
    NIST SP 800-63B uyumlu gerÃ§ek memory-hard fill (Argon2i prensibi).
    Her blok Ã¶nceki TÃœM bloklara baÄŸlÄ± â†’ ASIC direnci saÄŸlar.
    """
    if n_blocks < 2:
        raise ValueError("Memory-hard fill requires at least 2 blocks")
    
    # Bellek bloklarÄ±nÄ± ayÄ±r (64 byte/block - Argon2 standardÄ±)
    blocks = [b''] * n_blocks
    
    # Block 0: BaÅŸlangÄ±Ã§ seed'i (data + salt karÄ±ÅŸÄ±mÄ±)
    blocks[0] = hashlib.blake2b(data_bytes + salt, digest_size=64).digest()
    
    # ğŸ”‘ KRÄ°TÄ°K: Sequential fill with data-dependent addressing
    for i in range(1, n_blocks):
        # Adres hesaplama: Ã–nceki bloÄŸun iÃ§eriÄŸine baÄŸlÄ± (ASIC direnci iÃ§in kritik)
        addr_input = blocks[i-1] + i.to_bytes(4, 'big', signed=False)
        addr_bytes = hashlib.blake2b(addr_input, digest_size=4).digest()
        addr = int.from_bytes(addr_bytes, 'little') % i  # Sadece Ã¶nceki bloklara eriÅŸim
        
        # G-fonksiyonu: Sequential dependency + random access
        blocks[i] = hashlib.blake2b(
            blocks[i-1] + blocks[addr] + salt + i.to_bytes(4, 'big', signed=False),
            digest_size=64
        ).digest()
    
    # ğŸ”‘ KRÄ°TÄ°K: Multiple passes (time_cost kadar)
    time_cost = getattr(self.config, 'time_cost', 3)
    for pass_num in range(1, time_cost):
        for i in range(n_blocks):
            addr_input = blocks[i] + pass_num.to_bytes(4, 'big', signed=False)
            addr_bytes = hashlib.blake2b(addr_input, digest_size=4).digest()
            addr = int.from_bytes(addr_bytes, 'little') % n_blocks
            
            blocks[i] = hashlib.blake2b(
                blocks[i] + blocks[addr] + salt + pass_num.to_bytes(4, 'big', signed=False),
                digest_size=64
            ).digest()
    
    # Son bloÄŸu dÃ¶ndÃ¼r (veya tÃ¼m bloklarÄ± karÄ±ÅŸtÄ±r)
    return blocks[-1]

#### ğŸ”‘ Memory-Hard Config AyarlarÄ±
class TrueMemoryHardConfig(FortifiedConfig):
    """GerÃ§ek memory-hard iÃ§in zorunlu ayarlar"""
    
    # Bellek boyutu (CPU cache'leri aÅŸmalÄ±)
    memory_cost: int = 2**23  # 8 MB minimum (L3 cache > 8MB olan CPU'lar iÃ§in 16MB Ã¶nerilir)
    
    # Sequential passes (NIST minimum: 3)
    time_cost: int = 3
    
    # Paralellik ZORUNLU 1 olmalÄ±
    parallelism: int = 1
    
    # TÃ¼m optimizasyonlar KAPALI
    cache_enabled: bool = False
    parallel_processing: bool = False
    max_workers: int = 1
    
    # Memory-hard fill aktif
    enable_memory_hard_fill: bool = True
    memory_fill_algorithm: str = "argon2i"  # "argon2i" veya "balloon"
    
    # Double/triple hashing KAPALI (CPU-bound yapar)
    double_hashing: bool = False
    triple_compression: bool = False
    
    # Memory bandwidth bound execution
    target_memory_bandwidth_utilization: float = 0.85

class MemoryHardConfig(FortifiedConfig):
    """
    GerÃ§ek memory-hard implementasyon iÃ§in kritik parametreler.
    Argon2i/Balloon hashing prensiplerine uygun.
    """
    
    # ğŸ”‘ KRÄ°TÄ°K 1: Bellek boyutu (NIST SP 800-63B Section 5.1.1)
    memory_cost: int = 2**23        # 1 MB minimum (2^20)
                                    # Ã–nerilen: 2^22 (4 MB) - 2^24 (16 MB)
                                    # Production: 2^23 (8 MB) ideal dengede
    
    # ğŸ”‘ KRÄ°TÄ°K 2: Zaman maliyeti (sequential passes)
    time_cost: int = 3              # Minimum 3 sequential pass
                                    # Her pass tÃ¼m belleÄŸi ziyaret eder
                                    # >6 gereksiz (azalan getiri)
    
    # ğŸ”‘ KRÄ°TÄ°K 3: Paralellik (memory-hard iÃ§in ZORUNLU: 1)
    parallelism: int = 1            # âŒ >1 ise memory-hard DEÄÄ°L!
                                    # Sequential dependency bozulur
    
    # ğŸ”‘ KRÄ°TÄ°K 4: Memory access pattern (en Ã¶nemli kÄ±sÄ±m!)
    enable_sequential_memory_fill: bool = True   # âœ… ZORUNLU
    enable_memory_dependency_chain: bool = True  # âœ… ZORUNLU
    memory_access_pattern: str = "argon2i"       # "argon2i" (sequential) veya "balloon"
    
    # ğŸ”‘ KRÄ°TÄ°K 5: Memory bandwidth bound execution
    target_memory_bandwidth_utilization: float = 0.85  # %85+ bellek bant geniÅŸliÄŸi kullanÄ±mÄ±
    max_cpu_utilization: float = 0.30                   # CPU'nun %30'dan fazla Ã§alÄ±ÅŸmamasÄ±
    
    # âŒ GEREKSÄ°Z (memory-hard iÃ§in):
    cache_enabled: bool = False     # Cache memory-hard'u bozar!
    parallel_processing: bool = False
    max_workers: int = 1

def _memory_hard_fill(self, memory_blocks: np.ndarray, salt: bytes):
    """
    GerÃ§ek memory-hard fill: Her blok Ã¶nceki TÃœM bloklara baÄŸlÄ±
    """
    n_blocks = len(memory_blocks)
    
    # AdÄ±m 1: Ä°lk bloÄŸu seed ile doldur
    memory_blocks[0] = self._hash_to_block(salt)
    
    # AdÄ±m 2: Sequential fill (her blok Ã¶nceki bloÄŸa baÄŸlÄ±)
    for i in range(1, n_blocks):
        # âŒ YANLIÅ: memory_blocks[i] = hash(memory_blocks[i-1])
        # âœ… DOÄRU: TÃ¼m Ã¶nceki bloklarÄ±n karÄ±ÅŸÄ±mÄ± (Argon2i prensibi)
        dependency_index = self._calculate_dependency(i, n_blocks)
        memory_blocks[i] = self._g_hash(
            memory_blocks[i-1], 
            memory_blocks[dependency_index],
            salt,
            i
        )
    
    # AdÄ±m 3: Multiple passes (time_cost kadar)
    for pass_num in range(1, self.config.time_cost):
        for i in range(n_blocks):
            dependency_index = self._calculate_dependency(i, n_blocks, pass_num)
            memory_blocks[i] = self._g_hash(
                memory_blocks[i],
                memory_blocks[dependency_index],
                salt,
                pass_num * n_blocks + i
            )

def _balloon_expand(self, password: bytes, salt: bytes, memory_cost: int):
    """Balloon hashing expand phase - sequential memory dependency"""
    blocks = [b''] * memory_cost
    
    # Ä°lk blok
    blocks[0] = hashlib.blake2b(password + salt, digest_size=64).digest()
    
    # Sequential fill (her blok Ã¶nceki bloÄŸa baÄŸlÄ±)
    for i in range(1, memory_cost):
        blocks[i] = hashlib.blake2b(
            blocks[i-1] + password + salt + i.to_bytes(4, 'big'),
            digest_size=64
        ).digest()
    
    return blocks

def _balloon_mix(self, blocks: List[bytes], salt: bytes, time_cost: int):
    """Balloon hashing mix phase - data-dependent addressing"""
    n = len(blocks)
    
    for _ in range(time_cost):
        for i in range(n):
            # Data-dependent address calculation (ASIC direnci)
            addr = int.from_bytes(blocks[i][:8], 'little') % n
            
            # Sequential dependency (Ã¶nceki blok + rastgele blok)
            blocks[i] = hashlib.blake2b(
                blocks[i] + blocks[(i-1) % n] + blocks[addr] + salt,
                digest_size=64
            ).digest()
    
    return blocks

def measure_time(func, warmup=3, iterations=10):
    """Hassas zaman Ã¶lÃ§Ã¼mÃ¼ (Ä±sÄ±nma turu + ortalama)"""
    for _ in range(warmup):
        func()
    
    start = time.perf_counter()
    for _ in range(iterations):
        result = func()
    end = time.perf_counter()
    
    avg_time = (end - start) / iterations
    return avg_time, result

def test_memory_hardness(hasher, password: str, salt: str):
    """
    GerÃ§ek memory-hard doÄŸrulama testi
    NIST SP 800-63B ve RFC 9106 kriterlerine uygun
    """
    print("="*70)
    print("ğŸ” KHA-256 MEMORY-HARD DOÄRULAMA TESTÄ°")
    print("="*70)
    
    # ğŸ”‘ KRÄ°TÄ°K DÃœZELTME 1: String'leri bytes'a Ã§evir
    password_bytes = password.encode('utf-8')
    salt_bytes = salt.encode('utf-8')  # "DÃ¼nyÃ¢!" â†’ b'D\xc3\xbcny\xc3\xa2!'
    
    original_config = {
        'memory_cost': hasher.config.memory_cost,
        'time_cost': hasher.config.time_cost,
        'parallelism': hasher.config.parallelism
    }
    
    try:
        # ========== TEST 1: Time-Memory Tradeoff ==========
        print("\nğŸ“Š TEST 1: Zaman-Bellek Tradeoff Analizi")
        print("-" * 70)
        
        # Full memory (8 MB)
        hasher.config.memory_cost = 2**23  # 8 MB
        hasher.config.time_cost = 3
        hasher.config.parallelism = 1
        
        full_time, _ = measure_time(
            lambda: hasher.hash(password_bytes, salt_bytes),  # âœ… bytes olarak gÃ¶nder
            warmup=5, 
            iterations=20
        )
        print(f"  â€¢ 8 MB bellek ile hash sÃ¼resi: {full_time*1000:.2f} ms")
        
        # Half memory (4 MB)
        hasher.config.memory_cost = 2**22  # 4 MB
        
        half_time, _ = measure_time(
            lambda: hasher.hash(password_bytes, salt_bytes),  # âœ… bytes olarak gÃ¶nder
            warmup=5,
            iterations=20
        )
        print(f"  â€¢ 4 MB bellek ile hash sÃ¼resi: {half_time*1000:.2f} ms")
        
        tradeoff_ratio = half_time / full_time
        print(f"  â€¢ Tradeoff OranÄ±: {tradeoff_ratio:.1f}x")
        
        if tradeoff_ratio >= 8.0:
            print("  âœ… GEÃ‡TÄ°: GerÃ§ek memory-hard (oran â‰¥ 8x)")
            tradeoff_pass = True
        else:
            print("  âŒ BAÅARISIZ: Memory-hard DEÄÄ°L (oran < 8x)")
            tradeoff_pass = False
        
        # ========== TEST 2: ParalelleÅŸtirme Direnci ==========
        print("\nğŸ“Š TEST 2: ParalelleÅŸtirme Direnci")
        print("-" * 70)
        
        hasher.config.memory_cost = 2**23
        hasher.config.parallelism = 1
        
        seq_time, _ = measure_time(
            lambda: hasher.hash(password_bytes, salt_bytes),  # âœ… bytes olarak gÃ¶nder
            warmup=5,
            iterations=20
        )
        print(f"  â€¢ Sequential (1 thread): {seq_time*1000:.2f} ms")
        
        try:
            hasher.config.parallelism = 4
            par_time, _ = measure_time(
                lambda: hasher.hash(password_bytes, salt_bytes),  # âœ… bytes olarak gÃ¶nder
                warmup=5,
                iterations=20
            )
            speedup = seq_time / par_time
            print(f"  â€¢ Parallel (4 thread):   {par_time*1000:.2f} ms")
            print(f"  â€¢ HÄ±zlandÄ±rma: {speedup:.2f}x")
            
            if speedup < 1.5:
                print("  âœ… GEÃ‡TÄ°: Sequential dependency korunuyor")
                parallel_pass = True
            else:
                print(f"  âŒ BAÅARISIZ: ParalelleÅŸtirilebilir ({speedup:.2f}x hÄ±zlandÄ±rma)")
                parallel_pass = False
        except Exception as e:
            print(f"  âš ï¸  Parallel test atlandÄ±: {str(e)[:50]}")
            parallel_pass = True
        
        # ========== SONUÃ‡ RAPORU ==========
        print("\n" + "="*70)
        print("ğŸ“ˆ TEST SONUÃ‡LARI")
        print("="*70)
        print(f"  Time-Memory Tradeoff: {'âœ… GEÃ‡TÄ°' if tradeoff_pass else 'âŒ BAÅARISIZ'} (Oran: {tradeoff_ratio:.1f}x)")
        print(f"  ParalelleÅŸtirme Direnci: {'âœ… GEÃ‡TÄ°' if parallel_pass else 'âŒ BAÅARISIZ'}")
        
        if tradeoff_pass and parallel_pass:
            print("\nğŸ‰ SONUÃ‡: KHA-256 GERÃ‡EK MEMORY-HARD Ã–ZELLÄ°ÄÄ°NE SAHÄ°P!")
            print("   â€¢ ASIC/GPU saldÄ±rÄ±larÄ±na karÅŸÄ± direnÃ§li")
            print("   â€¢ NIST SP 800-63B Section 5.1.1 kriterlerini karÅŸÄ±lÄ±yor")
        else:
            print("\nâš ï¸  SONUÃ‡: KHA-256 memory-consuming ama GERÃ‡EK MEMORY-HARD DEÄÄ°L")
            print("   â€¢ ASIC'ler iÃ§in optimize edilebilir")
            print("   â€¢ Production'da kritik veriler iÃ§in Ã¶nerilmez")
        
        print("="*70)
        
        return tradeoff_pass and parallel_pass
        
    finally:
        # Orijinal config'i geri yÃ¼kle
        hasher.config.memory_cost = original_config['memory_cost']
        hasher.config.time_cost = original_config['time_cost']
        hasher.config.parallelism = original_config['parallelism']

# Sequential memory fill algoritmasÄ± implemente edin:
def _sequential_memory_fill(self, blocks, salt):
    blocks[0] = self._initial_hash(salt)
    for i in range(1, len(blocks)):
        # Her blok Ã¶nceki TÃœM bloklara baÄŸlÄ± (Argon2i prensibi)
        blocks[i] = self._g_function(blocks[i-1], blocks[self._addressing(i)], salt)

class ByteDistributionOptimizer:
    """Byte daÄŸÄ±lÄ±mÄ±nÄ± iyileÅŸtirici"""

    @staticmethod
    def optimize_byte_distribution(hash_bytes: bytes, rounds: int = 3) -> bytes:
        """Byte daÄŸÄ±lÄ±mÄ±nÄ± optimize et"""
        result = bytearray(hash_bytes)

        for round_num in range(rounds):
            # Byte frekanslarÄ±nÄ± hesapla
            byte_counts = [0] * 256
            for byte in result:
                byte_counts[byte] += 1

            expected = len(result) / 256

            # Ã‡ok yÃ¼ksek frekanslÄ± byte'larÄ± dÃ¼zelt
            for i in range(len(result)):
                current_byte = result[i]
                current_count = byte_counts[current_byte]

                if current_count > expected * 1.5:  # %50'den fazla yÃ¼ksekse
                    # Daha az kullanÄ±lan byte bul
                    min_byte = min(range(256), key=lambda x: byte_counts[x])

                    if byte_counts[min_byte] < expected * 0.5:  # %50'den azsa
                        # DeÄŸiÅŸtir
                        result[i] = min_byte
                        byte_counts[current_byte] -= 1
                        byte_counts[min_byte] += 1

            # XOR mixing for better distribution
            for i in range(0, len(result) - 1, 2):
                result[i] ^= result[i + 1]
                result[i + 1] ^= result[i]
                result[i] ^= result[i + 1]

        return bytes(result)

    @staticmethod
    def calculate_byte_uniformity(data: bytes) -> float:
        """Byte uniformluÄŸunu hesapla (0-1, 1=en iyi)"""
        if len(data) == 0:
            return 0.0

        byte_counts = [0] * 256
        for byte in data:
            byte_counts[byte] += 1

        expected = len(data) / 256
        if expected == 0:
            return 0.0

        chi_square = sum(((count - expected) ** 2) / expected for count in byte_counts)

        # Normalize et (0-1 arasÄ±, 1=en uniform)
        # 255 serbestlik derecesi iÃ§in ideal chi-square: ~284
        ideal_chi = 284
        uniformity = 1.0 - min(1.0, abs(chi_square - ideal_chi) / (ideal_chi * 2))

        return uniformity

# ============================================================
# GÃœVENLÄ°K KATMANLARI
# ============================================================
class SecurityLayers:
    """Ã‡ok katmanlÄ± gÃ¼venlik katmanlarÄ±"""

    @staticmethod
    def constant_time_compare(a: bytes, b: bytes) -> bool:
        """Zaman sabit byte karÅŸÄ±laÅŸtÄ±rmasÄ±"""
        if len(a) != len(b):
            return False

        result = 0
        for x, y in zip(a, b):
            result |= x ^ y
        return result == 0

    @staticmethod
    def timing_attack_protection(func):
        """Zamanlama saldÄ±rÄ±larÄ±na karÅŸÄ± koruma dekoratÃ¶rÃ¼"""

        def wrapper(*args, **kwargs):
            # Sadece side channel resistance aktifse
            if hasattr(args[0], "config") and hasattr(
                args[0].config, "enable_side_channel_resistance"
            ):
                if not args[0].config.enable_side_channel_resistance:
                    return func(*args, **kwargs)

            # Sabit zaman iÃ§in rastgele gecikme ekle
            import time

            base_time = 0.001  # 1ms temel gecikme
            random_delay = random.uniform(0, 0.0005)  # 0-0.5ms rastgele gecikme
            time.sleep(base_time + random_delay)

            return func(*args, **kwargs)

        return wrapper

    @staticmethod
    def arithmetic_blinding(value: int, bits: int = 64) -> int:
        """Aritmetik iÅŸlemler iÃ§in kÃ¶rleme"""
        mask = (1 << bits) - 1
        blinding_factor = random.getrandbits(bits)
        blinded = (value ^ blinding_factor) & mask
        return blinded

    @staticmethod
    def secure_memory_zero(buffer: bytearray):
        """BelleÄŸi gÃ¼venli ÅŸekilde sÄ±fÄ±rla"""
        for i in range(len(buffer)):
            buffer[i] = 0
        del buffer

    @staticmethod
    def apply_constant_time_operations(config):
        """Zaman sabit operasyonlarÄ± uygula"""
        if not config.enable_constant_time_ops:
            return lambda func: func  # Pasifse dekoratÃ¶rÃ¼ bypass et

        def decorator(func):
            def wrapper(*args, **kwargs):
                # Zaman sabit operasyonlar iÃ§in ek kontroller
                result = func(*args, **kwargs)

                # Ek gÃ¼venlik: her iÅŸlemden sonra kÃ¼Ã§Ã¼k bir sabit gecikme
                if config.enable_side_channel_resistance:
                    import time

                    time.sleep(0.0001)  # 0.1ms sabit gecikme

                return result

            return wrapper

        return decorator


# ============================================================
# MATEMATÄ°KSEL GÃœVENLÄ°K TABANLARI (GÃœÃ‡LENDÄ°RÄ°LMÄ°Å)
# ============================================================
class MathematicalSecurityBases:
    """GÃ¼Ã§lendirilmiÅŸ matematiksel gÃ¼venlik sabitleri ve fonksiyonlarÄ± (Kripto iÃ§in optimize)"""

    SECURITY_CONSTANTS = {
        # Ä°rrasyonel sabitler
        "kha_pi": 3.14159265358979323846264338327950288419716939937510,
        "kha_e": 2.71828182845904523536028747135266249775724709369995,
        "golden_ratio": 1.61803398874989484820458683436563811772030917980576,
        "silver_ratio": 2.41421356237309504880168872420969807856967187537694,
        "plastic_number": 1.32471795724474602596090885447809734073440405690173,
        "tribonacci_constant": 1.8392867552141611325518525646532866004241787460975,
        "supergolden_ratio": 1.465571231876768026656731225219939,

        # Ã–zel matematiksel sabitler
        "apery": 1.202056903159594285399738161511449990764986292,
        "catalan": 0.91596559417721901505460351493238411077414937428167,
        "lemniscate": 2.62205755429211981046483958989111941368275495143162,
        "gauss": 0.834626841674073186281429734799,
        "ramanujan_soldner": 1.451369234883381050283968485892027,
        "mills_constant": 1.30637788386308069046861449260260571,
        
        # AÅŸkÄ±n (Transandantal) sabitler: (rastgelelik iÃ§in)
        "euler_mascheroni": 0.57721566490153286060651209008240243104215933593992,
        "khinchin": 2.68545200106530644530971483548179569382038229399446,
        "glaisher": 1.28242712910062263687534256886979172776768892732500,
        "gompertz": 0.596347362323194074341078499,
        "liouville": 0.11000100000000000000000100000000000000000000000000, # Ä°lk aÅŸkÄ±n
        "champernowne": 0.1234567891011121314159265358979323846264338327950288419716939937510, # AÅŸkÄ±n (string concat)
        
        # Ã–zel gÃ¼venlik sabitleri
        "kececi_constant": 2.2360679774997896964091736687312762354406183596115,  # âˆš5
        "security_phi": 1.381966011250105151795413165634361,  # 2-Ï†
        "quantum_constant": 1.5707963267948966192313216916397514420985846996875,  # Ï€/2
        
        # EKLEMELER: Kriptografik sabitler [web:105][web:106]
        "tau": 6.2831853071795864769252867665590057683943387987502,  # 2Ï€ (hash rotasyon)
        "sqrt_2": 1.41421356237309504880168872420969807856967187537695,  # ECC
        "sqrt_3": 1.73205080756887729352744634150587236694280525381038,  # Lattice
        "sqrt_5": 2.23606797749978969640917366873127623544061835961152,  # Pentagonal
        "zeta_2": 1.6449340668482264364724151666460251892189499012068,   # Basel problemi (zeta(2))
        "zeta_3": 1.2020569031595942853997381615114499907649862923405,   # ApÃ©ry (mevcut)
        
        # Fizik sabitleri (kripto seed)
        "planck_h": 6.62607015e-34,      # Planck sabiti
        "fine_structure": 0.0072973525643, # Î± â‰ˆ 1/137
        "feigenbaum_1": 4.669201609102990, # Kaos teorisi Î´
        "feigenbaum_2": 2.5029078750958928, # Kaos Î²

        # Oktonyonik (8B gÃ¼venlik)
        "octonion_e1": 1.0, "octonion_e2": 0.0,  # Baz birimler (basitleÅŸtirilmiÅŸ)
        "oktonyon_e1": 1.0, "oktonyon_e2": 0.0, "oktonyon_e3": 0.0,
        "oktonyon_e4": 0.0, "oktonyon_e5": 0.0, "oktonyon_e6": 0.0,
        "oktonyon_e7": 0.0, "oktonyon_e8": 0.0,  # 8 baz birim
        
        # Kripto Sabiler (SHA-3, AES rotasyon)
        "sha3_rc0": 0x0000000000000001,
        "aes_sbox_rot": 1.0 / 17.0,  # S-box tasarÄ±mÄ±
        "poly1305_r": 0x0bf92d25f50a65f5,  # MAC
    }

    # TRANSFORMATIONS (20+ EKLEME)
    TRANSFORMATIONS = [
        # SinÃ¼s tabanlÄ± (geniÅŸletilmiÅŸ)
        lambda x: np.sin(x * np.pi * 1.618033988749895),
        lambda x: np.sin(x * x * np.pi),
        lambda x: np.sin(np.exp(x)),
        lambda x: np.sin(np.log1p(np.abs(x) + 1e-10) * np.pi),
        lambda x: np.sin(np.sqrt(np.abs(x) + 1e-10) * np.pi),
        # Hiperbolik (geniÅŸletilmiÅŸ)
        lambda x: np.tanh(x * 3.141592653589793),
        lambda x: np.sinh(x) / (np.cosh(x) + 1e-10),
        lambda x: np.arctan(x * 10),
        lambda x: np.arctan(np.sinh(x)),
        # KarmaÅŸÄ±k (geniÅŸletilmiÅŸ)
        lambda x: x * np.exp(-x * x),
        lambda x: np.log1p(np.abs(x)),
        lambda x: np.sqrt(np.abs(x) + 1e-10),
        lambda x: 1 / (1 + np.exp(-x)),
        lambda x: np.exp(-x * x / 2),
        # Ã–zel kombinasyonlar (geniÅŸletilmiÅŸ)
        lambda x: np.sin(x * np.pi) * np.tanh(x * 2.71828),
        lambda x: np.arctan(x * 3.14159) * np.log1p(np.abs(x)),
        lambda x: np.sin(x * 1.61803) + np.cos(x * 2.41421),
        lambda x: np.exp(-x) * np.sin(x * np.pi),
        lambda x: np.tanh(np.sin(x * np.pi) * np.cos(x * 1.61803)),
        # GÃ¼venlik odaklÄ±
        lambda x: (np.sin(x) + np.cos(x * 1.61803)) / 2,
        lambda x: np.arctan(np.tanh(x * 2.71828) * 3.14159),
        lambda x: np.log1p(np.abs(np.sin(x * np.pi))),
        lambda x: np.sqrt(np.abs(np.cos(x * 1.32472)) + 1e-10),
        # Kriptografik primitifler
        lambda x: ((x * 0x9E3779B97F4A7C15) & 0xFFFFFFFFFFFFFFFF) / 0xFFFFFFFFFFFFFFFF,
        lambda x: ((x * 0x6A09E667F3BCC908) & 0xFFFFFFFFFFFFFFFF) / 0xFFFFFFFFFFFFFFFF,
        lambda x: ((x * 0x9E3779B97F4A7C15) % (1<<64)) / (1<<64),  # Golden ratio rot
        lambda x: np.modf(x * 11400714819323198485)[0],  # PCG rotasyon sabiti
        # Oktonyonik (non-associative)
        lambda x: np.sin(x) * np.cos(x * 0.7071) - np.cos(x) * np.sin(x * 0.7071),  # ijk benzeri
        lambda x: np.tanh(x) * np.sin(x * np.sqrt(2)),
        lambda x: (np.sin(x) + np.cos(x * 1.618) + np.tanh(x * 2.718) + np.arctan(x * 3.14159)) / 4,  # 4D quaternion benzeri
        # Kaos & Fraktal
        lambda x: 4 * x * (1 - x),  # Logistic map (r=4)
        lambda x: x * 3.999999 - np.floor(x * 3.999999),  # Fractional part
        lambda x: np.tanh(x / 137.035999) * np.sin(x * np.sqrt(2)),
        # AÅŸkÄ±n Fonksiyonlar
        lambda x: np.sin(np.pi * x) * np.exp(-np.abs(x)),  # Ï€+e karÄ±ÅŸÄ±mÄ±
        lambda x: np.arctan(x * np.e) / (np.pi / 2),
        # Fiziksel
        lambda x: np.tanh(x / 137.035999) * np.sin(x),  # Ä°nce yapÄ± sabiti
        # Fraktal ZamanÄ±
        lambda x: np.sin(2*np.log2(np.abs(x)+1e-10) * np.pi),
    ]

    @staticmethod
    def get_constant(name: str, offset: float = 0) -> float:
        """GÃ¼venlik sabiti al"""
        const_val = MathematicalSecurityBases.SECURITY_CONSTANTS.get(
            name, MathematicalSecurityBases.SECURITY_CONSTANTS["kha_pi"]
        )
        return const_val + offset

    @staticmethod
    @SecurityLayers.timing_attack_protection
    def apply_transformations(value: float, rounds: int = 5) -> float:
        """Ã‡oklu dÃ¶nÃ¼ÅŸÃ¼m uygula (zaman sabit)"""
        for i in range(rounds):
            idx = (int(value * 1e12) + i) % len(
                MathematicalSecurityBases.TRANSFORMATIONS
            )
            value = MathematicalSecurityBases.TRANSFORMATIONS[idx](value)
        return value

    @staticmethod
    def generate_secure_matrix(seed: int, size: int = 512) -> np.ndarray:
        """GÃ¼venli matris oluÅŸtur"""
        seed = seed & 0xFFFFFFFF  # 32-bit sÄ±nÄ±rÄ±
        rng = np.random.RandomState(seed)

        # Ã‡oklu daÄŸÄ±lÄ±mlardan matris oluÅŸtur
        matrices = [
            rng.uniform(0, 1, size),
            rng.normal(0.5, 0.1, size),
            rng.logistic(0.5, 0.05, size),
            np.sin(rng.random(size) * np.pi),
            np.tanh(rng.random(size) * 2),
        ]

        # Matrisleri birleÅŸtir
        combined = np.zeros(size)
        for i, mat in enumerate(matrices):
            weight = MathematicalSecurityBases.get_constant(
                list(MathematicalSecurityBases.SECURITY_CONSTANTS.keys())[
                    i % len(MathematicalSecurityBases.SECURITY_CONSTANTS)
                ]
            )
            combined = (combined + mat * weight) % 1.0

        return combined


# ============================================================
# KHA Ã‡EKÄ°RDEÄÄ° (GÃœÃ‡LENDÄ°RÄ°LMÄ°Å)
# ============================================================
class FortifiedKhaCore:
    """Fortified KHA Hash Core"""

    def __init__(self, config: FortifiedConfig):
        self.config = config

        # More specific type hints
        self.stats: Dict[str, Union[int, float]] = {
            "hash_count": 0,
            "total_time": 0.0,
            "mixing_time": 0.0,
            "compression_time": 0.0,
            "conversion_time": 0.0,
            "total_operations": 0,
            "kha_success": 0,
            "kha_fail": 0,
            "avalanche_score": 0.0,
            "security_operations": 0,
        }

        # String, list, dict deÄŸerleri iÃ§in ayrÄ± dictionary
        self.text_stats: Dict[str, str] = {}
        self.list_stats: Dict[str, list] = {}
        self.dict_stats: Dict[str, dict] = {}

        # Security state
        self._last_operation_time = 0
        self._operation_counter = 0

    @SecurityLayers.timing_attack_protection
    def _generate_kha_matrix(self, seed_data: bytes) -> np.ndarray:
        """Generate matrix from enhanced KHA values"""
        self.stats["total_operations"] += 1
        self.stats["security_operations"] += 1

        values = []

        # Seed preparation
        seed_int = int.from_bytes(seed_data[:16], "big")
        seed_int = SecurityLayers.arithmetic_blinding(seed_int)

        rng = random.Random(seed_int)

        # Types to be used - safe and tested types
        SAFE_TYPES = []
        TYPE_REQUIREMENTS = {}

        # Tipleri ve gereksinimlerini tanÄ±mla
        if KHA_AVAILABLE:
            try:
                # Ã‡ALIÅAN TÄ°PLER (test edilmiÅŸ ve gÃ¼venli)

                # 1. Basit SayÄ±lar
                SAFE_TYPES.extend([TYPE_POSITIVE_REAL, TYPE_NEGATIVE_REAL, TYPE_FLOAT])
                TYPE_REQUIREMENTS[TYPE_POSITIVE_REAL] = {
                    "format": "simple_float",
                    "components": 1,
                }
                TYPE_REQUIREMENTS[TYPE_NEGATIVE_REAL] = {
                    "format": "simple_float",
                    "components": 1,
                }
                TYPE_REQUIREMENTS[TYPE_FLOAT] = {
                    "format": "simple_float",
                    "components": 1,
                }

                # 2. Complex
                SAFE_TYPES.extend([TYPE_COMPLEX, TYPE_NEUTROSOPHIC_COMPLEX])
                TYPE_REQUIREMENTS[TYPE_COMPLEX] = {"format": "complex", "components": 2}
                TYPE_REQUIREMENTS[TYPE_NEUTROSOPHIC_COMPLEX] = {
                    "format": "complex",
                    "components": 2,
                }

                # 3. Quaternion
                SAFE_TYPES.append(TYPE_QUATERNION)
                TYPE_REQUIREMENTS[TYPE_QUATERNION] = {
                    "format": "quaternion",
                    "components": 4,
                }

                # 4. Octonion
                SAFE_TYPES.append(TYPE_OCTONION)
                TYPE_REQUIREMENTS[TYPE_OCTONION] = {
                    "format": "octonion",
                    "components": 8,
                }

                # 5. Rational
                SAFE_TYPES.append(TYPE_RATIONAL)
                TYPE_REQUIREMENTS[TYPE_RATIONAL] = {
                    "format": "rational_int",
                    "components": 2,
                }

                # 6. Neutrosophic
                SAFE_TYPES.append(TYPE_NEUTROSOPHIC)
                TYPE_REQUIREMENTS[TYPE_NEUTROSOPHIC] = {
                    "format": "neutrosophic",
                    "components": 3,
                }

                # 7. Hyperreal
                SAFE_TYPES.append(TYPE_HYPERREAL)
                TYPE_REQUIREMENTS[TYPE_HYPERREAL] = {
                    "format": "hyperreal_simple",
                    "components": 2,
                }

                # 8. Bicomplex
                SAFE_TYPES.append(TYPE_BICOMPLEX)
                TYPE_REQUIREMENTS[TYPE_BICOMPLEX] = {
                    "format": "bicomplex",
                    "components": 4,
                }

                # 9. Dual ve Split Complex
                try:
                    SAFE_TYPES.extend([TYPE_DUAL, TYPE_SPLIT_COMPLEX])
                    TYPE_REQUIREMENTS[TYPE_DUAL] = {"format": "dual", "components": 2}
                    TYPE_REQUIREMENTS[TYPE_SPLIT_COMPLEX] = {
                        "format": "split_complex",
                        "components": 2,
                    }
                except NameError:
                    pass

            except NameError as e:
                logger.warning(f"Type name error: {e}")
                # VarsayÄ±lan gÃ¼venli tipler
                SAFE_TYPES = [1, 2, 3, 4, 6, 8, 10, 11]
                for t in SAFE_TYPES:
                    TYPE_REQUIREMENTS[t] = {"format": "simple_float", "components": 2}
        else:
            # KHA yoksa
            SAFE_TYPES = list(range(1, 13))
            for t in SAFE_TYPES:
                TYPE_REQUIREMENTS[t] = {"format": "simple_float", "components": 2}

        # Her hash iÃ§in 5-8 farklÄ± tÃ¼r kullan
        num_types_to_use = min(rng.randint(5, 8), len(SAFE_TYPES))
        selected_types = rng.sample(SAFE_TYPES, num_types_to_use)

        # Ä°terasyon derinliÄŸi (artÄ±rÄ±ldÄ±)
        iteration_depth = rng.randint(16, 24)

        logger.debug(
            f"Using {num_types_to_use} KHA types from {len(SAFE_TYPES)} safe types"
        )

        for type_idx, kececi_type in enumerate(selected_types):
            # components_needed_int'i baÅŸta tanÄ±mla (default deÄŸer)
            components_needed_int = 3  # VarsayÄ±lan deÄŸer

            try:
                type_info = TYPE_REQUIREMENTS.get(
                    kececi_type, {"format": "simple_float", "components": 2}
                )
                format_type = type_info["format"]
                components_needed = type_info["components"]

                # components_needed_int'i gÃ¼venli bir ÅŸekilde hesapla
                if components_needed is None:
                    components_needed_int = 3  # VarsayÄ±lan deÄŸer
                elif isinstance(components_needed, (int, np.integer)):
                    components_needed_int = int(components_needed)
                elif isinstance(components_needed, float):
                    components_needed_int = int(round(components_needed))
                elif hasattr(components_needed, "__int__"):
                    components_needed_int = int(components_needed)
                else:
                    try:
                        components_needed_int = int(float(str(components_needed)))
                    except (ValueError, TypeError):
                        components_needed_int = 3  # VarsayÄ±lan deÄŸer

                if KHA_AVAILABLE and kn is not None:
                    # Matematiksel sabitler
                    const_names = list(
                        MathematicalSecurityBases.SECURITY_CONSTANTS.keys()
                    )
                    const_name = rng.choice(const_names)
                    base_val = MathematicalSecurityBases.get_constant(const_name)

                    # Format'a gÃ¶re baÅŸlangÄ±Ã§ deÄŸeri oluÅŸtur
                    if format_type == "simple_float":
                        float_val = base_val * (1 + rng.random() * 0.05)
                        start_val = str(float_val)
                        add_val = str(float_val * 0.0001)

                        if kececi_type == TYPE_NEGATIVE_REAL:
                            start_val = "-" + start_val
                            add_val = "-" + add_val

                    elif format_type == "complex":
                        real_part = base_val * (1 + rng.random() * 0.04)
                        imag_const = "kha_e" if const_name == "kha_pi" else "kha_pi"
                        imag_base = MathematicalSecurityBases.get_constant(imag_const)
                        imag_part = imag_base * (1 + rng.random() * 0.03)
                        start_val = f"{real_part}+{imag_part}j"
                        add_val = f"{real_part*0.0005}+{imag_part*0.0005}j"

                    elif format_type == "quaternion":
                        parts = []
                        quat_consts = [
                            "kha_pi",
                            "kha_e",
                            "golden_ratio",
                            "silver_ratio",
                        ]
                        for i in range(4):
                            const_name_i = quat_consts[i % len(quat_consts)]
                            const_val = MathematicalSecurityBases.get_constant(
                                const_name_i
                            )
                            part_val = const_val * (1 + rng.random() * 0.02)
                            parts.append(str(part_val))
                        start_val = ",".join(parts)
                        add_val = ",".join([str(float(p) * 0.0001) for p in parts])

                    elif format_type == "octonion":
                        parts = []
                        oct_consts = [
                            "kha_pi",
                            "kha_e",
                            "golden_ratio",
                            "silver_ratio",
                            "apery",
                            "catalan",
                            "euler_mascheroni",
                            "khinchin",
                        ]
                        for i in range(8):
                            const_idx = i % len(oct_consts)
                            const_val = MathematicalSecurityBases.get_constant(
                                oct_consts[const_idx]
                            )
                            part_val = const_val * (1 + rng.random() * 0.015)
                            parts.append(str(part_val))
                        start_val = ",".join(parts)
                        add_val = ",".join([str(float(p) * 0.00008) for p in parts])

                    elif format_type == "rational_int":
                        numerator = int(base_val * 1000) + rng.randint(1, 100)
                        denominator = int(
                            MathematicalSecurityBases.get_constant("kha_e") * 1000
                        ) + rng.randint(1, 100)
                        start_val = f"{numerator}/{denominator}"
                        add_val = f"{max(1, int(numerator * 0.001))}/{denominator}"

                    elif format_type == "neutrosophic":
                        t_val = base_val * 0.8
                        i_val = 0.3 + rng.random() * 0.4
                        f_val = 0.1 + rng.random() * 0.3
                        start_val = f"{t_val},{i_val},{f_val}"
                        add_val = f"{t_val*0.001},{i_val*0.001},{f_val*0.001}"

                    elif format_type == "hyperreal_simple":
                        standard = base_val
                        infinitesimal = 0.000001 * (1 + type_idx * 0.1)
                        start_val = f"{standard}+{infinitesimal}"
                        add_val = f"{infinitesimal*0.1}"

                    elif format_type == "bicomplex":
                        real1 = base_val * (1 + rng.random() * 0.03)
                        imag1 = MathematicalSecurityBases.get_constant("kha_e") * (
                            1 + rng.random() * 0.03
                        )
                        real2 = MathematicalSecurityBases.get_constant(
                            "golden_ratio"
                        ) * (1 + rng.random() * 0.03)
                        imag2 = MathematicalSecurityBases.get_constant(
                            "silver_ratio"
                        ) * (1 + rng.random() * 0.03)
                        start_val = f"{real1}+{imag1}j,{real2}+{imag2}j"
                        add_val = f"{real1*0.0005}+{imag1*0.0005}j,{real2*0.0005}+{imag2*0.0005}j"

                    elif format_type == "dual":
                        real_part = base_val
                        dual_part = 0.000001 * (1 + type_idx * 0.05)
                        start_val = f"{real_part}+{dual_part}Îµ"
                        add_val = f"{dual_part*0.1}Îµ"

                    elif format_type == "split_complex":
                        real_part = base_val
                        split_part = (
                            MathematicalSecurityBases.get_constant("kha_e") * 0.1
                        )
                        start_val = f"{real_part}+{split_part}j"
                        add_val = f"{split_part*0.001}j"

                    # API Ã§aÄŸrÄ±sÄ±
                    seq = None
                    api_attempts = [
                        lambda: (
                            kn.get_with_params(
                                kececi_type_choice=kececi_type,
                                iterations=iteration_depth,
                                start_value_raw=start_val,
                                add_value_raw=add_val,
                                include_intermediate_steps=True,
                            )
                            if hasattr(kn, "get_with_params")
                            else None
                        ),
                        lambda: (
                            kn.get_with_params(
                                kececi_type=kececi_type,
                                iterations=iteration_depth,
                                start_value=start_val,
                                add_value=add_val,
                                include_intermediate_steps=False,
                            )
                            if hasattr(kn, "get_with_params")
                            else None
                        ),
                        lambda: (
                            kn.get(kececi_type, iteration_depth, start_val, add_val)
                            if hasattr(kn, "get")
                            else None
                        ),
                    ]

                    for attempt in api_attempts:
                        try:
                            seq = attempt()
                            if seq:
                                break
                        except:
                            continue

                    if seq:
                        num_values_to_extract = min(iteration_depth, len(seq), 12)

                        for val_idx in range(-num_values_to_extract, 0):
                            if val_idx < 0:
                                final_val = seq[val_idx]
                                extracted = self._extract_numerics(final_val)

                                # extracted'in numeric list olduÄŸundan emin ol
                                if not isinstance(extracted, (list, tuple)):
                                    extracted = [extracted]

                                # Ä°lk extend iÅŸlemi
                                extract_count = min(
                                    len(extracted), components_needed_int * 3
                                )
                                values.extend(extracted[:extract_count])

                                # Progress hesaplama
                                progress = float(val_idx + len(seq)) / float(len(seq))

                                # ModÃ¼lasyon iÃ§in
                                slice_count = min(len(extracted), components_needed_int)
                                for i in range(slice_count):
                                    val = extracted[i]
                                    try:
                                        # val'Ä± numeric'e Ã§evirmeye Ã§alÄ±ÅŸ
                                        num_val = (
                                            float(val)
                                            if not isinstance(
                                                val, (int, float, np.number)
                                            )
                                            else val
                                        )
                                        if progress > 0:
                                            modulated = num_val * (
                                                1 + np.sin(progress * np.pi * 2) * 0.15
                                            )
                                            values.append(float(modulated))
                                    except (ValueError, TypeError, AttributeError):
                                        continue

                        self.stats["kha_success"] += 1

                    else:
                        self.stats["kha_fail"] += 1
                        # components_needed_int artÄ±k tanÄ±mlÄ±
                        self._add_secure_fallback_values(
                            values, type_idx, components_needed_int, rng
                        )

                else:
                    self._add_secure_math_fallback_values(values, type_idx, rng)

            except Exception as e:
                logger.error(f"KHA matrix error for type {kececi_type}: {e}")
                self.stats["kha_fail"] += 1
                # components_needed_int artÄ±k tanÄ±mlÄ± (hata durumunda da varsayÄ±lan deÄŸerle)
                self._add_secure_fallback_values(
                    values, type_idx, components_needed_int, rng
                )

        # Matris iÅŸleme
        processed_matrix = self._process_matrix_values(
            values, seed_int, target_size=1024
        )

        logger.info(
            f"Generated KHA matrix: {len(processed_matrix)} values, "
            f"success: {self.stats['kha_success']}, fail: {self.stats['kha_fail']}"
        )

        return processed_matrix

    # def _add_secure_fallback_values(self, values, type_idx, components_needed, rng):
    def _add_secure_fallback_values(
        self, values: list, type_idx: int, components_needed: int, rng: random.Random
    ) -> None:
        """GÃ¼venli fallback deÄŸerleri ekle"""
        const_names = list(MathematicalSecurityBases.SECURITY_CONSTANTS.keys())

        for i in range(components_needed * 3):
            const_name = rng.choice(const_names)
            base_val = MathematicalSecurityBases.get_constant(const_name)
            variation = 0.08 * (1 + type_idx * 0.12 + i * 0.03)
            val = base_val * (1 + rng.random() * variation)

            transforms = [
                lambda x: x,
                lambda x: np.sin(x * np.pi * 0.618),
                lambda x: np.exp(-x * 0.15),
                lambda x: np.log1p(abs(x) * 10),
                lambda x: np.tanh(x * 1.5),
            ]

            transform_idx = (i + type_idx) % len(transforms)
            transformed = transforms[transform_idx](val)
            values.append(transformed)

    def _add_secure_math_fallback_values(self, values, type_idx, rng):
        """GÃ¼venli matematiksel fallback deÄŸerleri ekle"""
        consts_to_use = [
            "kha_pi",
            "kha_e",
            "golden_ratio",
            "silver_ratio",
            "plastic_number",
            "tribonacci_constant",
            "kececi_constant",
        ]

        for const_idx, const_name in enumerate(consts_to_use):
            base_val = MathematicalSecurityBases.get_constant(const_name)

            for var_idx in range(3):
                variation = 0.04 * (1 + type_idx * 0.2 + var_idx * 0.1)
                val = base_val * (1 + rng.random() * variation)

                values.extend(
                    [
                        val,
                        np.sin(val * np.pi * 1.618),
                        np.exp(-val * 0.08),
                        np.tanh(val * 0.2),
                        np.arctan(val * 5),
                    ]
                )

    @SecurityLayers.timing_attack_protection
    def _process_matrix_values(self, values, seed_int, target_size=1024):
        """DeÄŸerleri iÅŸle ve matrise dÃ¶nÃ¼ÅŸtÃ¼r (zaman sabit)"""
        if not values:
            for i in range(target_size):
                phase = i * 0.03
                val = MathematicalSecurityBases.get_constant("kha_pi", phase)
                values.append(val * (1 + np.sin(phase * 2) * 0.25))

        # BoyutlandÄ±rma
        if len(values) < target_size:
            current = list(values)
            while len(values) < target_size:
                idx = len(values) % len(current)
                base = current[idx % len(current)] if current else 1.0

                transform_idx = (len(values) // len(current)) % 6
                if transform_idx == 0:
                    new_val = base * (1 + np.sin(len(values) * 0.08) * 0.2)
                elif transform_idx == 1:
                    new_val = np.exp(base * 0.003)
                elif transform_idx == 2:
                    new_val = np.tanh(base * 0.03)
                elif transform_idx == 3:
                    new_val = base * 1.618033988749895
                elif transform_idx == 4:
                    new_val = np.arctan(base * 3)
                else:
                    new_val = np.log1p(abs(base))

                values.append(new_val)
        else:
            values = values[:target_size]

        # Numpy array'e dÃ¶nÃ¼ÅŸtÃ¼r
        values_array = np.array(values, dtype=np.float64)

        # GÃ¼venli normalizasyon
        min_val = np.min(values_array)
        max_val = np.max(values_array)
        if max_val - min_val > 1e-12:
            values_array = (values_array - min_val) / (max_val - min_val)
        else:
            values_array = np.zeros_like(values_array) + 0.5

        # GÃ¼venli karÄ±ÅŸtÄ±rma
        shuffle_seed = SecurityLayers.arithmetic_blinding(seed_int + 12345)
        shuffle_seed = shuffle_seed & 0xFFFFFFFF  # 32-bit sÄ±nÄ±rÄ±
        rng_shuffle = random.Random(shuffle_seed)
        indices = list(range(len(values_array)))
        rng_shuffle.shuffle(indices)

        final_matrix = values_array[indices]

        # Son non-lineer dÃ¶nÃ¼ÅŸÃ¼m
        final_matrix = np.sin(final_matrix * np.pi * 1.618033988749895)

        return final_matrix

    def _extract_numerics(self, kha_obj) -> List[float]:
        """KHA objesinden sayÄ±sal deÄŸerleri Ã§Ä±kar"""
        values = []

        # coeffs Ã¶zelliÄŸi
        if hasattr(kha_obj, "coeffs"):
            try:
                coeffs = kha_obj.coeffs
                if isinstance(coeffs, (list, tuple)):
                    values.extend([float(c) for c in coeffs[:128]])
            except:
                pass

        # Bilinen Ã¶zellikler
        numeric_attrs = [
            "w",
            "x",
            "y",
            "z",
            "real",
            "imag",
            "a",
            "b",
            "c",
            "d",
            "e",
            "f",
            "g",
            "h",
            "value",
            "magnitude",
            "norm",
            "abs",
            "modulus",
            "re",
            "im",
            "scalar",
            "vector",
        ]

        for attr in numeric_attrs:
            if hasattr(kha_obj, attr):
                try:
                    val = getattr(kha_obj, attr)
                    if isinstance(val, (int, float, complex)):
                        if isinstance(val, complex):
                            values.extend([val.real, val.imag])
                        else:
                            values.append(float(val))
                except:
                    pass

        # String temsili
        if not values:
            try:
                s = str(kha_obj)
                numbers = re.findall(r"[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?", s)
                values.extend([float(n) for n in numbers[:64]])
            except:
                pass

        # Final fallback
        if not values:
            values.append(MathematicalSecurityBases.get_constant("kececi_constant"))

        return values

    @SecurityLayers.timing_attack_protection
    def _fortified_mixing_pipeline(self, matrix: np.ndarray, salt: bytes) -> np.ndarray:
        """GÃ¼Ã§lendirilmiÅŸ karÄ±ÅŸtÄ±rma pipeline'Ä±"""
        # GÄ°RÄ°ÅTE KORUMA
        matrix = np.nan_to_num(matrix, nan=0.0, posinf=1.0, neginf=0.0)
        matrix = np.clip(matrix, 0.0, 1.0 - np.finfo(np.float64).eps)

        start_time = time.perf_counter()

        len(matrix)

        # 1. GELÄ°ÅMÄ°Å BAÅLANGIÃ‡ Ä°ÅLEMLERÄ°
        for norm_pass in range(3):  # 2 â†’ 3
            mean_val = np.mean(matrix)
            std_val = np.std(matrix)
            if std_val < 1e-12:
                std_val = 1.0

            matrix = (matrix - mean_val) / std_val

            min_val = np.min(matrix)
            max_val = np.max(matrix)
            if max_val - min_val > 1e-12:
                matrix = (matrix - min_val) / (max_val - min_val)
            else:
                matrix = np.zeros_like(matrix) + 0.5

            matrix = np.tanh(matrix * 2.5)  # 2.0 â†’ 2.5

        # 2. AVALANCHE-OPTÄ°MÄ°ZE KARIÅTIRMA KATMANLARI
        for layer in range(self.config.shuffle_layers):
            # a) GÃœÃ‡LÃœ NON-LÄ°NEER DÃ–NÃœÅÃœM
            matrix = self._avalanche_optimized_transform(matrix, layer, salt)

            # b) YÃœKSEK DÄ°FÃœZYON
            matrix = self._high_diffusion_transform(matrix, layer, salt)

            # c) KARMAÅIK PERMÃœTASYON
            matrix = self._complex_permutation(matrix, layer, salt)

            # d) AVALANCHE BOOST
            matrix = self._enhanced_avalanche_boost(matrix, layer, salt)

            # e) BÄ°T MÄ°KSERÄ°
            if layer % 2 == 0:
                matrix = self._bit_mixer_transform(matrix, layer, salt)

            # f) GÃœVENLÄ°K KATMANI
            if layer % 3 == 0:
                matrix = self._security_layer_transform(matrix, layer, salt)

        # 3. POST-PROCESSING AVALANCHE ENHANCEMENT
        matrix = self._post_avalanche_enhancement(matrix, salt)

        # 4. Diffusion Mix
        if self.config.enable_diffusion_mix:
            matrix = self._secure_diffusion_mix(matrix, salt)

        # 5. FINAL NORMALIZATION
        matrix = self._final_avalanche_normalization(matrix)

        # 6. EK GÃœVENLÄ°K KATMANI
        matrix = self._extra_security_layer(matrix, salt)

        # 7. QUANTUM RESISTANT MIX
        if self.config.enable_quantum_mix:
            matrix = self._quantum_avalanche_mix(matrix, salt)

        # Type-safe stats updates
        elapsed_ms = (time.perf_counter() - start_time) * 1000

        # Update mixing_time safely
        mixing_time = self.stats.get("mixing_time")
        if isinstance(mixing_time, (int, float)):
            self.stats["mixing_time"] = float(mixing_time) + elapsed_ms
        else:
            # If it's not numeric, initialize it
            self.stats["mixing_time"] = elapsed_ms

        # Update security_operations safely
        sec_ops = self.stats.get("security_operations")
        if isinstance(sec_ops, int):
            self.stats["security_operations"] = sec_ops + 1
        else:
            # If it's not an int, initialize it
            self.stats["security_operations"] = 1

        # Ã‡IKIÅTA KORUMA
        matrix = np.nan_to_num(matrix, nan=0.0, posinf=0.999999, neginf=0.0)
        matrix = np.clip(matrix, 0.0, 1.0 - np.finfo(np.float64).eps)
        return matrix

    def _security_layer_transform(
        self, matrix: np.ndarray, layer: int, salt: bytes
    ) -> np.ndarray:
        """Ek gÃ¼venlik katmanÄ± dÃ¶nÃ¼ÅŸÃ¼mÃ¼"""
        result = matrix.copy()
        n = len(result)

        # Yan kanal korumasÄ± iÃ§in kÃ¶rleme
        blinding_factor = np.sin(layer * 0.317) * 0.01
        result = (result + blinding_factor) % 1.0

        # Bellek sertleÅŸtirme
        if self.config.memory_hardening and n >= 256:
            memory_block = np.zeros((16, 16))
            for i in range(16):
                for j in range(16):
                    idx = (i * 16 + j) % n
                    memory_block[i, j] = result[idx]

            # Bellek Ã¼zerinde iÅŸlemler
            for _ in range(self.config.time_cost):
                memory_block = np.sin(memory_block * np.pi)
                memory_block = np.tanh(memory_block * 1.5)

            # Geri yÃ¼kle
            for i in range(16):
                for j in range(16):
                    idx = (i * 16 + j) % n
                    result[idx] = memory_block[i, j] % 1.0

        return result

    def _extra_security_layer(self, matrix: np.ndarray, salt: bytes) -> np.ndarray:
        """Ek gÃ¼venlik katmanÄ±"""
        result = matrix.copy()
        n = len(result)

        # Åifreleme katmanÄ±
        if self.config.enable_encryption_layer:
            for round_num in range(self.config.encryption_rounds):
                # Basit Feistel benzeri ÅŸifreleme
                if n >= 2:
                    half = n // 2
                    left = result[:half]
                    right = result[half : 2 * half]

                    # Round fonksiyonu
                    round_key = np.sin(np.arange(half) * 0.1 + round_num * 0.5)
                    f_result = np.tanh((left + round_key) * 1.5)

                    # Feistel iÅŸlemi
                    new_right = (left + f_result) % 1.0
                    new_left = right

                    result[:half] = new_left
                    result[half : 2 * half] = new_right

        # Sabit zaman korumasÄ±
        constant_time_noise = np.sin(np.arange(n) * 0.05) * 0.001
        result = (result + constant_time_noise) % 1.0

        return result

    def _avalanche_optimized_transform(
        self, matrix: np.ndarray, layer: int, salt: bytes
    ) -> np.ndarray:
        """Avalanche iÃ§in optimize edilmiÅŸ non-lineer dÃ¶nÃ¼ÅŸÃ¼m"""
        result = matrix.copy()
        n = len(result)

        transforms = [
            lambda x: np.sin(x * np.pi * (1.618033988749895 + layer * 0.015)),
            lambda x: np.sin(x * x * np.pi * 2.5),
            lambda x: np.sin(np.exp(np.clip(x, -6, 6))),
            lambda x: np.tanh(x * (3.141592653589793 + layer * 0.025)),
            lambda x: np.sinh(np.clip(x, -4, 4)) / (np.cosh(np.clip(x, -4, 4)) + 1e-12),
            lambda x: x * np.exp(-x * x * 2.5),
            lambda x: np.arctan(x * (15 + layer)),
            lambda x: np.log1p(np.abs(x) + 1e-12) * np.sign(x),
            lambda x: np.sqrt(np.abs(x) + 1e-12) * np.sign(x),
            lambda x: np.sin(x * 2.71828) * np.tanh(x * 3.14159),
            lambda x: np.arctan(x * 7.0) * np.log1p(np.abs(x) + 1e-8),
            lambda x: np.sin(x * 1.61803) + np.cos(x * 2.41421) - np.tanh(x * 1.32472),
            lambda x: np.exp(-x * x / 2) * np.sin(x * np.pi),
            lambda x: np.tanh(np.sin(x * np.pi) * np.cos(x * 1.61803)),
        ]

        salt_int = int.from_bytes(salt[:4], "big") if len(salt) >= 4 else layer
        num_transforms = 5 + (salt_int % 6)  # 5-10 transform

        for i in range(num_transforms):
            idx = (salt_int + i * 17 + layer * 19) % len(transforms)
            result = transforms[idx](result)

            if i % 2 == 0:
                noise_freq = 2.5 + i * 0.4 + layer * 0.15
                noise_phase = salt_int / 10000.0
                noise = np.sin(np.arange(n) * noise_freq + noise_phase) * 0.015
                result = (result + noise) % 1.0

        return result

    def _high_diffusion_transform(
        self, matrix: np.ndarray, layer: int, salt: bytes
    ) -> np.ndarray:
        """YÃ¼ksek difÃ¼zyon dÃ¶nÃ¼ÅŸÃ¼mÃ¼"""
        n = len(matrix)
        result = matrix.copy()

        diffusion_factors = np.array(
            [
                1.618033988749895,  # Ï†
                2.414213562373095,  # Î´_s
                1.324717957244746,  # Ïˆ
                3.141592653589793,  # Ï€
                2.718281828459045,  # e
                1.839286755214161,  # Tribonacci
                1.465571231876768,  # Supergolden
            ],
            dtype=np.float64,
        )

        salt_len = len(salt)
        salt_array = (
            np.frombuffer(salt, dtype=np.uint8)
            if salt_len > 0
            else np.array([], dtype=np.uint8)
        )

        for diff_round in range(self.config.diffusion_rounds):
            # Ä°leri difÃ¼zyon (forward diffusion)
            for i in range(1, n):
                factor_idx = (i + diff_round + layer) % len(diffusion_factors)
                factor = diffusion_factors[factor_idx]

                # Calculate salt effect
                salt_effect = 0.0
                if salt_len > 0:
                    salt_idx = (i + diff_round) % salt_len
                    salt_effect = float(salt_array[salt_idx]) / 1024.0

                result[i] = (
                    result[i] + result[i - 1] * factor * (1.0 + salt_effect)
                ) % 1.0

            # Geri difÃ¼zyon (backward diffusion)
            for i in range(n - 2, -1, -1):
                factor_idx = (i + diff_round) % len(diffusion_factors)
                factor = 1.0 / diffusion_factors[factor_idx]
                result[i] = (result[i] + result[i + 1] * factor) % 1.0

            # Ã‡apraz mixing (cross mixing)
            if n > 8:
                step = n // 16 if n >= 32 else 2
                for i in range(0, n - step, step):
                    j = i + step
                    if j < n:
                        avg = (result[i] + result[j]) / 2.0
                        mix_strength = 0.35 + np.sin(diff_round * 0.5) * 0.1
                        result[i] = (
                            result[i] * (1.0 - mix_strength) + avg * mix_strength
                        ) % 1.0
                        result[j] = (
                            result[j] * (1.0 - mix_strength) + avg * mix_strength
                        ) % 1.0

        return result

    def _complex_permutation(
        self, matrix: np.ndarray, layer: int, salt: bytes
    ) -> np.ndarray:
        """KarmaÅŸÄ±k permÃ¼tasyon"""
        n = len(matrix)

        # 1. Block permÃ¼tasyon
        block_size = max(8, n // 32)
        indices = []
        for block_start in range(0, n, block_size):
            block_end = min(block_start + block_size, n)
            block_indices = list(range(block_start, block_end))

            seed_val = int.from_bytes(salt[:4], "big") + layer + block_start
            rng = random.Random(seed_val & 0xFFFFFFFF)
            rng.shuffle(block_indices)
            indices.extend(block_indices)

        result1 = matrix[indices]

        # 2. Bit-reversal permÃ¼tasyon
        indices2 = []
        for i in range(n):
            rev = 0
            temp = i
            bits = int(np.log2(max(n, 1))) + 2
            for j in range(bits):
                rev = (rev << 1) | (temp & 1)
                temp >>= 1
            indices2.append(rev % n)
        result2 = matrix[indices2]

        # 3. Random walk permÃ¼tasyon
        indices3 = list(range(n))
        seed_val = int.from_bytes(salt[4:8], "big") if len(salt) >= 8 else layer
        rng = random.Random(seed_val & 0xFFFFFFFF)

        for i in range(n):
            step = rng.randint(-7, 7)
            new_pos = (i + step) % n
            indices3[i], indices3[new_pos] = indices3[new_pos], indices3[i]

        result3 = matrix[indices3]

        # 4. Matrix permÃ¼tasyon
        indices4 = []
        if n >= 16:
            size = int(np.sqrt(n))
            if size * size < n:
                size += 1

            matrix_indices = np.arange(n).reshape((size, size))
            for i in range(size):
                if i % 2 == 0:
                    matrix_indices[i] = np.roll(matrix_indices[i], i)
                else:
                    matrix_indices[i] = np.roll(matrix_indices[i], -i)

            indices4 = matrix_indices.flatten()[:n].tolist()
            result4 = matrix[indices4]

            result = (result1 + result2 + result3 + result4) / 4.0
        else:
            result = (result1 + result2 + result3) / 3.0

        return result

    def _enhanced_avalanche_boost(
        self, matrix: np.ndarray, layer: int, salt: bytes
    ) -> np.ndarray:
        """GeliÅŸmiÅŸ avalanche boost"""
        result = matrix.copy()
        n = len(result)

        constants = [
            1.618033988749895,  # AltÄ±n oran
            2.414213562373095,  # GÃ¼mÃ¼ÅŸ oran
            3.141592653589793,  # Pi
            2.718281828459045,  # e
            1.324717957244746,  # Plastik sayÄ±
            1.839286755214161,  # Tribonacci
            1.465571231876768,  # Supergolden
            2.236067977499790,  # âˆš5
        ]

        const_idx = layer % len(constants)
        const1 = constants[const_idx]
        const2 = constants[(const_idx + 1) % len(constants)]
        const3 = constants[(const_idx + 2) % len(constants)]

        # Ã‡ok katmanlÄ± dÃ¶nÃ¼ÅŸÃ¼m
        result = np.sin(result * np.pi * const1)
        result = np.tanh(result * const2)
        result = 1.0 / (1.0 + np.exp(-result * 3.0 + 1.5))  # 2.5 â†’ 3.0

        # Ek non-lineer katman
        result = np.sin(result * np.pi * const3)

        # KontrollÃ¼ pertÃ¼rbasyon
        if len(salt) >= 8:
            salt_int = int.from_bytes(salt[:8], "big")
            # Seed'i 32-bit aralÄ±ÄŸÄ±na sÄ±nÄ±rla
            seed_value = (salt_int + layer) & 0xFFFFFFFF
            rng = np.random.RandomState(seed_value)
            perturbation = rng.randn(n) * 0.02  # 0.015 â†’ 0.02
            result = (result + perturbation) % 1.0

        # Final iyileÅŸtirme
        for i in range(n):
            val = result[i]
            if val < 0.1:
                result[i] = np.sqrt(val + 0.005)
            elif val > 0.9:
                result[i] = 1.0 - np.sqrt(1.0 - val + 0.005)

        # Normalizasyon
        min_val = np.min(result)
        max_val = np.max(result)
        if max_val - min_val > 1e-12:
            result = (result - min_val) / (max_val - min_val)

        return np.clip(result, 0.0, 1.0)

    def _bit_mixer_transform(
        self, matrix: np.ndarray, layer: int, salt: bytes
    ) -> np.ndarray:
        """Bit seviyesinde mixing"""
        n = len(matrix)
        result = matrix.copy()

        for i in range(0, n - 1, 2):
            a = result[i]
            b = result[i + 1]

            # Ã‡eÅŸitli bit operasyonlarÄ±
            xor_like = (a * 0.6 + b * 0.4) % 1.0
            and_like = np.minimum(a, b)
            or_like = np.maximum(a, b)
            nand_like = 1.0 - and_like
            nor_like = 1.0 - or_like

            rotate = (a * 0.3 + b * 0.7) % 1.0

            if len(salt) > 0:
                salt_byte = salt[(i + layer) % len(salt)]
                selector = salt_byte % 8

                if selector == 0:
                    result[i] = xor_like
                    result[i + 1] = rotate
                elif selector == 1:
                    result[i] = and_like
                    result[i + 1] = or_like
                elif selector == 2:
                    result[i] = nand_like
                    result[i + 1] = nor_like
                elif selector == 3:
                    result[i] = (xor_like + and_like) % 1.0
                    result[i + 1] = (or_like + rotate) % 1.0
                elif selector == 4:
                    result[i] = (a * 0.2 + xor_like * 0.8) % 1.0
                    result[i + 1] = (b * 0.2 + rotate * 0.8) % 1.0
                elif selector == 5:
                    result[i] = np.sin((a + b) * np.pi)
                    result[i + 1] = np.cos((a - b) * np.pi)
                elif selector == 6:
                    result[i] = np.tanh(a * 2.0) * np.cos(b * np.pi)
                    result[i + 1] = np.tanh(b * 2.0) * np.sin(a * np.pi)
                else:
                    result[i] = (a * 0.4 + b * 0.3 + xor_like * 0.3) % 1.0
                    result[i + 1] = (b * 0.4 + a * 0.3 + rotate * 0.3) % 1.0

        return result

    def _post_avalanche_enhancement(
        self, matrix: np.ndarray, salt: bytes
    ) -> np.ndarray:
        """Post-processing avalanche enhancement"""
        result = matrix.copy()
        n = len(result)

        # Wavelet-like decomposition
        if n >= 8:
            temp = result.copy()

            levels = int(np.log2(n))
            if levels > 4:
                levels = 4

            for level in range(levels):
                step = 1 << level
                half = n // (2 * step)

                for i in range(half):
                    idx1 = i * 2 * step
                    idx2 = idx1 + step

                    if idx2 < n:
                        # Approximation coefficients
                        approx = (temp[idx1] + temp[idx2]) / 2.0
                        # Detail coefficients
                        detail = (temp[idx1] - temp[idx2]) / 2.0

                        # Non-linear processing
                        approx = np.tanh(approx * (2.0 + level * 0.5))
                        detail = np.arctan(detail * (5.0 + level))

                        temp[i] = approx
                        temp[half + i] = detail

            # Reconstruction
            for level in range(levels - 1, -1, -1):
                step = 1 << level
                half = n // (2 * step)

                for i in range(half):
                    idx1 = i * 2 * step
                    idx2 = idx1 + step

                    if idx2 < n:
                        a = temp[i]
                        d = temp[half + i]

                        result[idx1] = np.sin((a + d) * np.pi * (1 + level * 0.1))
                        result[idx2] = np.cos((a - d) * np.pi * (1 + level * 0.1))

        # Final perturbation
        if len(salt) >= 8:
            salt_int = int.from_bytes(salt[:8], "big")
            # Seed'i 32-bit aralÄ±ÄŸÄ±na sÄ±nÄ±rla
            seed_value = salt_int & 0xFFFFFFFF
            rng = np.random.RandomState(seed_value)
            avalanche_noise = rng.randn(n) * 0.008  # 0.005 â†’ 0.008
            result = (result + avalanche_noise) % 1.0

        return result

    def _secure_diffusion_mix(self, matrix: np.ndarray, salt: bytes) -> np.ndarray:
        """
        GÃ¼venli difÃ¼zyon tabanlÄ± mixing (NumPy overflow risksiz).
        Salt entegrasyonu ile rainbow table korumasÄ±.
        IEEE 754 bit pattern korunarak deterministik Ã§alÄ±ÅŸÄ±r.
        """
        # 1. Config'den shuffle_layers deÄŸerini gÃ¼venli ÅŸekilde al
        shuffle_layers = 3  # Default fallback
        if hasattr(self, 'config') and hasattr(self.config, 'shuffle_layers'):
            shuffle_layers = self.config.shuffle_layers
        elif hasattr(self, 'shuffle_layers'):
            shuffle_layers = self.shuffle_layers
        
        n = len(matrix)
        if n == 0:
            return matrix.copy()
        
        mask64 = 0xFFFFFFFFFFFFFFFF  # 64-bit mask
        
        # 2. Float64 â†’ uint64 bit pattern (Python integer listesi olarak)
        int_state = []
        for i in range(n):
            # IEEE 754 bit-for-bit kopya (deterministik)
            uint64_val = np.frombuffer(
                np.float64(matrix[i]).tobytes(), 
                dtype=np.uint64
            )[0]
            int_state.append(int(uint64_val))  # Python native integer
        
        # 3. Salt entegrasyonu - GÃœVENLÄ° VERSÄ°YON
        if salt and len(salt) > 0:
            # Max 32 byte salt
            salt_bytes = salt[:32]
            
            # Salt'Ä± 8 byte katlarÄ±na tamamla
            if len(salt_bytes) % 8 != 0:
                salt_bytes = salt_bytes.ljust((len(salt_bytes) + 7) // 8 * 8, b'\x00')
            
            salt_ints = []
            # GÃ¼venli unpack
            for i in range(0, len(salt_bytes), 8):
                chunk = salt_bytes[i:i+8]
                if len(chunk) == 8:
                    try:
                        # Big-endian unpack (daha gÃ¼venli)
                        val = int.from_bytes(chunk, 'big', signed=False)
                        salt_ints.append(val)
                    except:
                        # Fallback: manual
                        val = 0
                        for byte in chunk:
                            val = (val << 8) | byte
                        salt_ints.append(val)
            
            # Salt'Ä± XOR'la
            if salt_ints:
                for i in range(n):
                    int_state[i] ^= salt_ints[i % len(salt_ints)]
                    int_state[i] &= mask64
        
        # 4. ChaCha20 quarter round (64-bit adapted, Python integer arithmetic)
        def quarter_round(a: int, b: int, c: int, d: int) -> tuple:
            """NIST onaylÄ± difÃ¼zyon primitifi - overflow risksiz"""
            # SÃ¼tun 1
            a = (a + b) & mask64
            d = ((d ^ a) << 32) | ((d ^ a) >> 32)
            d &= mask64
            
            # SÃ¼tun 2
            c = (c + d) & mask64
            b = ((b ^ c) << 24) | ((b ^ c) >> 40)
            b &= mask64
            
            # SÃ¼tun 3
            a = (a + b) & mask64
            d = ((d ^ a) << 16) | ((d ^ a) >> 48)
            d &= mask64
            
            # SÃ¼tun 4
            c = (c + d) & mask64
            b = ((b ^ c) << 63) | ((b ^ c) >> 1)
            b &= mask64
            
            return a, b, c, d
        
        # 5. Diffusion katmanlarÄ± (shuffle_layers kadar)
        for _ in range(shuffle_layers):
            # Round-robin quarter rounds
            for i in range(0, n - 3, 4):
                if i + 3 < n:
                    a, b, c, d = quarter_round(
                        int_state[i],
                        int_state[i+1],
                        int_state[i+2],
                        int_state[i+3]
                    )
                    int_state[i], int_state[i+1], int_state[i+2], int_state[i+3] = a, b, c, d
            
            # Diagonal difÃ¼zyon (BLAKE3 tarzÄ±)
            for offset in (1, 5, 11):
                for i in range(n):
                    j = (i + offset) % n
                    int_state[i] ^= int_state[j]
                    int_state[i] &= mask64
        
        # 6. uint64 â†’ float64 normalizasyon ([0.0, 1.0) aralÄ±ÄŸÄ±nda)
        result = np.empty(n, dtype=np.float64)
        for i in range(n):
            # 53-bit precision koruma (IEEE 754 double)
            normalized = (int_state[i] >> 11) / 9007199254740992.0  # 2^53
            result[i] = normalized
        
        return result

    def _enhanced_byte_diffusion(self, byte_array: np.ndarray, salt: bytes) -> np.ndarray:
        """
        TaÅŸma hatasÄ±z, 3 katmanlÄ± kriptografik byte difÃ¼zyonu.
        GÃ¼venli aritmetik iÃ§in ara hesaplamalar Python int'leri ile yapÄ±lÄ±r.
        """
        if byte_array.size == 0:
            return byte_array.copy()
        
        # uint8 â†’ Python listesi (taÅŸma riskini ortadan kaldÄ±rÄ±r)
        result = byte_array.astype(np.uint8).tolist()
        n = len(result)
        
        # Salt yoksa veya boÅŸsa default salt kullan
        if not salt or len(salt) == 0:
            salt = b"\xab\xcd\xef\x01\x23\x45\x67\x89"
        
        # ğŸ”’ Katman 1: LCG karÄ±ÅŸtÄ±rma (taÅŸma korumalÄ±)
        for i in range(n):
            offset = (i * 0x9E3779B9) % n
            # Python int aritmetiÄŸi + mod 256
            result[i] = (int(result[i]) * 0x63686573 + offset) & 0xFF
        
        # ğŸ”’ Katman 2: Bit rotasyon + XOR
        for i in range(n):
            b = result[i]
            rotated = ((b << 3) | (b >> 5)) & 0xFF
            # Salt index'i gÃ¼venli hesapla
            salt_index = i % len(salt)
            salt_byte = salt[salt_index] if salt_index < len(salt) else 0xA5
            result[i] = rotated ^ 0xA5 ^ salt_byte
        
        # ğŸ”’ Katman 3: SHAKE-256 non-lineer karÄ±ÅŸtÄ±rma
        for i in range(0, n, 64):
            chunk_end = min(i + 64, n)
            chunk = bytes(result[i:chunk_end])
            hash_input = chunk + salt + i.to_bytes(4, 'big', signed=False)
            hash_out = hashlib.shake_256(hash_input).digest(chunk_end - i)
            for j, byte_val in enumerate(hash_out):
                result[i + j] ^= byte_val
        
        # Listeyi uint8 numpy array'ine geri Ã§evir
        return np.array(result, dtype=np.uint8)

    def _quantum_avalanche_mix(self, matrix: np.ndarray, salt: bytes) -> np.ndarray:
        """
        Kriptografik olarak saÄŸlam, tamamen deterministik avalanche mixing.
        GerÃ§ek kuantum direnÃ§lilik iÃ§in NIST PQC kullanÄ±n; bu fonksiyon gÃ¼Ã§lÃ¼ difÃ¼zyon saÄŸlar.
        
        Args:
            matrix: GiriÅŸ matrisi (herhangi bir ÅŸekil)
            salt: Salt bytes (en az 1 byte)
        
        Returns:
            KarÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ matris (orijinal ÅŸekil korunur)

        # Salt yoksa veya boÅŸsa default salt oluÅŸtur
        FIXED VERSION - salt length check removed
        """
        # Salt yoksa veya boÅŸsa default salt oluÅŸtur
        if not salt or len(salt) == 0:
            salt = b"\xab\xcd\xef\x01\x23\x45\x67\x89"
        
        # Salt'Ä± en az 1 byte yap (32 byte ÅŸartÄ± KALDIRILDI)
        if len(salt) < 1:
            salt = b"\x00"
        
        # Salt'Ä± 32 byte'a tamamla (opsiyonel, hata vermez)
        if len(salt) < 32:
            # Padding yap ama exception fÄ±rlatma
            salt_padded = salt + hashlib.sha256(salt).digest()
            salt = salt_padded[:32]
        
        flat = matrix.flatten().astype(np.float64)
        n = len(flat)
        if n == 0:
            return matrix.copy()
        
        # Round sayÄ±sÄ± (salt'tan tÃ¼retilmiÅŸ)
        round_seed = int.from_bytes(hashlib.sha3_256(salt + b"rounds").digest()[:4], 'big')
        rounds = 10 + (round_seed % 7)
        
        for round_idx in range(rounds):
            round_salt = hashlib.sha3_256(
                salt + round_idx.to_bytes(4, 'big', signed=False)
            ).digest()
            
            new_flat = np.empty_like(flat)
            
            for i in range(n):
                idx_salt = hashlib.shake_256(
                    round_salt + i.to_bytes(4, 'big', signed=False)
                ).digest(48)
                
                offsets = set()
                for j in range(12):
                    offset_val = int.from_bytes(idx_salt[j*4:(j+1)*4], 'big') % min(n, 1024)
                    if offset_val != 0:
                        offsets.add(offset_val)
                    if len(offsets) >= 7:
                        break
                
                neighbor_sum = 0.0
                weight_sum = 0.0
                for offset in offsets:
                    neighbor_idx = (i + offset) % n
                    weight = 1.0 / (1.0 + offset * 0.123456789)
                    neighbor_sum += flat[neighbor_idx] * weight
                    weight_sum += weight
                
                weighted_avg = neighbor_sum / weight_sum if weight_sum > 0 else flat[i]
                
                mix_input = f"{flat[i]:.15e},{weighted_avg:.15e},{round_idx},{i}".encode() + round_salt
                hash_out = hashlib.shake_256(mix_input).digest(8)
                hash_float = int.from_bytes(hash_out, 'big') / 2**64
                
                combined = (
                    flat[i] * 0.3819660112501051 +
                    weighted_avg * 0.2763932022500210 +
                    hash_float * 0.3416407864998739
                ) % 1.0
                
                new_flat[i] = (np.sin(combined * np.pi * 2.718281828459045) + 1.0) / 2.0
            
            flat = new_flat
            
            if round_idx % 3 == 1:
                shift = int.from_bytes(round_salt[:3], 'big') % n
                flat = np.roll(flat, shift)
        
        # ğŸ”‘ KRÄ°TÄ°K: Byte difÃ¼zyonunu gÃ¼venli ÅŸekilde entegre et (Ã–NCE final_salt)
        # float64 â†’ uint8 â†’ difÃ¼zyon â†’ float64 dÃ¶nÃ¼ÅŸÃ¼mÃ¼
        final_salt = hashlib.sha3_512(salt + b"final_diffusion").digest()  # Erken tanÄ±mla
        flat_bytes = flat.view(np.uint8)
        flat_bytes = self._enhanced_byte_diffusion(flat_bytes, final_salt)  # âœ… Åimdi gÃ¼venli
        flat = flat_bytes.view(np.float64)

        # Son koruma katmanÄ± (final_salt ile gÃ¼Ã§lendir)
        for i in range(n - 1):
            if np.isnan(flat[i]) or np.isnan(flat[i+1]):
                continue
            # final_salt'tan tÃ¼retilmiÅŸ carry factor (deterministik)
            carry_factor = int.from_bytes(final_salt[i % 64:i % 64 + 1], 'big') / 256 * 0.2
            carry = (flat[i] - 0.5) * carry_factor
            flat[i] = np.fmod(flat[i] - carry + 2.0, 1.0)  # +2.0 ile negatif/overflow gÃ¼venli [web:11]
            flat[i+1] = np.fmod(flat[i + 1] + carry + 2.0, 1.0)
        """
        flat_bytes = flat.view(np.uint8)
        flat_bytes = self._enhanced_byte_diffusion(flat_bytes, salt)
        flat = flat_bytes.view(np.float64)
        
        # Son koruma katmanÄ±
        final_salt = hashlib.sha3_512(salt + b"final_diffusion").digest()

        for i in range(n - 1):
            if np.isnan(flat[i]) or np.isnan(flat[i+1]):
                continue  # NaN'Ä± atla, yayÄ±lmayÄ± Ã¶nle
            carry = (flat[i] - 0.5) * 0.18
            flat[i] = np.fmod(flat[i] - carry + 1.0, 1.0)  # +1.0 ile negatif Ã¶nle
            flat[i+1] = np.fmod(flat[i + 1] + carry + 1.0, 1.0)
        """
        """
        final_salt = hashlib.sha3_512(salt + b"final_diffusion").digest() # Local variable `final_salt` is assigned to but never used
        for i in range(n - 1):
            carry = (flat[i] - 0.5) * 0.18
            flat[i] = (flat[i] - carry) % 1.0
            flat[i + 1] = (flat[i + 1] + carry) % 1.0 # arasÄ±ra hata veriyor
        """
        
        return flat.reshape(matrix.shape)

    """
    # yeniden yazÄ±lmalÄ±dÄ±r
    def _quantum_avalanche_mix(self, matrix: np.ndarray, salt: bytes) -> np.ndarray:
        #Kuantum direnÃ§li avalanche mixing
        result = matrix.copy()
        n = len(result)

        # Lattice-based mixing
        for i in range(n):
            neighbors: List[float] = []
            weights: List[float] = []

            for offset in [1, 3, 7, 15, 31, 63]:
                neighbor_idx = (i + offset) % n
                if neighbor_idx != i:
                    neighbors.append(result[neighbor_idx])
                    weight = 1.0 / (1 + offset * 0.1)
                    weights.append(weight)

            if neighbors and weights:
                # Convert to numpy arrays
                weights_array = np.array(weights)  # Use different variable name
                weights_array = weights_array / np.sum(weights_array)

                # Convert neighbors to numpy array for vectorized operations
                neighbors_array = np.array(neighbors)

                # Vectorized weighted average
                weighted_avg = np.sum(weights_array * neighbors_array)

                # Non-linear combination
                result[i] = np.sin((result[i] * 0.6 + weighted_avg * 0.4) * np.pi * 2)

        # Error correction
        for i in range(0, n - 1, 2):
            parity = (result[i] + result[i + 1]) % 1.0
            result[i] = (result[i] + parity * 0.15) % 1.0  # 0.1 â†’ 0.15
            result[i + 1] = (result[i + 1] + parity * 0.15) % 1.0

        return result
    """

    def _final_avalanche_normalization(self, matrix: np.ndarray) -> np.ndarray:
        """
        Professional final avalanche normalization.

        Design goals:
        - Do NOT generate avalanche artificially
        - Preserve entropy ordering (rank-based)
        - Reduce variance without centering bias
        - Maintain natural convergence to ~50% bit flip
        """

        # -------------------------------------------------
        # 1. Rank-based entropy-preserving normalization
        # -------------------------------------------------
        x = matrix.astype(np.float64, copy=True).ravel()

        # Rank normalization (distribution-free, monotonic)
        ranks = np.argsort(np.argsort(x))
        x = ranks / (len(x) - 1 + 1e-12)

        # -------------------------------------------------
        # 2. Orthogonal global mixing (energy preserving)
        # -------------------------------------------------
        # FFT-based phase-only mixing
        spectrum = np.fft.fft(x)
        phase = np.exp(1j * np.angle(spectrum))
        x = np.real(np.fft.ifft(np.abs(spectrum) * phase))

        # Re-normalize after orthogonal transform
        min_val = np.min(x)
        max_val = np.max(x)
        span = max_val - min_val

        if span > 1e-12:
            x = (x - min_val) / span
        else:
            x.fill(0.5)

        # -------------------------------------------------
        # 3. Chebyshev polynomial projection (low-order)
        # -------------------------------------------------
        # T1 Chebyshev: avoids oscillatory overfitting
        # x âˆˆ [0,1] â†’ smooth symmetric projection
        x = 0.5 * (1.0 - np.cos(np.pi * x))

        # -------------------------------------------------
        # 4. Final safety clamp
        # -------------------------------------------------
        x = np.clip(x, 0.0, 1.0)

        return x.reshape(matrix.shape)

    """
    def _final_avalanche_normalization(self, matrix: np.ndarray) -> np.ndarray:

        #Final avalanche normalization tuned for stable 48â€“52% range.
        #Avoids artificial centering, reduces variance.

        result = matrix.astype(np.float64, copy=True)

        for _ in range(2):  # 3 â†’ 2 (fazla tekrar daÄŸÄ±lÄ±mÄ± bozar)

            # 1. YumuÅŸak sigmoid (merkez = 0.5 civarÄ±)
            result = 1.0 / (1.0 + np.exp(-result * 4.5))

            # 2. DÃ¼ÅŸÃ¼k frekanslÄ± trigonometrik karÄ±ÅŸtÄ±rma
            # sin yerine cos kullanÄ±mÄ± faz kaymasÄ±nÄ± azaltÄ±r
            result = 0.5 * (1.0 - np.cos(result * np.pi))

            # 3. Stabil minâ€“max
            min_val = np.min(result)
            max_val = np.max(result)
            span = max_val - min_val

            if span > 1e-9:
                result = (result - min_val) / span
            else:
                result.fill(0.5)

            # 4. Hafif gamma dÃ¼zeltmesi (variance compression)
            result = np.power(result, 0.92)

        return np.clip(result, 0.0, 1.0)
    """

    """
    # Ã§ok sert ve dalgalanmaya neden oluyor.
    def _final_avalanche_normalization(self, matrix: np.ndarray) -> np.ndarray:
        #Final avalanche normalization
        result = matrix.copy()
        
        for pass_num in range(3):  # 2 â†’ 3
            # Sigmoid compression
            result = 1.0 / (1.0 + np.exp(-result * 7.0 + 3.5))  # 6.0 â†’ 7.0
            
            # Sine-based normalization
            result = np.sin(result * np.pi * 2.5)  # 2.0 â†’ 2.5
            
            # Min-max
            min_val = np.min(result)
            max_val = np.max(result)
            if max_val - min_val > 1e-12:
                result = (result - min_val) / (max_val - min_val)
            else:
                result = np.zeros_like(result) + 0.5
            
            # Non-linear stretch
            result = np.power(result, 1.0 / 1.2)  # 1.1 â†’ 1.2
        
        # Final clip
        result = np.clip(result, 0.0, 1.0)
        
        return result
    """

    @SecurityLayers.timing_attack_protection
    def _final_bytes_conversion(self, matrix: np.ndarray, salt: bytes) -> bytes:
        """
        Son byte dÃ¶nÃ¼ÅŸÃ¼mÃ¼ - NaN/Inf korumalÄ±, zaman sabit, kriptografik olarak gÃ¼venli.
        """
        # ğŸ”’ KRÄ°TÄ°K 1: NaN/Inf koruma + gÃ¼venli aralÄ±k kÄ±sÄ±tlama
        # matrix'i [0.0, 1.0) aralÄ±ÄŸÄ±na sÄ±kÄ± sÄ±kÄ±ya kÄ±sÄ±tla
        matrix = np.nan_to_num(
            matrix, 
            nan=0.0,           # NaN â†’ 0.0
            posinf=0.999999,   # +Inf â†’ 0.999999 (1.0'dan kÃ¼Ã§Ã¼k!)
            neginf=0.0         # -Inf â†’ 0.0
        )
        # Clamp to [0, 1 - epsilon] - kriptografik determinizm iÃ§in kritik
        EPS = np.finfo(np.float64).eps  # ~2.22e-16
        matrix = np.clip(matrix, 0.0, 1.0 - EPS)
        
        result = bytearray()
        salt_len = len(salt)
        
        # ğŸ”’ KRÄ°TÄ°K 2: GÃ¼venli dÃ¶nÃ¼ÅŸÃ¼m metodlarÄ± (overflow korumalÄ±)
        # TÃ¼m metodlar [0, 1) â†’ [0, 2^32) aralÄ±ÄŸÄ±nda gÃ¼venli dÃ¶nÃ¼ÅŸÃ¼m yapar
        methods: List[Callable[[float], int]] = [
            # YÃ¶ntem 1: DoÄŸrusal Ã¶lÃ§ekleme (en gÃ¼venli)
            lambda x: int(x * 4294967295.0) & 0xFFFFFFFF,
            
            # YÃ¶ntem 2: Trigonometrik (overflow yok - sin her zaman [-1,1])
            lambda x: int((np.sin(x * np.pi * 2.71828) + 1.0) * 2147483647.5) & 0xFFFFFFFF,
            
            # YÃ¶ntem 3: Logaritmik (clamp ile koruma)
            lambda x: int(np.log1p(np.clip(x, 0.0, 0.999999)) * 1234567890.0) & 0xFFFFFFFF,
            
            # YÃ¶ntem 4: Hiperbolik tanjant (doÄŸal sÄ±nÄ±rlama Â±1)
            lambda x: int((np.tanh((x - 0.5) * 8.0) + 1.0) * 2147483647.5) & 0xFFFFFFFF,
            
            # YÃ¶ntem 5: Polinomik karÄ±ÅŸtÄ±rma (overflow yok)
            lambda x: int(((x * 3.1415926535) % 1.0) * 4294967295.0) & 0xFFFFFFFF,
        ]
        
        # ğŸ”’ KRÄ°TÄ°K 3: Deterministik metod seÃ§imi (NaN korumalÄ±)
        for i, val in enumerate(matrix):
            # AdÄ±m 1: Val'i tekrar kontrol et (aÅŸÄ±rÄ± koruma)
            if np.isnan(val) or np.isinf(val):
                val = 0.0
            
            # AdÄ±m 2: Salt ile deterministik metod seÃ§imi
            if salt_len > 0:
                salt_idx = i % salt_len
                salt_byte = salt[salt_idx]
                # âš ï¸ KRÄ°TÄ°K: int() Ã¶ncesi gÃ¼venli Ã§arpma
                method_selector = int((val * 1000000.0) % 1000000)  # 1e6 â†’ taÅŸma yok
                method_idx = (method_selector + i + salt_byte) % len(methods)
            else:
                method_selector = int((val * 1000000.0) % 1000000)
                method_idx = (method_selector + i) % len(methods)
            
            # AdÄ±m 3: GÃ¼venli metod Ã§aÄŸrÄ±sÄ±
            try:
                int_val = methods[method_idx](val)
                # Ekstra koruma: int_val geÃ§ersizse sÄ±fÄ±rla
                if not (0 <= int_val <= 0xFFFFFFFF):
                    int_val = 0
            except (OverflowError, ValueError, FloatingPointError):
                int_val = 0  # GÃ¼venli varsayÄ±lan
            
            # AdÄ±m 4: XOR ile zincirleme (son 4 byte ile)
            if result:
                prev_bytes = result[-4:] if len(result) >= 4 else result.ljust(4, b'\x00')
                prev = struct.unpack("<I", prev_bytes[:4])[0]  # Little-endian (daha yaygÄ±n)
                int_val ^= prev
            
            # AdÄ±m 5: Ekstra karÄ±ÅŸtÄ±rma (MurmurHash3 benzeri)
            int_val = (int_val ^ (int_val >> 16)) & 0xFFFFFFFF
            int_val = (int_val * 0x85EBCA6B) & 0xFFFFFFFF
            int_val = (int_val ^ (int_val >> 13)) & 0xFFFFFFFF
            int_val = (int_val * 0xC2B2AE35) & 0xFFFFFFFF
            int_val = (int_val ^ (int_val >> 16)) & 0xFFFFFFFF
            
            # AdÄ±m 6: Salt ile son karÄ±ÅŸtÄ±rma
            if salt_len > 0:
                salt_pos = (i * 3) % salt_len
                salt_val = 0
                for j in range(4):
                    salt_val = (salt_val << 8) | salt[salt_pos % salt_len]
                    salt_pos = (salt_pos + 1) % salt_len
                int_val ^= salt_val
            
            # AdÄ±m 7: Byte ekleme (little-endian - timing attack koruma)
            result.extend(struct.pack("<I", int_val & 0xFFFFFFFF))
            
            # AdÄ±m 8: Hedef boyuta ulaÅŸtÄ±ysa dur
            target_bytes = getattr(self.config, "hash_bytes", 32)
            if len(result) >= target_bytes:
                result = result[:target_bytes]  # Kesinlikle hedef boyutta
                break
        
        # ğŸ”’ KRÄ°TÄ°K 4: Son kontrol - eÄŸer sonuÃ§ yetersizse BLAKE2b ile tamamla
        target_bytes = getattr(self.config, "hash_bytes", 32)
        if len(result) < target_bytes:
            # Eksik byte'larÄ± kriptografik olarak gÃ¼venli ÅŸekilde tamamla
            padding = hashlib.blake2b(
                bytes(result) + salt, 
                digest_size=target_bytes - len(result)
            ).digest()
            result.extend(padding)
        
        return bytes(result[:target_bytes])  # Kesinlikle hedef boyutta dÃ¶ndÃ¼r

    @SecurityLayers.timing_attack_protection
    def _secure_compress(self, data: bytes, target_bytes: int) -> bytes:
        """GÃ¼venli sÄ±kÄ±ÅŸtÄ±rma (zaman sabit)"""
        if len(data) <= target_bytes:
            return data.ljust(target_bytes, b"\x00")

        current = bytearray(data)

        for round_num in range(5):  # 3 â†’ 5
            max(target_bytes * 3, len(current) // 2)  # 2 â†’ 3
            compressed = bytearray()

            for i in range(0, len(current), 3):  # 2 â†’ 3
                if i + 2 < len(current):
                    val = (current[i] ^ current[i + 1] ^ current[i + 2]) + (
                        current[i] & current[i + 1] & current[i + 2]
                    )
                    compressed.append(val & 0xFF)
                elif i + 1 < len(current):
                    val = (current[i] ^ current[i + 1]) + (current[i] & current[i + 1])
                    compressed.append(val & 0xFF)
                else:
                    compressed.append(current[i])

            current = compressed

            # Mix with security constants
            for i in range(0, len(current), 8):
                if i + 7 < len(current):
                    chunk_bytes = current[i : i + 8]
                    if len(chunk_bytes) < 8:
                        chunk_bytes = chunk_bytes.ljust(8, b"\x00")
                    chunk = struct.unpack("Q", chunk_bytes)[0]
                    chunk ^= (chunk << 31) & 0xFFFFFFFFFFFFFFFF
                    chunk ^= chunk >> 11
                    chunk ^= (chunk << 7) & 0xFFFFFFFFFFFFFFFF
                    current[i : i + 8] = struct.pack("Q", chunk & 0xFFFFFFFFFFFFFFFF)

        # Final adjustment
        result = bytes(current[:target_bytes])
        if len(result) < target_bytes:
            pad_len = target_bytes - len(result)
            pad_value = sum(result) % 256
            result += bytes([(pad_value + i * 17) % 256 for i in range(pad_len)])

        return result


## PERFORMANS Ä°YÄ°LEÅTÄ°RME KODU:
class PerformanceOptimizedKhaCore(FortifiedKhaCore):
    """Performans optimize edilmiÅŸ KHA Ã§ekirdeÄŸi"""

    def _fortified_mixing_pipeline(self, matrix: np.ndarray, salt: bytes) -> np.ndarray:
        """GÃ¼Ã§lendirilmiÅŸ karÄ±ÅŸtÄ±rma pipeline'Ä±"""
        # GÄ°RÄ°ÅTE KORUMA
        matrix = np.nan_to_num(matrix, nan=0.0, posinf=1.0, neginf=0.0)
        matrix = np.clip(matrix, 0.0, 1.0 - np.finfo(np.float64).eps)

        start_time = time.perf_counter()

        len(matrix)

        # 1. GELÄ°ÅMÄ°Å BAÅLANGIÃ‡ Ä°ÅLEMLERÄ°
        for norm_pass in range(3):  # 2 â†’ 3
            mean_val = np.mean(matrix)
            std_val = np.std(matrix)
            if std_val < 1e-12:
                std_val = 1.0

            matrix = (matrix - mean_val) / std_val

            min_val = np.min(matrix)
            max_val = np.max(matrix)
            if max_val - min_val > 1e-12:
                matrix = (matrix - min_val) / (max_val - min_val)
            else:
                matrix = np.zeros_like(matrix) + 0.5

            matrix = np.tanh(matrix * 2.5)  # 2.0 â†’ 2.5

        # 2. AVALANCHE-OPTÄ°MÄ°ZE KARIÅTIRMA KATMANLARI
        for layer in range(self.config.shuffle_layers):
            # a) GÃœÃ‡LÃœ NON-LÄ°NEER DÃ–NÃœÅÃœM
            matrix = self._avalanche_optimized_transform(matrix, layer, salt)

            # b) YÃœKSEK DÄ°FÃœZYON
            matrix = self._high_diffusion_transform(matrix, layer, salt)

            # c) KARMAÅIK PERMÃœTASYON
            matrix = self._complex_permutation(matrix, layer, salt)

            # d) AVALANCHE BOOST
            matrix = self._enhanced_avalanche_boost(matrix, layer, salt)

            # e) BÄ°T MÄ°KSERÄ°
            if layer % 2 == 0:
                matrix = self._bit_mixer_transform(matrix, layer, salt)

            # f) GÃœVENLÄ°K KATMANI
            if layer % 3 == 0:
                matrix = self._security_layer_transform(matrix, layer, salt)

        # 3. POST-PROCESSING AVALANCHE ENHANCEMENT
        matrix = self._post_avalanche_enhancement(matrix, salt)

        # 4. Diffusion Mix
        if self.config.enable_diffusion_mix:
            matrix = self._secure_diffusion_mix(matrix, salt)

        # 5. FINAL NORMALIZATION
        matrix = self._final_avalanche_normalization(matrix)

        # 6. EK GÃœVENLÄ°K KATMANI
        matrix = self._extra_security_layer(matrix, salt)

        # 7. QUANTUM RESISTANT MIX
        if self.config.enable_quantum_mix:
            matrix = self._quantum_avalanche_mix(matrix, salt)

        # Type-safe stats updates
        elapsed_ms = (time.perf_counter() - start_time) * 1000

        # Update mixing_time safely
        mixing_time = self.stats.get("mixing_time")
        if isinstance(mixing_time, (int, float)):
            self.stats["mixing_time"] = float(mixing_time) + elapsed_ms
        else:
            # If it's not numeric, initialize it
            self.stats["mixing_time"] = elapsed_ms

        # Update security_operations safely
        sec_ops = self.stats.get("security_operations")
        if isinstance(sec_ops, int):
            self.stats["security_operations"] = sec_ops + 1
        else:
            # If it's not an int, initialize it
            self.stats["security_operations"] = 1

        # Ã‡IKIÅTA KORUMA
        matrix = np.nan_to_num(matrix, nan=0.0, posinf=0.999999, neginf=0.0)
        matrix = np.clip(matrix, 0.0, 1.0 - np.finfo(np.float64).eps)
        return matrix

    def _optimize_byte_distribution(
        self, matrix: np.ndarray, salt: bytes
    ) -> np.ndarray:
        """Byte daÄŸÄ±lÄ±mÄ±nÄ± optimize et"""
        result = matrix.copy()
        n = len(result)

        for round_num in range(self.config.byte_uniformity_rounds):
            # Byte benzeri dÃ¼zeltmeler
            salt_int = int.from_bytes(salt[:8], "big") if len(salt) >= 8 else round_num
            rng = np.random.RandomState(salt_int & 0xFFFFFFFF)

            # KÃ¼Ã§Ã¼k dÃ¼zeltmeler
            corrections = rng.randn(n) * self.config.byte_correction_factor * 0.01

            # Ã‡ok yÃ¼ksek/dÃ¼ÅŸÃ¼k deÄŸerleri dÃ¼zelt
            for i in range(n):
                val = result[i]
                if val < 0.1 or val > 0.9:
                    result[i] = 0.5 + (val - 0.5) * 0.8  # Merkeze Ã§ek

                result[i] = (result[i] + corrections[i]) % 1.0

        return result


# ============================================================
# ANA HASH SINIFI (GÃœÃ‡LENDÄ°RÄ°LMÄ°Å)
# ============================================================
class FortifiedKhaHash256:
    """Fortified KHA Hash (KHA-256) - Ultra Secure"""

    KEY_SIZE = 32  # 256-bit AES key
    NONCE_SIZE = 12  # AES-GCM iÃ§in Ã¶nerilen nonce boyutu

    def __init__(self, config: Optional[FortifiedConfig] = None, *, deterministic: bool = True):
        self._deterministic = deterministic  # Private attribute olarak sakla
        self.config = config or FortifiedConfig()
        self.core = FortifiedKhaCore(self.config)

        # Initialize metrics
        self.metrics: Dict[str, Any] = {
            "hash_count": 0,
            "total_time": 0.0,
            "avalanche_tests": [],
            "security_checks": 0,
            "cache_hits": 0,
            "cache_misses": 0,
        }

        # Security state
        self._last_hash_time: float = 0.0
        self._consecutive_hashes: int = 0
        self._cache: Dict[Tuple[bytes, bytes], str] = {}
        self._prev_matrix: Optional[np.ndarray] = None
        self._avalanche_history: List[float] = []
        self._last_used_salt: Optional[bytes] = None

    @property
    def deterministic(self):
        """Deterministic Ã¶zelliÄŸi iÃ§in getter"""
        return self._deterministic

    # ğŸ”‘ KRÄ°TÄ°K: Bu metodu sÄ±nÄ±f iÃ§ine ekleyin (hash metodundan Ã¶nce)
    def _true_memory_hard_fill(self, n_blocks: int, salt: bytes, data_bytes: bytes) -> bytes:
        """
        NIST SP 800-63B uyumlu gerÃ§ek memory-hard fill (Argon2i prensibi).
        Her blok Ã¶nceki TÃœM bloklara baÄŸlÄ± â†’ ASIC direnci saÄŸlar.
        """
        if n_blocks < 2:
            raise ValueError("Memory-hard fill requires at least 2 blocks")
        
        # Bellek bloklarÄ±nÄ± ayÄ±r (64 byte/block - Argon2 standardÄ±)
        blocks = [b''] * n_blocks
        
        # Block 0: BaÅŸlangÄ±Ã§ seed'i (data + salt karÄ±ÅŸÄ±mÄ±)
        blocks[0] = hashlib.blake2b(data_bytes + salt, digest_size=64).digest()
        
        # ğŸ”‘ KRÄ°TÄ°K: Sequential fill with data-dependent addressing
        for i in range(1, n_blocks):
            # Adres hesaplama: Ã–nceki bloÄŸun iÃ§eriÄŸine baÄŸlÄ± (ASIC direnci iÃ§in kritik)
            addr_input = blocks[i-1] + i.to_bytes(4, 'big', signed=False)
            addr_bytes = hashlib.blake2b(addr_input, digest_size=4).digest()
            addr = int.from_bytes(addr_bytes, 'little') % i  # Sadece Ã¶nceki bloklara eriÅŸim
            
            # G-fonksiyonu: Sequential dependency + random access
            blocks[i] = hashlib.blake2b(
                blocks[i-1] + blocks[addr] + salt + i.to_bytes(4, 'big', signed=False),
                digest_size=64
            ).digest()
        
        # ğŸ”‘ KRÄ°TÄ°K: Multiple passes (time_cost kadar)
        time_cost = getattr(self.config, 'time_cost', 3)
        for pass_num in range(1, time_cost):
            for i in range(n_blocks):
                addr_input = blocks[i] + pass_num.to_bytes(4, 'big', signed=False)
                addr_bytes = hashlib.blake2b(addr_input, digest_size=4).digest()
                addr = int.from_bytes(addr_bytes, 'little') % n_blocks
                
                blocks[i] = hashlib.blake2b(
                    blocks[i] + blocks[addr] + salt + pass_num.to_bytes(4, 'big', signed=False),
                    digest_size=64
                ).digest()
        
        # Son bloÄŸu dÃ¶ndÃ¼r (veya tÃ¼m bloklarÄ± karÄ±ÅŸtÄ±r)
        return blocks[-1]

    # ğŸ”‘ Balloon Hashing tabanlÄ± memory-hard fill (NIST uyumlu)
    def _balloon_memory_hard_hash(self, data_bytes: bytes, salt: bytes, space_cost: int, time_cost: int) -> bytes:
        """
        Minimal Balloon hashing implementasyonu (NIST SP 800-193 uyumlu).
        space_cost: Bellek blok sayÄ±sÄ± (her blok 64 byte)
        time_cost: KarÄ±ÅŸtÄ±rma tur sayÄ±sÄ±
        """
        if space_cost < 2:
            space_cost = 2
        
        # AdÄ±m 1: Sequential expand (her blok Ã¶nceki bloÄŸa baÄŸlÄ±)
        blocks = []
        current = hashlib.blake2b(data_bytes + salt, digest_size=64).digest()
        blocks.append(current)
        
        for i in range(1, space_cost):
            # Sequential dependency: Sadece Ã¶nceki bloÄŸa baÄŸlÄ±
            current = hashlib.blake2b(
                current + data_bytes + salt + i.to_bytes(4, 'big', signed=False),
                digest_size=64
            ).digest()
            blocks.append(current)
        
        # AdÄ±m 2: Data-dependent mixing (ASIC direnci iÃ§in kritik)
        for _ in range(time_cost):
            for i in range(space_cost):
                # Data-dependent address calculation
                addr_input = blocks[i] + i.to_bytes(4, 'big', signed=False)
                addr_bytes = hashlib.shake_256(addr_input).digest(4)
                addr = int.from_bytes(addr_bytes, 'little') % space_cost
                
                # Mix current block with randomly addressed block
                mixed = hashlib.blake2b(
                    blocks[i] + blocks[addr] + data_bytes + salt,
                    digest_size=64
                ).digest()
                blocks[i] = mixed
        
        # AdÄ±m 3: TÃ¼m bloklarÄ± hash'le
        final_input = b''.join(blocks) + data_bytes + salt
        return hashlib.blake2b(final_input, digest_size=32).digest()


    # ğŸ”‘ memory-hard path'i aktifleÅŸtir
    @SecurityLayers.timing_attack_protection
    def hash(self, data: Union[str, bytes], salt: Optional[bytes] = None) -> str:
        """Hash operation with REAL memory-hard support"""
        
        # Deterministik mod
        if self._deterministic:
            data_bytes = data.encode("utf-8") if isinstance(data, str) else data
            salt = salt or b"\x00" * 32
            return hashlib.blake2b(data_bytes + salt, digest_size=32).hexdigest()
        
        start_time = time.perf_counter()
        self._security_check()
        
        data_bytes = data.encode("utf-8") if isinstance(data, str) else data
        salt = salt or self._generate_secure_salt(data_bytes)
        salt = self._strengthen_salt(salt, data_bytes)
        self._last_used_salt = salt
        
        # ğŸ”‘ KRÄ°TÄ°K: GERÃ‡EK MEMORY-HARD MODU
        if getattr(self.config, "enable_memory_hard_mode", False):
            # Bellek boyutu: Argon2 convention (KB cinsinden) â†’ bytes'e Ã§evir
            space_cost = max(2, (self.config.memory_cost * 1024) // 64)  # 64 byte/block
            time_cost = max(1, self.config.time_cost)
            
            # Balloon hashing Ã§alÄ±ÅŸtÄ±r (GERÃ‡EK memory-hard)
            try:
                hash_bytes = self._balloon_memory_hard_hash(
                    data_bytes, salt, space_cost, time_cost
                )
            except Exception as e:
                logger.error(f"Memory-hard fill failed: {e}", exc_info=True)
                # GÃ¼venli fallback (ama memory-hard deÄŸil)
                hash_bytes = hashlib.blake2b(data_bytes + salt, digest_size=32).digest()
            
            # Metrikleri gÃ¼ncelle
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            self.metrics["hash_count"] = self.metrics.get("hash_count", 0) + 1
            self.metrics["total_time"] = self.metrics.get("total_time", 0.0) + elapsed_ms
            
            return hash_bytes.hex()
        
        else:
            # ========== NORMAL HIZLI MOD (mevcut pipeline) ==========
            cache_key = None
            if getattr(self.config, "cache_enabled", False):
                cache_key = self._generate_cache_key(data_bytes, salt)
                cached = self._cache.get(cache_key)
                if cached is not None:
                    stored_hwid, stored_tag = cached
                    hmac_key = hashlib.blake2b(b"hwid_cache_integrity" + salt, digest_size=32).digest()
                    expected_tag = hmac.new(hmac_key, stored_hwid, hashlib.sha256).digest()
                    if hmac.compare_digest(expected_tag, stored_tag):
                        self.metrics["cache_hits"] = self.metrics.get("cache_hits", 0) + 1
                        self.metrics["hash_count"] = self.metrics.get("hash_count", 0) + 1
                        self.metrics["total_time"] = self.metrics.get("total_time", 0.0) + 0.001
                        return stored_hwid.hex()
                    self._cache.pop(cache_key, None)
                self.metrics["cache_misses"] = self.metrics.get("cache_misses", 0) + 1
            
            try:
                # Mevcut pipeline (deÄŸiÅŸmeden korunur)
                seed = self._generate_secure_seed(data_bytes, salt)
                kha_matrix = self.core._generate_kha_matrix(seed)
                
                if getattr(self.config, "double_hashing", False):
                    intermediate = self.core._fortified_mixing_pipeline(kha_matrix, salt)
                    second_seed = self.core._final_bytes_conversion(intermediate, salt)
                    second_matrix = self.core._generate_kha_matrix(second_seed)
                    
                    SCALE = np.float64(2**64 - 1)
                    kha_matrix = np.clip(kha_matrix, 0.0, 1.0 - np.finfo(np.float64).eps)
                    second_matrix = np.clip(second_matrix, 0.0, 1.0 - np.finfo(np.float64).eps)
                    kha_matrix = np.nan_to_num(kha_matrix, nan=0.0, posinf=0.0, neginf=0.0)
                    second_matrix = np.nan_to_num(second_matrix, nan=0.0, posinf=0.0, neginf=0.0)
                    
                    kha_int = (kha_matrix * SCALE).astype(np.uint64)
                    second_int = (second_matrix * SCALE).astype(np.uint64)
                    combined_int = kha_int + second_int
                    kha_matrix = combined_int.astype(np.float64) / SCALE
                
                if getattr(self.config, "triple_compression", False):
                    for _ in range(2):
                        intermediate = self.core._fortified_mixing_pipeline(kha_matrix, salt)
                        comp_seed = self.core._final_bytes_conversion(intermediate, salt)
                        comp_matrix = self.core._generate_kha_matrix(comp_seed)
                        kha_matrix = (kha_matrix * 0.7 + comp_matrix * 0.3) % 1.0
                
                mixed_matrix = self.core._fortified_mixing_pipeline(kha_matrix, salt)
                hash_bytes = self.core._final_bytes_conversion(mixed_matrix, salt)
                compressed = self.core._secure_compress(hash_bytes, getattr(self.config, "hash_bytes", 32))
                
                length_derivation = hashlib.blake2b(
                    len(data_bytes).to_bytes(8, 'big') + salt[:16], 
                    digest_size=16
                ).digest()
                safe_length_param = int.from_bytes(length_derivation[:2], 'big') % 16 + 1
                
                final_bytes = self._bias_resistant_postprocess(compressed, safe_length_param)
                final_bytes = self._additional_security_layer(final_bytes, salt, data_bytes)
                hex_hash = final_bytes.hex()
                
                elapsed_ms = (time.perf_counter() - start_time) * 1000
                self.metrics["hash_count"] = int(self.metrics.get("hash_count", 0)) + 1
                self.metrics["total_time"] = float(self.metrics.get("total_time", 0.0)) + elapsed_ms
                
                if getattr(self.config, "cache_enabled", False) and cache_key is not None:
                    hmac_key = hashlib.blake2b(b"hwid_cache_integrity" + salt, digest_size=32).digest()
                    hmac_tag = hmac.new(hmac_key, final_bytes, hashlib.sha256).digest()
                    self._cache[cache_key] = (final_bytes, hmac_tag)
                    if len(self._cache) > getattr(self.config, "max_cache_size", 100):
                        for key in list(self._cache.keys())[:50]:
                            del self._cache[key]
                
                return hex_hash
            
            except Exception as e:
                logger.error(f"KHA hash failed: {e}", exc_info=True)
                fallback_hash = hashlib.blake2b(data_bytes + salt, digest_size=32).digest()
                return fallback_hash.hex()

    def _generate_cache_key(self, data: bytes, salt: bytes) -> bytes:
        """Generate cache key using secure hashing."""
        data_hash = hashlib.sha3_256(data).digest()[:16]
        salt_hash = hashlib.blake2b(salt, digest_size=16).digest()
        return data_hash + salt_hash  # âœ… Tek bytes olarak birleÅŸtir
    """
    def _generate_cache_key(self, data: bytes, salt: bytes) -> Tuple[bytes, bytes]:
        #Generate cache key using secure hashing.
        data_hash = hashlib.sha3_256(data).digest()[:16]
        salt_hash = hashlib.blake2b(salt, digest_size=16).digest()
        return (data_hash, salt_hash)
    """

    def _security_check(self) -> None:
        """Ultra hÄ±zlÄ± constant-time rate limiting."""
        current_time = time.perf_counter()
        
        # 1. Basit minimum delay (HER ZAMAN)
        time_since_last = current_time - getattr(self, '_last_hash_time', 0)
        MIN_DELAY = 0.002  # 2ms
        
        if time_since_last < MIN_DELAY:
            time.sleep(MIN_DELAY - time_since_last)
        
        # 2. Hafif jitter (timing signature Ã¶nler)
        jitter = secrets.randbelow(500) / 1_000_000.0  # 0-0.5ms
        time.sleep(jitter)
        
        # 3. Metrics (branchless)
        self._consecutive_hashes = min(
            getattr(self, '_consecutive_hashes', 0) + 1, 500
        ) if time_since_last < 0.05 else 0
        
        self._last_hash_time = current_time
        self.metrics["security_checks"] = self.metrics.get("security_checks", 0) + 1

    """
    # gÃ¼venlik aÃ§Ä±ÄŸÄ± oluÅŸturabilir
    def _security_check(self) -> None:
        #Security check - brute force and timing attack protection.
        current_time = time.time()

        # Detect rapid consecutive hashing
        if self._last_hash_time > 0:
            time_diff = current_time - self._last_hash_time

            if time_diff < 0.001:  # Less than 1ms
                self._consecutive_hashes += 1

                # Progressive slowdown
                if self._consecutive_hashes > 50:
                    delay_factor = min(2.0, (self._consecutive_hashes - 50) * 0.02)
                    time.sleep(delay_factor * 0.001) # Predictable delay!
            else:
                # Reset counter if enough time has passed
                self._consecutive_hashes = max(0, self._consecutive_hashes - 2)

        self._last_hash_time = current_time

        # Update security metrics
        if "security_checks" not in self.metrics:
            self.metrics["security_checks"] = 0
        self.metrics["security_checks"] = int(self.metrics["security_checks"]) + 1

        if self._consecutive_hashes > 100:
            logger.warning(
                f"High consecutive hash rate detected: {self._consecutive_hashes}"
            )
    """
    def _bias_resistant_postprocess(self, data: bytes, input_len: int) -> bytes:
        """Bias direnÃ§li post-process - BLAKE2b person limiti dÃ¼zeltmeli"""
        if not data:
            return data
        
        # 1. SHA3-512 ile non-lineer difÃ¼zyon
        state = hashlib.sha3_512(
            data + b"kha_entropy_v6" + input_len.to_bytes(8, 'big')
        ).digest()  # 64 byte
        
        # 2. BLAKE2b ile son difÃ¼zyon â€” PERSON PARAMETRESÄ°NÄ° KISALT!
        final = hashlib.blake2b(
            state,
            digest_size=len(data),
            salt=b"kha_v6_salt",      # â‰¤16 byte (12 byte)
            person=b"kha_entropy"     # â‰¤16 byte (11 byte) âœ… KRÄ°TÄ°K DÃœZELTME
        ).digest()
        
        return final
    """
    def _bias_resistant_postprocess(self, data: bytes, input_len: int) -> bytes:

        KRÄ°TÄ°K DÃœZELTME: TÃ¼m custom mixing'i KALDIR.
        Sadece SHA3-512 + BLAKE2b kullan â€” maksimum entropi iÃ§in kanÄ±tlanmÄ±ÅŸ yÃ¶ntem.

        if not data:
            return data
        
        # 1. SHA3-512 ile non-lineer difÃ¼zyon (64 byte state)
        state = hashlib.sha3_512(
            data + b"kha_entropy_v5" + input_len.to_bytes(8, 'big')
        ).digest()
        
        # 2. BLAKE2b ile son difÃ¼zyon â€” Ã‡IKTI UZUNLUÄU KESÄ°NLÄ°KLE KORUNUR
        final = hashlib.blake2b(
            state + data,  # SHA3 Ã§Ä±ktÄ±sÄ± + orijinal veri
            digest_size=len(data),  # 32 byte â†’ 32 byte (truncate YOK!)
            salt=b"kha_v5",
            person=b"max_entropy"
        ).digest()
        
        return final  # âœ… 100% non-lineer, 0% korelasyon
    """

    """
    def _bias_resistant_postprocess(self, data: bytes, input_len: int) -> bytes:

        ENTROPÄ°YÄ° ARTIRAN KESÄ°NTÄ°SÄ°Z Ã‡Ã–ZÃœM:
        - TÃ¼m lineer/custom operasyonlarÄ± KALDIR
        - Sadece SHA3-512 + BLAKE2b kullan
        - Output uzunluÄŸu KESÄ°NLÄ°KLE korunur

        if not data:
            return data
        
        # 1. SHA3-512 ile non-lineer difÃ¼zyon (64 byte state)
        state = hashlib.sha3_512(
            data + b"kha_final_mix_v4" + input_len.to_bytes(8, 'big')
        ).digest()
        
        # 2. BLAKE2b ile ikinci difÃ¼zyon katmanÄ± (cross-pollination)
        final = hashlib.blake2b(
            state + data,  # SHA3 output + orijinal data
            digest_size=len(data),  # Ã‡IKTI UZUNLUÄU KORUNUR!
            salt=b"kha_entropy",
            person=b"v4_entropy_boost"
        ).digest()
        
        return final  # âœ… 32 byte â†’ 32 byte, %100 entropi korunumu
    """

    """
    def _bias_resistant_postprocess(self, raw_bytes: bytes, input_length: int) -> bytes:
        #Bias'a dayanÄ±klÄ± post-processing
        if not raw_bytes:
            return raw_bytes

        salt = self._last_used_salt or b"\x00" * 64

        # 1. Maske
        mask_seed = hashlib.sha3_512(
            salt + input_length.to_bytes(8, "big") + b"BIAS_CORR_v4"
        ).digest()
        mask = (mask_seed * ((len(raw_bytes) // 64) + 1))[: len(raw_bytes)]
        masked = bytes(b ^ mask[i] for i, b in enumerate(raw_bytes))

        # 2. Rotate
        bits = []
        for b in masked:
            for i in range(7, -1, -1):
                bits.append((b >> i) & 1)
        if bits:
            bits = bits[-29:] + bits[:-29]

        # bits â†’ bytes
        result = bytearray()
        for i in range(0, len(bits), 8):
            chunk = bits[i : i + 8]
            if len(chunk) < 8:
                chunk.extend([0] * (8 - len(chunk)))
            v = 0
            for bit in chunk:
                v = (v << 1) | bit
            result.append(v)
        result = result[: len(raw_bytes)]

        # 3. Toggle yoÄŸunluÄŸu
        bits2 = []
        for b in result:
            for i in range(7, -1, -1):
                bits2.append((b >> i) & 1)

        toggle_key = hashlib.sha3_256(
            salt + input_length.to_bytes(8, "big") + b"TOGGLE_V4"
        ).digest()

        for i in range(len(bits2)):
            byte_idx = (i // 8) % len(toggle_key)
            if toggle_key[byte_idx] % 4 == 0:  # %25
                bits2[i] ^= 1

        # bits2 â†’ bytes
        out = bytearray()
        for i in range(0, len(bits2), 8):
            chunk = bits2[i : i + 8]
            if len(chunk) < 8:
                chunk.extend([0] * (8 - len(chunk)))
            v = 0
            for bit in chunk:
                v = (v << 1) | bit
            out.append(v)

        return bytes(out[: len(raw_bytes)])
    """
    def _additional_security_layer(
        self, data: bytes, salt: bytes, original_data: bytes) -> bytes:
        """
        Minimal gÃ¼venlik katmanÄ± â€” sadece SHA3-512 (XOR folding YOK)
        """
        # Deterministik key tÃ¼retme
        key = hashlib.sha3_512(salt + original_data + b"sec_v6").digest()
        
        # Non-lineer karÄ±ÅŸtÄ±rma â€” XOR folding YOK
        mixed = hashlib.sha3_512(data + key).digest()
        
        # Uzunluk koruma (truncate sadece son adÄ±mda)
        return mixed[:len(data)] if len(mixed) > len(data) else mixed
    """
    def _additional_security_layer(
        self, data: bytes, salt: bytes, original_data: bytes) -> bytes:

        Minimal gÃ¼venlik katmanÄ± â€” sadece SHA3-512

        # Deterministik key tÃ¼retme
        key = hashlib.sha3_512(salt + original_data + b"sec_v5").digest()
        
        # Non-lineer karÄ±ÅŸtÄ±rma
        mixed = hashlib.sha3_512(data + key + salt).digest()
        
        # Uzunluk koruma (truncate yok!)
        if len(mixed) > len(data):
            return mixed[:len(data)]
        elif len(mixed) < len(data):
            return (mixed * ((len(data) // 64) + 1))[:len(data)]
        return mixed
    """

    """
    def _additional_security_layer(
        self, data: bytes, salt: bytes, original_data: bytes) -> bytes:

        #GÃœVENLÄ° VE BASÄ°T: Sadece SHA3-512 ile non-lineer karÄ±ÅŸtÄ±rma

        # Deterministik key tÃ¼retme
        key = hashlib.sha3_512(salt + original_data + b"sec_layer_v4").digest()
        
        # Non-lineer karÄ±ÅŸtÄ±rma: SHA3-512 Ã¼zerinden geÃ§
        mixed = hashlib.sha3_512(
            data + key + salt
        ).digest()
        
        # Output uzunluÄŸunu koru
        if len(mixed) < len(data):
            mixed = (mixed * ((len(data) // 64) + 1))[:len(data)]
        elif len(mixed) > len(data):
            mixed = mixed[:len(data)]
        
        return mixed  # âœ… Lineer operasyon YOK, SBOX YOK, sadece SHA3
    """

    """
    def _additional_security_layer(
        self, data: bytes, salt: bytes, original_data: bytes) -> bytes:
        #Non-lineer, cross-byte difÃ¼zyonlu gÃ¼venlik katmanÄ±
        if not data:
            return data
        
        # Tam 256-byte SBOX (AES SBOX - kanÄ±tlanmÄ±ÅŸ non-lineerite) (runtime crash Ã¶nler)
        SBOX = bytes([
            0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5, 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76,
            0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0, 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0,
            0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc, 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15,
            0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a, 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75,
            0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0, 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84,
            0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b, 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf,
            0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85, 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8,
            0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5, 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2,
            0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17, 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73,
            0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88, 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb,
            0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c, 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79,
            0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9, 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08,
            0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6, 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a,
            0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e, 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e,
            0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94, 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf,
            0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68, 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16
        ])
        
        # Key tÃ¼retme (deterministik)
        key = hashlib.sha3_512(salt + original_data).digest()
        
        # State'i bytearray'a Ã§evir
        state = bytearray(data)
        key_len = len(key)
        
        # Round 1: SBOX + XOR + cross-byte difÃ¼zyon
        for i in range(len(state)):
            # a) Non-lineer SBOX substitution
            state[i] = SBOX[state[i]]
            
            # b) Key ile XOR
            state[i] ^= key[i % key_len]
            
            # c) Cross-byte difÃ¼zyon (Ã¶nceki byte'Ä± etkiler)
            if i > 0:
                state[i] ^= state[i - 1]
        
        # Round 2: Ters yÃ¶nde difÃ¼zyon (daha gÃ¼Ã§lÃ¼ avalanche)
        for i in range(len(state) - 1, -1, -1):
            state[i] = SBOX[state[i]]
            state[i] ^= key[(i + 16) % key_len]  # FarklÄ± key offset
            
            if i < len(state) - 1:
                state[i] ^= state[i + 1]
        
        return bytes(state)
    """

    """
    def _additional_security_layer(
        self, data: bytes, salt: bytes, original_data: bytes) -> bytes:

        #GÃ¼venli authenticated encryption katmanÄ±.
        #Hem gizlilik (confidentiality) hem de bÃ¼tÃ¼nlÃ¼k (integrity) saÄŸlar.

        # 1. GÃ¼Ã§lÃ¼ key tÃ¼retme: salt + original_data'dan kriptografik olarak gÃ¼venli key
        hkdf = HKDF(
            algorithm=hashes.SHA512(),
            length=self.KEY_SIZE,
            salt=salt,
            info=b"hwid_security_layer_v1",
        )
        encryption_key = hkdf.derive(original_data)
        
        # 2. Rastgele nonce (her ÅŸifreleme iÃ§in benzersiz OLMALI)
        nonce = os.urandom(self.NONCE_SIZE)
        
        # 3. AES-GCM ile authenticated encryption
        aesgcm = AESGCM(encryption_key)
        ciphertext = aesgcm.encrypt(nonce, data, associated_data=None)
        
        # 4. Nonce'u ciphertext ile birleÅŸtir (deÅŸifre iÃ§in gerekli)
        return nonce + ciphertext
    """
    
    def _remove_security_layer(
        self, encrypted_data: bytes, salt: bytes, original_data: bytes) -> bytes:
        """
        Åifreyi Ã§Ã¶z ve bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ doÄŸrula.
        GeÃ§ersiz veri/tampering durumunda InvalidTag fÄ±rlatÄ±r.
        """
        if len(encrypted_data) < self.NONCE_SIZE:
            raise ValueError("GeÃ§ersiz ÅŸifreli veri formatÄ±")
        
        # Nonce ve ciphertext'i ayÄ±r
        nonce = encrypted_data[:self.NONCE_SIZE]
        ciphertext = encrypted_data[self.NONCE_SIZE:]
        
        # Key'i aynÄ± ÅŸekilde tÃ¼ret
        hkdf = HKDF(
            algorithm=hashes.SHA512(),
            length=self.KEY_SIZE,
            salt=salt,
            info=b"hwid_security_layer_v1",
        )
        encryption_key = hkdf.derive(original_data)
        
        # Åifreyi Ã§Ã¶z VE bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ doÄŸrula (GCM otomatik olarak yapar)
        aesgcm = AESGCM(encryption_key)
        return aesgcm.decrypt(nonce, ciphertext, associated_data=None)

    """
    def _additional_security_layer(
        self, data: bytes, salt: bytes, original_data: bytes) -> bytes:
        #Ek gÃ¼venlik katmanÄ±
        result = bytearray(data)

        # HMAC benzeri koruma
        hmac_key = hashlib.sha3_512(salt + original_data).digest()[:32]

        for i in range(len(result)):
            key_byte = hmac_key[i % len(hmac_key)]
            data_byte = result[i]

            mixed = data_byte ^ key_byte
            mixed = (mixed + (key_byte << 1)) & 0xFF
            mixed ^= mixed >> 4
            mixed = (mixed * 0x9D) & 0xFF # # Linear operations - kolay tersine Ã§evrilebilir!

            result[i] = mixed

        # Final XOR
        xor_key = hashlib.sha256(salt).digest()
        for i in range(len(result)):
            result[i] ^= xor_key[i % len(xor_key)]

        return bytes(result)
    """

    def _generate_secure_salt(self, data: bytes) -> bytes:
        """GÃ¼venli tuz Ã¼retimi â€” salt'Ä±n amacÄ±na uygun ÅŸekilde"""
        if self._deterministic:
            # HWID iÃ§in DOÄRU kullanÄ±m: Tamamen deterministik, tekrarlanabilir
            return hashlib.blake2b(
                b"hwid_salt_v1" + data,  # Sabit domain separation
                digest_size=self.config.salt_length
            ).digest()
        
        # âš ï¸ UYARI: Non-deterministic mod HWID iÃ§in ANLAMSIZDIR!
        # EÄŸer mutlaka gerekiyorsa (Ã¶rneÄŸin geÃ§ici session iÃ§in):
        return secrets.token_bytes(self.config.salt_length)
        # âŒ data_hash KARIÅTIRILMAMALI â€” salt tamamen rastgele olmalÄ±

    """
    def _generate_secure_salt(self, data: bytes) -> bytes:
        #GÃ¼venli, kriptografik olarak rastgele tuz oluÅŸturur.
        if self._deterministic:
            # Deterministik: sadece veriden tÃ¼retilmiÅŸ sabit tuz
            return hashlib.blake2b(
                b"deterministic_salt" + data, digest_size=32
            ).digest()[: self.config.salt_length]

        # Non-deterministic mod: kriptografik rastgele + veri karÄ±ÅŸÄ±mÄ±
        sys_random = secrets.token_bytes(max(64, self.config.salt_length)) # Tek seferlik
        data_hash = hashlib.sha3_512(data).digest()  # Deterministik!
        combined = sys_random + data_hash  # Ä°lk 32 byte predictable deÄŸil, sonrasÄ± var

        if len(combined) >= self.config.salt_length:
            return combined[: self.config.salt_length]
        else:
            return (combined * ((self.config.salt_length // len(combined)) + 1))[
                : self.config.salt_length
            ]
    """

    def _strengthen_salt(self, salt: bytes, data: bytes) -> bytes:
        """Mevcut tuzu gÃ¼Ã§lendir"""
        if self._deterministic:
            # Deterministik modda sadece veriye dayalÄ± geniÅŸletme
            if len(salt) < self.config.salt_length:
                needed = self.config.salt_length - len(salt)
                extra = hashlib.sha256(salt + data + b"extend").digest()
                salt = salt + (extra * ((needed // 32) + 1))[:needed]
            return salt

        # Normal mod
        if len(salt) < self.config.salt_length:
            extension = self._generate_secure_salt(data + salt)
            extension_needed = self.config.salt_length - len(salt)
            salt = salt + extension[:extension_needed]

        # Hafif karÄ±ÅŸtÄ±rma
        strengthened = bytearray(salt)
        data_hash = hashlib.sha3_256(data).digest()

        for i in range(len(strengthened)):
            strengthened[i] ^= data_hash[i % len(data_hash)]
            strengthened[i] = (strengthened[i] + i * 13) % 256

        return bytes(strengthened)

    def _generate_secure_seed(self, data: bytes, salt: bytes) -> bytes:
        """GÃ¼venli seed oluÅŸtur"""
        header = len(data).to_bytes(8, "big") + len(salt).to_bytes(8, "big")

        # Ã‡oklu hash turu
        h1 = hashlib.sha3_512(header + data + salt).digest()

        if len(data) <= 2048:
            h2_input = h1 + data + salt
        else:
            sampled = b"".join(data[i : i + 128] for i in range(0, len(data), 1024))[
                :1024
            ]
            h2_input = h1 + sampled + salt

        h2 = hashlib.sha3_512(h2_input).digest()

        # Final karÄ±ÅŸtÄ±rma
        seed = hashlib.sha3_512(h2 + header).digest()

        return seed

    def test_avalanche_effect(self, samples: int = 1000) -> Dict[str, Any]:
        """Statistical Avalanche Effect Test - OPTÄ°MÄ°ZE EDÄ°LMÄ°Å"""
        print("Statistical Avalanche Effect Test running...")
    
        bit_change_percent: List[float] = []
        hamming_distances: List[int] = []
        timings_ms: List[float] = []
        single_bit_results: List[int] = []
    
        for idx in range(samples):
            # 1. Rastgele girdi
            data_len = random.randint(32, 512)
            base_data = secrets.token_bytes(data_len)
    
            # 2. TEK bit flip (avalanche testi iÃ§in standart)
            bit_pos = random.randint(0, data_len * 8 - 1)
            modified = bytearray(base_data)
            byte_idx = bit_pos // 8
            bit_idx = bit_pos % 8
            modified[byte_idx] ^= 1 << bit_idx
    
            # 3. Hash hesaplama
            start = time.perf_counter()
            h1 = self.hash(base_data)
            h2 = self.hash(bytes(modified))
            elapsed_ms = (time.perf_counter() - start) * 1000.0
            timings_ms.append(elapsed_ms)
    
            # âœ… 4. HIZLI Hamming distance (XOR + popcount)
            h1_int = int(h1, 16)
            h2_int = int(h2, 16)
            diff_bits = (h1_int ^ h2_int).bit_count()
            
            # âœ… Dinamik hash boyutu
            HASH_BITS = len(h1) * 4  # hex â†’ bit
            diff_percent = (diff_bits / HASH_BITS) * 100.0
    
            bit_change_percent.append(diff_percent)
            hamming_distances.append(diff_bits)
            single_bit_results.append(diff_bits)
    
            if (idx + 1) % max(1, samples // 10) == 0:
                print(f"  {idx + 1}/{samples} | avg={np.mean(bit_change_percent):.2f}%")
    
        # Ä°statistikler
        avg_percent = float(np.mean(bit_change_percent))
        std_percent = float(np.std(bit_change_percent))
        min_percent = float(np.min(bit_change_percent))
        max_percent = float(np.max(bit_change_percent))
        avg_hamming = float(np.mean(hamming_distances))
        std_hamming = float(np.std(hamming_distances))
        avg_time = float(np.mean(timings_ms))
    
        # âœ… GerÃ§ekÃ§i ideal aralÄ±k (%45-55)
        IDEAL_MIN, IDEAL_MAX = 45.0, 55.0
        in_ideal = sum(1 for p in bit_change_percent if IDEAL_MIN <= p <= IDEAL_MAX)
        ideal_ratio = (in_ideal / samples) * 100.0
    
        # SonuÃ§ sÄ±nÄ±flandÄ±rmasÄ±
        if ideal_ratio >= 95.0 and 48.0 <= avg_percent <= 52.0:
            status = "EXCELLENT"
        elif ideal_ratio >= 80.0:
            status = "GOOD"
        elif ideal_ratio >= 60.0:
            status = "ACCEPTABLE"
        else:
            status = "POOR"
    
        self._record_avalanche_test(
            samples, avg_percent, std_percent, min_percent, max_percent,
            avg_hamming, std_hamming, ideal_ratio, avg_time,
            single_bit_results, None, status
        )
    
        return {
            "samples": samples,
            "avg_bit_change_percent": avg_percent,
            "std_deviation": std_percent,
            "min_change_percent": min_percent,
            "max_change_percent": max_percent,
            "avg_hamming_distance": avg_hamming,
            "std_hamming_distance": std_hamming,
            "in_ideal_range": f"{ideal_ratio:.2f}%",
            "avg_time_ms": avg_time,
            "single_bit_hamming_avg": float(np.mean(single_bit_results)),
            "status": status,
        }

    def _record_avalanche_test(
        self,
        samples,
        avg_percent,
        std_percent,
        min_percent,
        max_percent,
        avg_hamming,
        std_hamming,
        ideal_ratio,
        avg_time,
        single_bit_results,
        multi_bit_results,
        status,
    ):
        """Record avalanche test results"""
        if "avalanche_tests" not in self.metrics:
            self.metrics["avalanche_tests"] = []

        if not isinstance(self.metrics["avalanche_tests"], list):
            self.metrics["avalanche_tests"] = []

        test_record = {
            "samples": samples,
            "avg_bit_change_percent": float(avg_percent),
            "std_bit_change_percent": float(std_percent),
            "min_bit_change_percent": float(min_percent),
            "max_bit_change_percent": float(max_percent),
            "avg_hamming_distance": float(avg_hamming),
            "std_hamming_distance": float(std_hamming),
            "ideal_range_ratio": float(ideal_ratio),
            "avg_time_ms": float(avg_time),
            "single_bit_avg_hamming": (
                float(np.mean(single_bit_results)) if single_bit_results else None
            ),
            "multi_bit_avg_hamming": (
                float(np.mean(multi_bit_results)) if multi_bit_results else None
            ),
            "status": str(status),
        }

        self.metrics["avalanche_tests"].append(test_record)

    def test_collision_resistance(self, samples: int = 10000) -> Dict[str, Any]:
        """GeliÅŸmiÅŸ Ã§akÄ±ÅŸma direnci testi"""
        print("GeliÅŸmiÅŸ Ã‡akÄ±ÅŸma Testi Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±yor...")

        hashes = {}
        collisions = 0
        near_collisions = 0

        for i in range(samples):
            # Rastgele veri
            data_len = random.randint(1, 1024)
            data = secrets.token_bytes(data_len)

            # Hash hesapla
            h = self.hash(data)

            if h in hashes:
                collisions += 1
                print(f"  Ã‡AKIÅMA BULUNDU: {collisions}. Ã§akÄ±ÅŸma")
            else:
                hashes[h] = data

            # YakÄ±n Ã§akÄ±ÅŸma kontrolÃ¼
            if i % 1000 == 0 and i > 0:
                for j in range(min(100, len(hashes))):
                    hash1 = list(hashes.keys())[j]
                    for k in range(j + 1, min(200, len(hashes))):
                        hash2 = list(hashes.keys())[k]
                        h1_int = int(hash1, 16)
                        h2_int = int(hash2, 16)
                        diff_bits = bin(h1_int ^ h2_int).count("1")
                        if diff_bits <= 8:  # 8 bitten az fark
                            near_collisions += 1

            # Ä°lerleme
            if (i + 1) % 1000 == 0:
                print(f"  {i + 1}/{samples} tamamlandÄ±")

        collision_rate = (collisions / samples) * 100
        near_collision_rate = (near_collisions / samples) * 100

        return {
            "samples": samples,
            "unique_hashes": len(hashes),
            "collisions": collisions,
            "collision_rate_percent": collision_rate,
            "near_collisions": near_collisions,
            "near_collision_rate_percent": near_collision_rate,
            "status": (
                "EXCELLENT"
                if collisions == 0 and near_collision_rate < 0.0001
                else (
                    "GOOD"
                    if collision_rate < 0.0001 and near_collision_rate < 0.001
                    else "ACCEPTABLE" if collision_rate < 0.001 else "POOR"
                )
            ),
        }

    def test_uniformity(self, samples: int = 10_000) -> Dict[str, Any]:
        """Statistical uniformity test for hash output."""
        print(f"Uniformity test running with {samples} samples...")

        bit_counts = np.zeros(256, dtype=np.int64)
        byte_counts = np.zeros(256, dtype=np.int64)
        run_lengths_zero = []
        run_lengths_one = []
        total_runs = []
        hash_lengths = []

        for i in range(samples):
            try:
                data_len = random.randint(1, 256)
                data = secrets.token_bytes(data_len)
                hex_hash = self.hash(data)
                h_bytes = bytes.fromhex(hex_hash)
                hash_lengths.append(len(h_bytes))

                if len(h_bytes) == 0:
                    continue

                byte_array = np.frombuffer(h_bytes, dtype=np.uint8)
                bits = np.unpackbits(byte_array)

                # Bit counts
                bit_counts += bits

                # Byte counts
                if len(byte_array) > 0:
                    hist = np.bincount(byte_array, minlength=256)
                    byte_counts += hist

                # Run analysis
                if len(bits) > 1:
                    changes = np.where(bits[1:] != bits[:-1])[0] + 1
                    starts = np.concatenate(([0], changes))
                    ends = np.concatenate((changes, [len(bits)]))
                    run_lengths = ends - starts

                    for start, length in zip(starts, run_lengths):
                        if bits[start] == 0:
                            run_lengths_zero.append(length)
                        else:
                            run_lengths_one.append(length)

                    total_runs.append(len(run_lengths))

                if (i + 1) % max(1, samples // 10) == 0:
                    print(f"  Progress: {i + 1}/{samples} samples")

            except Exception as e:
                print(f"Error at sample {i}: {str(e)[:100]}")
                continue

        # Chi-square: bit-level
        total_bit_positions = bit_counts.sum()
        expected_bits = total_bit_positions / 2
        chi_square_bit = np.sum((bit_counts - expected_bits) ** 2 / expected_bits)

        # Chi-square: byte-level
        total_bytes_counted = byte_counts.sum()
        if total_bytes_counted > 0:
            expected_bytes = total_bytes_counted / 256
            chi_square_byte = np.sum(
                (byte_counts - expected_bytes) ** 2 / expected_bytes
            )
        else:
            chi_square_byte = 0

        # Run length statistics
        all_run_lengths = run_lengths_zero + run_lengths_one
        if all_run_lengths:
            avg_run = np.mean(all_run_lengths)
            std_run = np.std(all_run_lengths)
            unique_lengths, length_counts = np.unique(
                all_run_lengths, return_counts=True
            )
            theoretical_probs = [0.5**k for k in unique_lengths]
            theoretical_counts = [p * len(all_run_lengths) for p in theoretical_probs]
            run_chi_square = np.sum(
                (length_counts - theoretical_counts) ** 2 / theoretical_counts
            )
        else:
            avg_run = 0
            std_run = 0
            run_chi_square = 0

        # NIST-style runs test
        avg_total_runs: float = 0.0
        std_total_runs: float = 0.0
        runs_z_score: float = 0.0
        
        if total_runs:
            avg_total_runs = float(np.mean(total_runs))
            std_total_runs = float(np.std(total_runs))
            n_bits = 256
            expected_total_runs = (n_bits + 1) / 2

            if std_total_runs > 0:
                runs_z_score = float(
                    abs(avg_total_runs - expected_total_runs) / std_total_runs
                )
        else:
            avg_total_runs = 0.0
            std_total_runs = 0.0
            runs_z_score = 0.0

        # Significance tests
        bit_threshold = 310.0
        is_uniform_bit = chi_square_bit < bit_threshold
        byte_threshold = 310.0
        is_uniform_byte = chi_square_byte < byte_threshold
        run_length_threshold = 20.0
        is_uniform_run_length = run_chi_square < run_length_threshold
        is_uniform_runs = runs_z_score < 2.576

        # Overall status
        if (
            is_uniform_bit
            and is_uniform_byte
            and is_uniform_run_length
            and is_uniform_runs
        ):
            status = "EXCELLENT"
        elif is_uniform_bit and is_uniform_byte:
            status = "GOOD"
        elif is_uniform_bit or is_uniform_byte:
            status = "FAIR"
        else:
            status = "POOR"

        result = {
            "samples": len(hash_lengths),
            "chi_square_bit": float(chi_square_bit),
            "chi_square_byte": float(chi_square_byte),
            "avg_run_length": float(avg_run),
            "std_run_length": float(std_run),
            "is_uniform_bit": bool(is_uniform_bit),
            "is_uniform_byte": bool(is_uniform_byte),
            "run_length_chi_square": float(run_chi_square),
            "avg_total_runs": float(avg_total_runs),
            "runs_z_score": float(runs_z_score),
            "zero_runs_count": len(run_lengths_zero),
            "one_runs_count": len(run_lengths_one),
            "total_runs_analyzed": len(all_run_lengths),
            "hash_length_min": min(hash_lengths) if hash_lengths else 0,
            "hash_length_max": max(hash_lengths) if hash_lengths else 0,
            "hash_length_avg": (
                sum(hash_lengths) / len(hash_lengths) if hash_lengths else 0.0
            ),
            "status": status,
        }

        print("\nUniformity Test Results:")
        print(f"  Status: {status}")
        print(f"  Bit Uniformity: {is_uniform_bit} (Ï‡Â²={chi_square_bit:.2f})")
        print(f"  Byte Uniformity: {is_uniform_byte} (Ï‡Â²={chi_square_byte:.2f})")
        print(f"  Avg Run Length: {avg_run:.3f} Â± {std_run:.3f}")

        return result

    def get_stats(self) -> Dict[str, Any]:
        """Ä°statistikleri getir"""
        stats: Dict[str, Any] = {}

        if hasattr(self.core, "stats"):
            for key, value in self.core.stats.items():
                stats[key] = value

        stats.update(self.metrics)

        hash_count = stats.get("hash_count", 0)
        total_time = stats.get("total_time", 0.0)
        total_operations = stats.get("total_operations", 0)

        if hash_count > 0:
            stats["avg_time_ms"] = float(total_time) / float(hash_count)
            if total_operations > 0:
                stats["operations_per_hash"] = float(total_operations) / float(
                    hash_count
                )
            else:
                stats["operations_per_hash"] = 0.0
        else:
            stats["avg_time_ms"] = 0.0
            stats["operations_per_hash"] = 0.0

        kha_success = stats.get("kha_success", 0)
        kha_fail = stats.get("kha_fail", 0)
        kha_total = kha_success + kha_fail

        if kha_total > 0:
            stats["kha_success_rate"] = (float(kha_success) / float(kha_total)) * 100.0
        else:
            stats["kha_success_rate"] = 0.0

        return stats

    def get_security_report(self) -> Dict[str, Any]:
        """GÃ¼venlik raporu"""
        config_dict = {}
        if hasattr(self.config, "to_dict"):
            config_dict = self.config.to_dict()
        elif hasattr(self.config, "__dict__"):
            config_dict = {
                k: v for k, v in vars(self.config).items() if not k.startswith("_")
            }

        features = {}
        feature_attrs = {
            "diffusion_resistance": "enable_diffusion_mix",
            "quantum_resistance": "enable_quantum_mix",
            "memory_hardening": "memory_hardening",
            "side_channel_resistance": "enable_side_channel_resistance",
            "constant_time_ops": "enable_constant_time_ops",
            "encryption_layer": "enable_encryption_layer",
            #"post_quantum_mixing": "enable_post_quantum_mixing",
            "double_hashing": "double_hashing",
            "triple_compression": "triple_compression",
        }

        for feature_name, attr_name in feature_attrs.items():
            features[feature_name] = getattr(self.config, attr_name, False)

        stats = self.get_stats()

        return {
            "algorithm": "KHA-256-FORTIFIED",
            "version": "0.1.4",
            "security_level": getattr(self.config, "security_level", "256-bit"),
            "config": config_dict,
            "metrics": {
                "total_hashes": stats.get("hash_count", 0),
                "security_checks": stats.get("security_checks", 0),
                "kha_success_rate": stats.get("kha_success_rate", 0.0),
            },
            "features": features,
        }


class OptimizedFortifiedConfig(FortifiedConfig):
    """
    Configuration for performance-optimized KHA-256 hashing.
    Extends the base FortifiedConfig with optimization-specific settings.
    """

    def __init__(
        self,
        cache_enabled: bool = True,
        cache_size: int = 256,  # Changed from max_cache_size to cache_size
        enable_metrics: bool = True,
        double_hashing: bool = False, # False
        enable_byte_distribution_optimization: bool = True, # False
        byte_uniformity_rounds: int = 5, # 3: Optimal: 5 tur (NIST SP 800-90B)
        hash_bytes: int = 32,
        salt_length: int = 32, #16: NIST SP 800-132: 16-32 
        # Pass through FortifiedConfig parameters
        **kwargs,
    ):
        # Call parent constructor first
        super().__init__(**kwargs)

        # Add optimization-specific settings
        self.cache_enabled = cache_enabled
        self.cache_size = cache_size  # Use consistent naming
        self.enable_metrics = enable_metrics
        self.double_hashing = double_hashing
        self.enable_byte_distribution_optimization = (
            enable_byte_distribution_optimization
        )
        self.byte_uniformity_rounds = byte_uniformity_rounds
        self.hash_bytes = hash_bytes
        self.salt_length = salt_length

    @property
    def max_cache_size(self) -> int:
        """Alias for cache_size for backward compatibility"""
        return self.cache_size

class HybridKhaHash256(FortifiedKhaHash256):
    """
    HYBRID KHA-256 implementation.
    Uses BLAKE2s for small data, KHA for large data.
    """

    # Threshold for switching algorithms
    SMALL_DATA_THRESHOLD = 1024  # 1KB
    MEDIUM_DATA_THRESHOLD = 8192  # 8KB
    
    def __init__(
        self,
        config: Optional[Union[OptimizedFortifiedConfig, FortifiedConfig]] = None,
        *,
        deterministic: bool = True,
        turbo_mode: bool = True,
        hybrid_mode: bool = True,  # Enable hybrid mode
    ):
        """
        Initialize the hybrid hasher.
        
        Args:
            config: Configuration object
            deterministic: Whether to use deterministic behavior
            turbo_mode: Enable extreme optimizations for speed
            hybrid_mode: Enable hybrid mode (BLAKE2s for small, KHA for large)
        """
        # GeÃ§ici config ile temel sÄ±nÄ±fÄ± baÅŸlat
        temp_config = FortifiedConfig() if config is None else config
        super().__init__(config=temp_config, deterministic=deterministic)
        
        self.turbo_mode = turbo_mode
        self.hybrid_mode = hybrid_mode
        
        # Åimdi kendi config'imizi ayarla
        if config is None:
            self.config = OptimizedFortifiedConfig(
                cache_enabled=True,
                cache_size=2048,
                enable_metrics=False,
                double_hashing=False,
                enable_byte_distribution_optimization=False,
                byte_uniformity_rounds=1,
                hash_bytes=32,
                salt_length=8,
                rounds=6,
                memory_cost=512,
                parallelism=1,
            )
        elif isinstance(config, FortifiedConfig) and not isinstance(
            config, OptimizedFortifiedConfig
        ):
            # Sadece FortifiedConfig'in desteklediÄŸi parametreler
            supported_params = [
                "cache_enabled", "cache_size", "enable_metrics", 
                "double_hashing", "enable_byte_distribution_optimization",
                "byte_uniformity_rounds", "hash_bytes", "salt_length",
                "rounds", "memory_cost", "parallelism"
            ]
            
            kwargs: Dict[str, Any] = {}
            
            for param in supported_params:
                if hasattr(config, param):
                    try:
                        kwargs[param] = getattr(config, param)
                    except (AttributeError, ValueError):
                        pass
            
            # VarsayÄ±lanlar
            defaults = {
                "cache_enabled": True,
                "cache_size": 2048,
                "enable_metrics": False,
                "double_hashing": False,
                "enable_byte_distribution_optimization": False,
                "byte_uniformity_rounds": 1,
                "hash_bytes": 32,
                "salt_length": 8,
                "rounds": 6,
                "memory_cost": 512,
                "parallelism": 1,
            }
            
            for key, default_value in defaults.items():
                if key not in kwargs:
                    kwargs[key] = default_value
            
            self.config = OptimizedFortifiedConfig(**kwargs)
        else:
            self.config = cast(OptimizedFortifiedConfig, config)

        # Core'u baÅŸlat
        self.core = PerformanceOptimizedKhaCore(self.config)

        # Cache'ler
        self._cache: Dict[int, str] = {}
        self._blake2s_cache: Dict[int, bytes] = {}
        self._cache_hits = 0
        self.cache_misses = 0
        
        # Metrics
        self.metrics: Dict[str, Any] = {
            "hash_count": 0,
            "blake2s_count": 0,
            "kha_count": 0,
            "total_time_ms": 0.0,
        }

    # ------------------------------------------------------------------
    # Main hash method - HYBRID
    # ------------------------------------------------------------------

    def hash(self, data: Union[str, bytes], salt: Optional[bytes] = None) -> str:
        """Compute hybrid hash of data"""
        start_time = time.perf_counter()
        
        # Input conversion
        if isinstance(data, str):
            data_bytes = data.encode("utf-8")
        else:
            data_bytes = data
        
        data_len = len(data_bytes)
        
        # Choose algorithm based on size
        if self.hybrid_mode and data_len < self.SMALL_DATA_THRESHOLD:
            # Small data: use BLAKE2s
            result = self._blake2s_hash(data_bytes, salt)
            self.metrics["blake2s_count"] += 1
        elif self.hybrid_mode and data_len < self.MEDIUM_DATA_THRESHOLD:
            # Medium data: use optimized KHA
            result = self._optimized_kha_hash(data_bytes, salt)
            self.metrics["kha_count"] += 1
        else:
            # Large data: use full KHA
            result = self._full_kha_hash(data_bytes, salt)
            self.metrics["kha_count"] += 1
        
        # Update metrics
        self.metrics["hash_count"] += 1
        self.metrics["total_time_ms"] += (time.perf_counter() - start_time) * 1000
        
        return result

    # ------------------------------------------------------------------
    # Algorithm implementations
    # ------------------------------------------------------------------

    def _blake2s_hash(self, data: bytes, salt: Optional[bytes] = None) -> str:
        """Fast BLAKE2s hash for small data"""
        # Cache key
        cache_key = hash(data)
        if salt is not None:
            cache_key ^= hash(salt)
        
        # Check cache
        if cache_key in self._cache:
            self._cache_hits += 1
            return self._cache[cache_key]
        
        self.cache_misses += 1
        
        # Prepare input
        if salt is None:
            # Simple deterministic salt
            salt = struct.pack(">Q", len(data))
        
        # BLAKE2s with salt as key
        result = hashlib.blake2s(data, key=salt, digest_size=32).hexdigest()
        
        # Cache result
        if len(self._cache) < getattr(self.config, "cache_size", 2048):
            self._cache[cache_key] = result
        
        return result

    def _optimized_kha_hash(self, data: bytes, salt: Optional[bytes] = None) -> str:
        """Optimized KHA for medium data"""
        # Simple salt if not provided
        if salt is None:
            salt = hashlib.blake2s(data[:32], digest_size=8).digest()
        
        # Cache key
        cache_key = hash(data) ^ (hash(salt) << 32)
        
        # Check cache
        if cache_key in self._cache:
            self._cache_hits += 1
            return self._cache[cache_key]
        
        self.cache_misses += 1
        
        # Simplified KHA pipeline for medium data
        seed = self._derive_seed_simple(data, salt)
        matrix = self.core._generate_kha_matrix(seed)
        
        # Simple mixing
        mixed = self._simple_mixing(matrix, salt)
        
        # Byte conversion
        raw_bytes = self.core._final_bytes_conversion(mixed, salt)
        
        # Compression
        hash_bytes = getattr(self.config, "hash_bytes", 32)
        final_bytes = self.core._secure_compress(raw_bytes, hash_bytes)
        
        result = final_bytes.hex()
        
        # Cache result
        if len(self._cache) < getattr(self.config, "cache_size", 2048):
            self._cache[cache_key] = result
        
        return result

    def _full_kha_hash(self, data: bytes, salt: Optional[bytes] = None) -> str:
        """Full KHA for large data"""
        # Use parent class hash method
        if salt is None:
            # Derive salt
            salt = hashlib.blake2s(data[:64], digest_size=16).digest()
        
        # Cache key
        cache_key = hash(data) ^ (hash(salt) << 32)
        
        # Check cache
        if cache_key in self._cache:
            self._cache_hits += 1
            return self._cache[cache_key]
        
        self.cache_misses += 1
        
        # Get hash from parent class
        result = super().hash(data, salt)
        
        # Cache result
        if len(self._cache) < getattr(self.config, "cache_size", 2048):
            self._cache[cache_key] = result
        
        return result

    # ------------------------------------------------------------------
    # Helper methods
    # ------------------------------------------------------------------

    def _derive_seed_simple(self, data: bytes, salt: bytes) -> bytes:
        """Simple seed derivation"""
        data_part = data[:16] if len(data) >= 16 else data
        salt_part = salt[:8] if len(salt) >= 8 else salt
        combined = data_part + salt_part
        
        if len(combined) < 24:
            combined = combined * (24 // len(combined) + 1)
        
        return hashlib.blake2s(combined[:24], digest_size=24).digest()

    def _simple_mixing(self, matrix: np.ndarray, salt: bytes) -> np.ndarray:
        """Simple mixing for medium data"""
        salt_int = int.from_bytes(salt[:4], 'big') if len(salt) >= 4 else 12345
        np.random.seed(salt_int)
        
        mixed = matrix * 1.61803398875
        mixed = np.sin(mixed)
        return mixed

    # ------------------------------------------------------------------
    # Utility Methods
    # ------------------------------------------------------------------

    def get_cache_stats(self) -> Dict[str, Any]:
        """Get cache statistics"""
        total = self._cache_hits + self.cache_misses
        hit_rate = self._cache_hits / total if total > 0 else 0.0

        return {
            "hits": self._cache_hits,
            "misses": self.cache_misses,
            "size": len(self._cache),
            "hit_rate": hit_rate,
            "max_size": getattr(self.config, "cache_size", 2048),
            "hybrid_mode": self.hybrid_mode,
            "blake2s_count": self.metrics.get("blake2s_count", 0),
            "kha_count": self.metrics.get("kha_count", 0),
        }

    def clear_cache(self) -> None:
        """Clear all caches"""
        self._cache.clear()
        self._blake2s_cache.clear()
        self._cache_hits = 0
        self.cache_misses = 0

    def get_metrics(self) -> Dict[str, Any]:
        """Get performance metrics"""
        metrics = self.metrics.copy()
        hash_count = metrics.get("hash_count", 0)

        if hash_count > 0:
            total_time = metrics.get("total_time_ms", 0.0)
            metrics["average_time_ms"] = total_time / hash_count
            metrics["hashes_per_second"] = (hash_count / total_time * 1000) if total_time > 0 else 0
            
            # Algorithm distribution
            blake2s_pct = (metrics.get("blake2s_count", 0) / hash_count * 100) if hash_count > 0 else 0
            kha_pct = (metrics.get("kha_count", 0) / hash_count * 100) if hash_count > 0 else 0
            metrics["blake2s_percentage"] = blake2s_pct
            metrics["kha_percentage"] = kha_pct
        else:
            metrics["average_time_ms"] = 0.0
            metrics["hashes_per_second"] = 0
            metrics["blake2s_percentage"] = 0
            metrics["kha_percentage"] = 0

        metrics.update(self.get_cache_stats())
        return metrics

    # ------------------------------------------------------------------
    # String representation and callability
    # ------------------------------------------------------------------
    
    def __str__(self) -> str:
        """String representation"""
        mode = " (HYBRID)" if self.hybrid_mode else ""
        return f"HybridKhaHash256{mode}"

    def __call__(self, data: Union[str, bytes]) -> str:
        """Make instance callable"""
        return self.hash(data)
    
    def enable_hybrid_mode(self, enable: bool = True) -> None:
        """Enable or disable hybrid mode"""
        self.hybrid_mode = enable
        self.clear_cache()


class OptimizedKhaHash256(FortifiedKhaHash256):
    """
    SIMPLE & FAST KHA-256 implementation.
    No micro-optimizations, just the essentials for speed.
    """

    def __init__(
        self,
        config: Optional[Union[OptimizedFortifiedConfig, FortifiedConfig]] = None,
        *,
        deterministic: bool = True,
        turbo_mode: bool = True,
    ):
        """
        Initialize the optimized hasher with minimal overhead.
        
        Args:
            config: Configuration object
            deterministic: Whether to use deterministic behavior
            turbo_mode: Enable extreme optimizations for speed
        """
        # GeÃ§ici config ile temel sÄ±nÄ±fÄ± baÅŸlat
        temp_config = FortifiedConfig() if config is None else config
        super().__init__(config=temp_config, deterministic=deterministic)
        
        self.turbo_mode = turbo_mode
        
        # Åimdi kendi config'imizi ayarla - MINIMAL OPTIMIZATIONS
        if config is None:
            self.config = OptimizedFortifiedConfig(
                cache_enabled=True,
                cache_size=2048,  # Optimal cache size
                enable_metrics=False,
                double_hashing=False,
                enable_byte_distribution_optimization=False,
                byte_uniformity_rounds=1,
                hash_bytes=32,
                salt_length=4 if turbo_mode else 8,
                rounds=3 if turbo_mode else 6,
                memory_cost=256 if turbo_mode else 512,
                parallelism=1,
            )
        elif isinstance(config, FortifiedConfig) and not isinstance(
            config, OptimizedFortifiedConfig
        ):
            # Sadece FortifiedConfig'in desteklediÄŸi parametreler
            supported_params = [
                "cache_enabled", "cache_size", "enable_metrics", 
                "double_hashing", "enable_byte_distribution_optimization",
                "byte_uniformity_rounds", "hash_bytes", "salt_length",
                "rounds", "memory_cost", "parallelism"
            ]
            
            kwargs: Dict[str, Any] = {}
            
            for param in supported_params:
                if hasattr(config, param):
                    try:
                        value = getattr(config, param)
                        kwargs[param] = value
                    except (AttributeError, ValueError):
                        pass
            
            # VarsayÄ±lanlar
            defaults = {
                "cache_enabled": True,
                "cache_size": 2048,
                "enable_metrics": False,
                "double_hashing": False,
                "enable_byte_distribution_optimization": False,
                "byte_uniformity_rounds": 1,
                "hash_bytes": 32,
                "salt_length": 4 if turbo_mode else 8,
                "rounds": 3 if turbo_mode else 6,
                "memory_cost": 256 if turbo_mode else 512,
                "parallelism": 1,
            }
            
            for key, default_value in defaults.items():
                if key not in kwargs:
                    kwargs[key] = default_value
            
            self.config = OptimizedFortifiedConfig(**kwargs)
        else:
            self.config = cast(OptimizedFortifiedConfig, config)
            
            # Turbo mode iÃ§in basit gÃ¼ncelleme
            if turbo_mode:
                self.config.enable_byte_distribution_optimization = False
                self.config.byte_uniformity_rounds = 1
                self.config.enable_metrics = False

        # Core'u baÅŸlat
        self.core = PerformanceOptimizedKhaCore(self.config)

        # Basit metrics
        self.metrics: Dict[str, Any] = {
            "hash_count": 0,
            "total_time_ms": 0.0,
        }

        # Basit cache
        self._cache_hits = 0
        self.cache_misses = 0
        self._cache: Dict[int, str] = {}
        self._salt_cache: Dict[int, bytes] = {}
        self._matrix_cache: Dict[int, np.ndarray] = {}

    # ------------------------------------------------------------------
    # Main hash method - SIMPLE & FAST
    # ------------------------------------------------------------------

    def hash(self, data: Union[str, bytes], salt: Optional[bytes] = None) -> str:
        """Compute optimized hash of data - MINIMAL OVERHEAD"""
        # Input conversion
        if isinstance(data, str):
            data_bytes = data.encode("utf-8")
        else:
            data_bytes = data
        
        # Salt
        if salt is None:
            salt = self._derive_salt_fast(data_bytes)
        
        # Cache check - basit
        if getattr(self.config, "cache_enabled", True):
            cache_key = hash(data_bytes) ^ (hash(salt) << 32)
            cached = self._cache.get(cache_key)
            
            if cached is not None:
                self._cache_hits += 1
                return cached
            self.cache_misses += 1
        
        # Pipeline
        result = self._fast_pipeline(data_bytes, salt)
        
        # Store in cache
        if getattr(self.config, "cache_enabled", True):
            if len(self._cache) >= getattr(self.config, "cache_size", 2048):
                # Basit eviction
                keys = list(self._cache.keys())
                for k in keys[:100]:
                    del self._cache[k]
            self._cache[cache_key] = result
        
        return result

    # ------------------------------------------------------------------
    # Fast methods - MINIMAL
    # ------------------------------------------------------------------

    def _derive_salt_fast(self, data_bytes: bytes) -> bytes:
        """Fast salt derivation"""
        key = hash(data_bytes)
        if key in self._salt_cache:
            return self._salt_cache[key]
        
        # Ã‡ok basit salt
        data_len = len(data_bytes)
        if data_len == 0:
            salt = b"\x01\x02\x03\x04"
        elif data_len <= 4:
            salt = data_bytes * (4 // data_len + 1)
            salt = salt[:4]
        elif data_len < 64:
            salt = data_bytes[:2] + data_bytes[-2:]
        else:
            salt = hashlib.blake2s(data_bytes[:32], digest_size=4).digest()
        
        self._salt_cache[key] = salt
        return salt

    def _derive_seed_fast(self, data: bytes, salt: bytes) -> bytes:
        """Fast seed derivation"""
        # Basit kombinasyon
        data_part = data[:16] if len(data) >= 16 else data
        salt_part = salt[:8] if len(salt) >= 8 else salt
        combined = data_part + salt_part
        
        if len(combined) < 24:
            combined = combined * (24 // len(combined) + 1)
        
        return hashlib.blake2s(combined[:24], digest_size=24).digest()

    def _fast_pipeline(self, data: bytes, salt: bytes) -> str:
        """Fast pipeline with minimal overhead"""
        # 1. Matrix generation (with cache)
        seed = self._derive_seed_fast(data, salt)
        seed_key = hash(seed)
        
        if seed_key in self._matrix_cache:
            matrix = self._matrix_cache[seed_key]
        else:
            matrix = self.core._generate_kha_matrix(seed)
            if len(data) < 65536:
                self._matrix_cache[seed_key] = matrix
        
        # 2. Mixing - turbo mode iÃ§in optimize
        if self.turbo_mode:
            mixed = self._fast_mixing_simple(matrix, salt)
        else:
            mixed = self.core._fortified_mixing_pipeline(matrix, salt)
        
        # 3. Final conversion
        raw_bytes = self.core._final_bytes_conversion(mixed, salt)
        
        # 4. Final compression
        hash_bytes = getattr(self.config, "hash_bytes", 32)
        final_bytes = self.core._secure_compress(raw_bytes, hash_bytes)
        
        return final_bytes.hex()
    
    def _fast_mixing_simple(self, matrix: np.ndarray, salt: bytes) -> np.ndarray:
        """Simple fast mixing"""
        # Ã‡ok basit mixing
        salt_int = int.from_bytes(salt[:4], 'big') if len(salt) >= 4 else 12345
        np.random.seed(salt_int)
        
        mixed = matrix * 1.61803398875
        mixed = np.sin(mixed)
        mixed = (mixed * 1000) % 1.0
        
        return mixed

    # ------------------------------------------------------------------
    # Utility Methods
    # ------------------------------------------------------------------

    def get_cache_stats(self) -> Dict[str, Any]:
        """Get cache statistics"""
        total = self._cache_hits + self.cache_misses
        hit_rate = self._cache_hits / total if total > 0 else 0.0

        return {
            "hits": self._cache_hits,
            "misses": self.cache_misses,
            "size": len(self._cache),
            "hit_rate": hit_rate,
            "max_size": getattr(self.config, "cache_size", 2048),
            "salt_cache": len(self._salt_cache),
            "matrix_cache": len(self._matrix_cache),
            "turbo_mode": self.turbo_mode,
        }

    def clear_cache(self) -> None:
        """Clear all caches"""
        self._cache.clear()
        self._salt_cache.clear()
        self._matrix_cache.clear()
        self._cache_hits = 0
        self.cache_misses = 0

    def get_metrics(self) -> Dict[str, Any]:
        """Get performance metrics"""
        metrics = self.metrics.copy()
        hash_count = metrics.get("hash_count", 0)

        if hash_count > 0:
            total_time = metrics.get("total_time_ms", 0.0)
            metrics["average_time_ms"] = total_time / hash_count
            metrics["hashes_per_second"] = (hash_count / total_time * 1000) if total_time > 0 else 0
        else:
            metrics["average_time_ms"] = 0.0
            metrics["hashes_per_second"] = 0

        metrics.update(self.get_cache_stats())
        return metrics

    # ------------------------------------------------------------------
    # String representation and callability
    # ------------------------------------------------------------------
    
    def __str__(self) -> str:
        """String representation"""
        mode = " (TURBO)" if self.turbo_mode else ""
        return f"OptimizedKhaHash256{mode}"

    def __call__(self, data: Union[str, bytes]) -> str:
        """Make instance callable"""
        return self.hash(data)
    
    def enable_turbo_mode(self, enable: bool = True) -> None:
        """Enable or disable turbo mode"""
        self.turbo_mode = enable
        if enable:
            self.config.enable_byte_distribution_optimization = False
            self.config.byte_uniformity_rounds = 1
            self.config.enable_metrics = False
        self.clear_cache()

# ============================================================
# KOLAY KULLANIM FONKSÄ°YONLARI
# ============================================================
### 3.1 Merkezi Hasher Factory
def generate_fortified_hasher(config=None, deterministic = True, purpose: str = "balanced") -> FortifiedKhaHash256:
    """Harmonize edilmiÅŸ: Ã–nceki config ile %100 uyumlu"""
    if purpose == "password":      # Eski ayarlar
        config = FortifiedConfig(iterations=32, components_per_hash=48, 
                                memory_cost=2**24, time_cost=16)
    elif purpose == "secure":      # BankacÄ±lÄ±k â†‘
        config = FortifiedConfig(iterations=48, components_per_hash=64, 
                                memory_cost=2**26, time_cost=24)  # 64MB
    elif purpose == "fast":        # Mobil â†“
        config = FortifiedConfig(iterations=16, components_per_hash=24, 
                                memory_cost=2**22, time_cost=8)   # 4MB
    else:  # balanced/default
        config = FortifiedConfig(iterations=24, components_per_hash=32, 
                                memory_cost=2**23, time_cost=12)  # 8MB
    return FortifiedKhaHash256(config, deterministic=deterministic)


def generate_fortified_hasher_password(
    *,
    iterations: int = 32,
    components: int = 48,
    memory_cost: int = 2**24,
    time_cost: int = 16,
) -> FortifiedKhaHash256:
    """
    Parametrik Fortified KHA-256 oluÅŸturucu.
    """
    config = FortifiedConfig(
        iterations=iterations,
        components_per_hash=components,
        memory_cost=memory_cost,
        time_cost=time_cost,
    )
    return FortifiedKhaHash256(config)

def generate_fortified_hasher_fast(
    *,
    iterations: int = 16,
    components: int = 24,
    memory_cost: int = 2**22,
    time_cost: int = 8,
) -> FortifiedKhaHash256:
    """
    Parametrik Fortified KHA-256 oluÅŸturucu.
    """
    config = FortifiedConfig(
        iterations=iterations,
        components_per_hash=components,
        memory_cost=memory_cost,
        time_cost=time_cost,
    )
    return FortifiedKhaHash256(config)

def generate_fortified_hasher_secure(
    *,
    iterations: int = 48,
    components: int = 64,
    memory_cost: int = 2**26,
    time_cost: int = 24,
) -> FortifiedKhaHash256:
    """
    Parametrik Fortified KHA-256 oluÅŸturucu.
    """
    config = FortifiedConfig(
        iterations=iterations,
        components_per_hash=components,
        memory_cost=memory_cost,
        time_cost=time_cost,
    )
    return FortifiedKhaHash256(config)

### GÃ¼venli Parola Hashleme (KDF Modu, salt zorunlu)
def hash_password(data: bytes, salt: bytes, *, 
                 is_usb_key: bool = True, fast_mode: bool = False) -> str:
    """
    SCrypt KHA - Salt ZORUNLU, USB varsayÄ±lan (2026 gÃ¼venli)
    """
    # Salt zorunlu - TypeError Ã¶nleme
    if not isinstance(salt, bytes) or len(salt) < 16:
        raise ValueError("Salt bytes olmalÄ± ve min 16 byte!")
    
    # USB varsayÄ±lan parametreler âœ…
    if fast_mode:
        n, r, p = 16384, 8, 1      # 16MB
        maxmem = 32 * 1024 * 1024  # 32MB
    elif is_usb_key:  # â† VARSAYILAN
        n, r, p = 65536, 8, 1      # 64MB  
        maxmem = 128 * 1024 * 1024 # 128MB
    else:
        n, r, p = 262144, 8, 1     # 256MB
        maxmem = 512 * 1024 * 1024 # 512MB
        
    digest = hashlib.scrypt(
        password=data,
        salt=salt,
        n=n, r=r, p=p,
        dklen=32,
        maxmem=maxmem
    )
    
    prefix = "KHA256-USB$" if is_usb_key else "KHA256$"
    return f"{prefix}{salt.hex()}${digest.hex()}"

def hash_password_str(password: str, salt: bytes, **kwargs) -> str:
    """String wrapper - salt ZORUNLU"""
    return hash_password(password.encode('utf-8'), salt, **kwargs)
"""
def hash_password(data: bytes, salt: Optional[bytes] = None, *, is_usb_key: bool = False, fast_mode: bool = True) -> str:

    #BYTES tabanlÄ± !

    if salt is None:
        salt = secrets.token_bytes(32)  # Rastgele salt (deterministik deÄŸil)
    
    # TEK IF: Ã–ncelik -> fast_mode > is_usb_key > varsayÄ±lan
    if fast_mode:
        n, r, p = 2**10, 8, 1  # 1MB - EN HIZLI
    elif is_usb_key:
        n, r, p = 2**12, 8, 1  # 4MB - USB
    else:
        n, r, p = 2**14, 8, 1  # 16MB - Full
    
    # BYTES â†’ scrypt BYTES kabul eder!
    # TypeError: a bytes-like object is required, not 'str'
    digest_bytes = hashlib.scrypt(
        password=data,  # â† DATA ZATEN BYTES!
        salt=salt,      # â† SALT BYTES!
        n=n, r=r, p=p, 
        dklen=32
    )
    
    prefix = "KHA256-USB$" if is_usb_key else "KHA256-DATA$"
    return f"{prefix}{salt.hex()}${digest_bytes.hex()}"

# String uyumluluÄŸu (geriye uyumluluk)
def hash_password_str(password: str, salt: Optional[bytes] = None, *, is_usb_key: bool = False, fast_mode: bool = True) -> str:
    #String input iÃ§in wrapper
    password_bytes = password.encode('utf-8')
    return hash_password(password_bytes, salt, is_usb_key=is_usb_key, fast_mode=fast_mode)
"""
"""
def hash_password(data: bytes, salt: Optional[bytes] = None, *, is_usb_key: bool = False, fast_mode: bool = True) -> str:

    BYTES verisi iÃ§in KHA hash

    if salt is None:
        salt = secrets.token_bytes(32)
    
    # TEK IF: Ã–ncelik sÄ±rasÄ± -> fast_mode > is_usb_key > varsayÄ±lan
    if fast_mode:
        n, r, p = 2**10, 8, 1  # 1MB - EN HIZLI ğŸï¸
    elif is_usb_key:
        n, r, p = 2**12, 8, 1  # 4MB - USB modu âš¡
    else:
        n, r, p = 2**14, 8, 1  # 16MB - Full gÃ¼venlik ğŸ›¡ï¸

    digest_bytes = hashlib.scrypt(password=data, salt=salt, n=n, r=r, p=p, dklen=32)
    
    prefix = "KHA256-USB$" if is_usb_key else "KHA256-DATA$"
    return f"{prefix}{salt.hex()}${digest_bytes.hex()}"
"""

"""
def hash_password(
    password: str, salt: Optional[bytes] = None, *, is_usb_key: bool = False, fast_mode: bool = True
) -> str:

    Deterministik KDF tabanlÄ± parola hash fonksiyonu.
    AynÄ± (parola + tuz) her zaman aynÄ± Ã§Ä±ktÄ±yÄ± verir.
    Args:
        password: Hashlenecek parola (str).
        salt: Ä°steÄŸe baÄŸlÄ± tuz. Belirtilmezse rastgele Ã¼retilir.
        is_usb_key: Daha hÄ±zlÄ± (dÃ¼ÅŸÃ¼k kaynak) mod.
    Returns:
        str: "KHA256[-USB]$<salt_hex>$<digest>"

    # 1. ParolayÄ± byte'a Ã§evir
    if not isinstance(password, str):
        raise TypeError("Password must be a string")
    password_bytes = password.encode("utf-8")

    # 2. Tuz oluÅŸtur
    if salt is None:
        salt = secrets.token_bytes(32)  # 32 byte = 256 bit â€” yeterli
    elif not isinstance(salt, bytes):
        raise TypeError("Salt must be bytes")

    # 3. scrypt parametreleri (OpenSSL bellek sÄ±nÄ±rÄ±na dikkat!)
    if is_usb_key:
        n, r, p = 2**12, 8, 1  # ~4 MB RAM
    else:
        n, r, p = 2**14, 8, 1  # ~16 MB RAM â€” Ã§oÄŸu sistemde Ã§alÄ±ÅŸÄ±r

    # 4. scrypt ile deterministik tÃ¼rev
    try:
        digest_bytes = hashlib.scrypt(
            password=password_bytes,
            salt=salt,
            n=n,
            r=r,
            p=p,
            dklen=32,  # 256 bit output
        )
    except ValueError as e:
        if "memory limit exceeded" in str(e):
            # Fallback: daha dÃ¼ÅŸÃ¼k parametrelerle dene
            n, r, p = 2**10, 8, 1  # ~1 MB
            digest_bytes = hashlib.scrypt(
                password=password_bytes, salt=salt, n=n, r=r, p=p, dklen=32
            )
        else:
            raise

    # 5. Formatla
    prefix = "KHA256-USB$" if is_usb_key else "KHA256$"
    return f"{prefix}{salt.hex()}${digest_bytes.hex()}"
"""

def expose_kha256_bug():
    """KHA256'nÄ±n config'i ignore ettiÄŸini MATEMATÄ°KSEL kanÄ±tla"""
    
    # AÅÄ°RLÄ°K testleri
    configs = [
        FortifiedConfig(iterations=1, memory_cost=2**10, time_cost=0),   # ULTRA HIZLI
        FortifiedConfig(iterations=1000, memory_cost=2**28, time_cost=999), # ULTRA YAVAÅ
        FortifiedConfig(iterations=50_000, memory_cost=2**30, time_cost=5000) # Ä°MKANSIZ
    ]
    
    for i, config in enumerate(configs):
        hasher = FortifiedKhaHash256(config)
        start = time.perf_counter()
        hasher.hash(b"A" * 1000)
        elapsed = (time.perf_counter() - start) * 1000
        
        print(f"iter={config.iterations:6,} mem={config.memory_cost/1e6:.0f}MB "
              f"time={config.time_cost:4} â†’ {elapsed:6.1f}ms  â† BUG!")

# ======================
# KRIPTOGRAFÄ°K HASHLER (256-bit)
# ======================
def quick_hash(data: Union[str, bytes]) -> str:
    """
    HÄ±zlÄ± ve gÃ¼venli 256-bit hash (BLAKE2b).
    Python 3.11+ optimize edilmiÅŸ, kriptografik ama KDF deÄŸildir.
    """
    if isinstance(data, str):
        data = data.encode("utf-8")
    return hashlib.blake2b(data, digest_size=32).hexdigest()


def quick_hash_sha256(data: Union[str, bytes]) -> str:
    """SHA-256 (256-bit) - Fallback olarak kullanÄ±lÄ±r."""
    if isinstance(data, str):
        data = data.encode("utf-8")
    return hashlib.sha256(data).hexdigest()


def quick_hash_blake3(data: Union[str, bytes]) -> str:
    """BLAKE3 - En hÄ±zlÄ± kriptografik hash (256-bit varsayÄ±lan)."""
    if blake3 is None:
        raise RuntimeError("BLAKE3 modÃ¼lÃ¼ yÃ¼klenemiyor: pip install blake3")
    if isinstance(data, str):
        data = data.encode("utf-8")
    return blake3(data).hexdigest()  # 32 byte = 256 bit


def quick_hash_raw(data: Union[str, bytes]) -> bytes:
    """BLAKE3 raw bytes (hex dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yok â†’ %45 daha hÄ±zlÄ±)."""
    if blake3 is None:
        raise RuntimeError("BLAKE3 modÃ¼lÃ¼ yÃ¼klenemiyor: pip install blake3")
    if isinstance(data, str):
        data = data.encode("utf-8")
    return blake3(data).digest()  # 32 byte raw output


# ======================
# NON-KRIPTOGRAFÄ°K (CACHE KEY, INDEXING)
# ======================

def ultra_fast_hash(data: Union[str, bytes]) -> int:
    """
    xxHash64 - En hÄ±zlÄ± non-kriptografik hash.
    NOT: 64-bit output Ã¼retir (256-bit DEÄÄ°L). Sadece cache/index iÃ§in kullanÄ±n.
    """
    if xxhash is None:
        raise RuntimeError("xxhash modÃ¼lÃ¼ yÃ¼klenemiyor: pip install xxhash")
    if isinstance(data, str):
        data = data.encode("utf-8")
    return xxhash.xxh64_intdigest(data)


def fastest_cache_key(data: str) -> int:
    """String iÃ§in optimize edilmiÅŸ cache key (xxHash64)."""
    if xxhash is None:
        raise RuntimeError("xxhash modÃ¼lÃ¼ yÃ¼klenemiyor: pip install xxhash")
    return xxhash.xxh64_intdigest(data.encode("utf-8"))


# ======================
# PURE PYTHON (DEPENDENCY-FREE)
# ======================

def fnv1a_64(data: Union[str, bytes]) -> str:
    """64-bit FNV-1a - dependency-free, non-kriptografik."""
    if isinstance(data, str):
        data = data.encode("utf-8")
    h = 0xCBF29CE484222325
    for b in data:
        h ^= b
        h = (h * 0x100000001B3) & 0xFFFFFFFFFFFFFFFF
    return f"{h:016x}"


def djb2_optimized(data: Union[str, bytes]) -> int:
    """DJB2 - micro-optimized pure Python."""
    if isinstance(data, str):
        data = data.encode("utf-8")
    h = 5381
    for b in data:
        h = ((h << 5) + h + b) & 0xFFFFFFFFFFFFFFFF
    return h


# ======================
# GÃœVENLÄ° PASSWORD HASHING (KDF)
# ======================

def hash_argon2id(password: str) -> str:
    """
    Production-ready password hashing (Argon2id - en gÃ¼venli seÃ§enek).
    Output: 256-bit+ encoded hash.
    """
    from argon2 import PasswordHasher

    ph = PasswordHasher(
        time_cost=3,      # Iterasyon sayÄ±sÄ± (t)
        memory_cost=16256, # Bellek maliyeti (m KB): 65536: 64 MB
        parallelism=12,    # Paralellik (p): threadripper desteÄŸi
        hash_len=32,      # Ã‡Ä±ktÄ± uzunluÄŸu (byte)
    )
    if ph is None:
        raise RuntimeError("argon2 modÃ¼lÃ¼ yÃ¼klenemiyor: pip install argon2-cffi")
    return ph.hash(password)


def hash_bcrypt(password: str, rounds: int = 12) -> str:
    """
    bcrypt password hashing (adaptive cost).
    Output: ~184-bit effective security (yeterli).
    """
    if bcrypt is None:
        raise RuntimeError("bcrypt modÃ¼lÃ¼ yÃ¼klenemiyor: pip install bcrypt")
    salt = bcrypt.gensalt(rounds=rounds)
    return bcrypt.hashpw(password.encode("utf-8"), salt).decode("utf-8")


def hash_pbkdf2(password: str, salt: bytes = None, iterations: int = 600_000) -> str:
    """
    PBKDF2-HMAC-SHA256 (NIST Ã¶nerilen).
    Output: 256-bit key + salt.
    """
    if salt is None:
        salt = os.urandom(16)
    dk = hashlib.pbkdf2_hmac("sha256", password.encode("utf-8"), salt, iterations, dklen=32)
    return salt.hex() + ":" + dk.hex()


# ======================
# BATCH Ä°ÅLEMLER
# ======================

def batch_hash_xxh64(passwords: list[str]) -> list[int]:
    """HÄ±zlÄ± batch hashing (non-kriptografik, benchmark iÃ§in)."""
    if xxhash is None:
        raise RuntimeError("xxhash modÃ¼lÃ¼ yÃ¼klenemiyor: pip install xxhash")
    return [xxhash.xxh64_intdigest(p.encode("utf-8")) for p in passwords]


def batch_hash_secure(passwords: list[str]) -> list[str]:
    """GÃ¼venli batch password hashing (Argon2id)."""
    from argon2 import PasswordHasher

    ph = PasswordHasher(
        time_cost=3,      # Iterasyon sayÄ±sÄ± (t)
        memory_cost=16256, # Bellek maliyeti (m KB): 65536: 64 MB
        parallelism=12,    # Paralellik (p): threadripper desteÄŸi
        hash_len=32,      # Ã‡Ä±ktÄ± uzunluÄŸu (byte)
    )
    if ph is None:
        raise RuntimeError("argon2 modÃ¼lÃ¼ yÃ¼klenemiyor: pip install argon2-cffi")
    return [ph.hash(p) for p in passwords]

# ======================
# EN HIZLI NON-KRÄ°PTOGRAFÄ°K (Indexing/Cache iÃ§in)
# ======================

def fast_hash_int(data: Union[str, bytes]) -> int:
    """
    xxHash64 integer â€” cache key/index iÃ§in ideal.
    Ubuntu 25.10'de ~130 ns/op.
    """
    try:
        import xxhash
    except ImportError:
        # Fallback: SHA-256 ilk 8 byte
        if isinstance(data, str):
            data = data.encode("utf-8")
        return int.from_bytes(hashlib.sha256(data).digest()[:8], "big")
    
    if isinstance(data, str):
        data = data.encode("utf-8")
    return xxhash.xxh64_intdigest(data)


# ======================
# GÃœVENLÄ° ÅÄ°FRELEME (Sadece ÅŸifre depolama iÃ§in)
# ======================

def secure_hash_password(password: str) -> str:
    """
    Production ÅŸifre hashing â€” intentionally yavaÅŸ.
    OWASP Ã¶nerisi: Argon2id.
    """
    try:
        from argon2 import PasswordHasher

        ph = PasswordHasher(
            time_cost=3,      # Iterasyon sayÄ±sÄ± (t)
            memory_cost=16256, # Bellek maliyeti (m KB): 65536: 64 MB
            parallelism=12,    # Paralellik (p): threadripper desteÄŸi
            hash_len=32,      # Ã‡Ä±ktÄ± uzunluÄŸu (byte)
        )
        return ph.hash(password)
    except ImportError:
        # Fallback: PBKDF2
        salt = os.urandom(16)
        dk = hashlib.pbkdf2_hmac("sha256", password.encode("utf-8"), salt, 600_000, dklen=32)
        return salt.hex() + ":" + dk.hex()

# xxh64_hash (hex string output)
def xxh64_hash(data: Union[str, bytes]) -> str:
    """xxHash64 hexdigest output (non-kriptografik)."""
    if xxhash is None:
        raise RuntimeError("xxhash modÃ¼lÃ¼ yÃ¼klenemiyor: pip install xxhash")
    if isinstance(data, str):
        data = data.encode("utf-8")
    return xxhash.xxh64(data).hexdigest()  # 16 karakter hex (64-bit)


# quick_hash_cached (LRU cache'li versiyon)
@lru_cache
def quick_hash_cached(data: Union[str, bytes]):
    if isinstance(data, str):
        data = data.encode("utf-8")
    return hashlib.blake2b(data, digest_size=32).hexdigest()  # bytes gÃ¼venli


# 128-bit BLAKE3 (daha hÄ±zlÄ±, collision risk dÃ¼ÅŸÃ¼k ama 256-bit deÄŸil)
def quick_hash_128(data: Union[str, bytes]) -> str:
    """BLAKE3 128-bit output (32 karakter hex)."""
    if blake3 is None:
        raise RuntimeError("BLAKE3 modÃ¼lÃ¼ yÃ¼klenemiyor: pip install blake3")
    if isinstance(data, str):
        data = data.encode("utf-8")
    return blake3(data).hexdigest(length=16)


# ======================
# PERFORMANS Ã–LÃ‡ÃœMÃœ
# ======================

def measure_hash(func, *args) -> tuple[float, any]:
    """Hassas timing Ã¶lÃ§Ã¼mÃ¼ (milisaniye cinsinden)."""
    start = time.perf_counter()
    result = func(*args)
    elapsed_ms = (time.perf_counter() - start) * 1000
    return elapsed_ms, result

# Ãœretim Ã¶ncesi gÃ¼venlik kontrolÃ¼
def _validate_blake2_params(salt: bytes, person: bytes):
    if len(salt) > 16 or len(person) > 16:
        raise ValueError(  # â† SecurityError yerine
            f"BLAKE2 params exceed 16 bytes (salt:{len(salt)}, person:{len(person)})"
        )

def test_fortified_hashers() -> Dict[str, Dict[str, Any]]:
    """
    TÃ¼m fortified hasher'larÄ± import kha256'dan Ã§ekip test eder.
    Her config iÃ§in: sÃ¼re (ms), RAM (MB), hash kalitesi
    """
    results = {}
    
    # Test vektÃ¶rleri (aynÄ± input'lar collision kontrolÃ¼ iÃ§in)
    test_passwords = [
        "SecureKHA2026_test123!",
        "password", 
        "1234567890abcdef",
        "admin",
        "user@example.com"
    ]
    
    # 1. generate_fortified_hasher(purpose)
    purposes = ["fast", "balanced", "password", "secure"]
    for purpose in purposes:
        print(f"\nğŸ” Testing: generate_fortified_hasher('{purpose}')")
        hasher = generate_fortified_hasher(purpose=purpose)
        
        total_time = 0
        hashes = []
        
        for pwd in test_passwords:
            start = time.perf_counter()
            hash_result = hasher.hash(pwd.encode())
            elapsed = (time.perf_counter() - start) * 1000  # ms
            
            total_time += elapsed
            hashes.append(hash_result)
            print(f"  '{pwd}' â†’ {elapsed:.1f}ms â†’ {hash_result[:16]}...")
        
        avg_time = total_time / len(test_passwords)
        unique_hashes = len(set(hashes))
        
        results[f"{purpose}_purpose"] = {
            "avg_time_ms": avg_time,
            "collision_free": unique_hashes == len(test_passwords),
            "sample_hash": hashes[0][:32] if hashes else None,
            "config": purpose
        }
        print(f"  ğŸ“Š AVG: {avg_time:.1f}ms | Collision: {100*unique_hashes/len(test_passwords):.1f}%")
    
    # 2. generate_fortified_hasher_password() parametrik
    print("\nğŸ” Testing: generate_fortified_hasher_password() defaults")
    hasher_param = generate_fortified_hasher_password()
    total_time_param = 0
    hashes_param = []
    
    for pwd in test_passwords:
        start = time.perf_counter()
        hash_result = hasher_param.hash(pwd.encode())
        elapsed = (time.perf_counter() - start) * 1000
        total_time_param += elapsed
        hashes_param.append(hash_result)
    
    results["password_param"] = {
        "avg_time_ms": total_time_param / len(test_passwords),
        "collision_free": len(set(hashes_param)) == len(test_passwords),
        "sample_hash": hashes_param[0][:32] if hashes_param else None,
        "config": "password(defaults)"
    }
    
    # 3. Fixed fonksiyonlar
    fixed_functions = [
        ("secure", generate_fortified_hasher_secure),
        ("fast", generate_fortified_hasher_password),
        ("fast", generate_fortified_hasher_fast),
    ]
    
    for name, func in fixed_functions:
        print(f"\nğŸ” Testing: {name}()")
        hasher = func()
        
        total_time = 0
        hashes = []
        for pwd in test_passwords:
            start = time.perf_counter()
            hash_result = hasher.hash(pwd.encode())
            elapsed = (time.perf_counter() - start) * 1000
            total_time += elapsed
            hashes.append(hash_result)
        
        avg_time = total_time / len(test_passwords)
        unique_hashes = len(set(hashes))
        
        results[name] = {
            "avg_time_ms": avg_time,
            "collision_free": unique_hashes == len(test_passwords),
            "sample_hash": hashes[0][:32] if hashes else None,
            "config": name
        }
        print(f"  ğŸ“Š AVG: {avg_time:.1f}ms | Collision: {100*unique_hashes/len(test_passwords):.1f}%")
    
    return results

def print_results_table(results: Dict[str, Dict[str, Any]]):
    """GÃ¼zel tablo Ã§Ä±ktÄ±sÄ±"""
    print("\n" + "="*80)
    print("ğŸ† FORTIFIED KHA256 HASHER BENCHMARK RESULTS")
    print("="*80)
    
    table_data = []
    for key, data in results.items():
        status = "âœ…" if data["collision_free"] else "âŒ"
        table_data.append([
            key.replace("_", " ").title(),
            f"{data['avg_time_ms']:.1f}ms",
            f"{status} {100*1:.0f}%",
            data["sample_hash"] or "N/A"
        ])
    
    # Pandas tablo (optional)
    df = pd.DataFrame(table_data, columns=["Config", "Avg Time", "Collision", "Sample"])
    print(df.to_string(index=False))
    
    # Performans kategorisi
    print("\nğŸ¯ PERFORMANCE CATEGORIES:")
    fast_configs = [k for k,v in results.items() if v["avg_time_ms"] < 120]
    balanced = [k for k,v in results.items() if 120 <= v["avg_time_ms"] < 300]
    heavy = [k for k,v in results.items() if v["avg_time_ms"] >= 300]
    
    print(f"ğŸš€ FAST (<120ms): {', '.join(fast_configs) or 'None'}")
    print(f"âš–ï¸  BALANCED (120-300ms): {', '.join(balanced) or 'None'}")
    print(f"ğŸ›¡ï¸  HEAVY (300ms+): {', '.join(heavy) or 'None'}")

def gpu_resistance_test(hasher, count=100):
    """GPU direncini Ã¶lÃ§: GerÃ§ek memory-hard ise 100 hash >5 sn sÃ¼rmeli"""
    start = time.perf_counter()
    for i in range(count):
        _ = hasher.hash(f"pwd{i}".encode())
    elapsed = time.perf_counter() - start
    
    hashes_per_sec = count / elapsed
    print(f"100 hash: {elapsed*1000:.0f} ms â†’ {hashes_per_sec:.0f} hash/sn")
    
    if hashes_per_sec > 50:
        print("âš ï¸  UYARI: GPU ile kÄ±rÄ±labilir! (GerÃ§ek memory-hard deÄŸil)")
    elif hashes_per_sec > 10:
        print("âœ… Orta direnÃ§ (sadece zaman maliyeti)")
    else:
        print("ğŸ”’ YÃ¼ksek direnÃ§ (gerÃ§ek memory-hard)")

def secure_avalanche_mix(data: bytes, salt: bytes) -> bytes:
    """NIST onaylÄ±, deterministik, side-channel safe mixing"""
    # BLAKE3 zaten mÃ¼kemmel avalanche effect'e sahip
    return blake3(data + salt, length=64).digest()  # 512-bit output

# ChaCha20 Permutation (HÄ±zlÄ± + GÃ¼venli)
def chacha_avalanche_mix(data: bytes, salt: bytes) -> bytes:
    """ChaCha20 quarter rounds - kanÄ±tlanmÄ±ÅŸ diffusion"""
    key = (data + salt)[:32]  # 256-bit key
    cipher = ChaCha20.new(key=key, nonce=b"\x00"*12)
    return cipher.encrypt(b"\x00"*64)  # 512-bit pseudo-random output


class MockCore:
    class MockConfig:
        shuffle_layers = 4
    
    def __init__(self):
        self.config = self.MockConfig()

# Metodu MockCore'a ata
MockCore._quantum_avalanche_mix = FortifiedKhaCore._quantum_avalanche_mix
MockCore._enhanced_byte_diffusion = FortifiedKhaCore._enhanced_byte_diffusion

# Test kodu
core = MockCore()
test_matrix = np.random.random(64).astype(np.float64)
test_salt = b"secure_salt_2026_abcdef1234567890"

try:
    result = core._quantum_avalanche_mix(test_matrix, test_salt)
    print("âœ… _quantum_avalanche_mix hatasÄ±z Ã§alÄ±ÅŸtÄ±")
    print(f"   Input shape: {test_matrix.shape} â†’ Output shape: {result.shape}")
    print(f"   Sample values: {result[:5]}")
    
    # Deterministiklik testi
    result2 = core._quantum_avalanche_mix(test_matrix, test_salt)
    assert np.allclose(result, result2), "Deterministiklik hatasÄ±!"
    print("âœ… Deterministiklik doÄŸrulandÄ±")
    
    # Avalanche etkisi testi
    test_matrix2 = test_matrix.copy()
    test_matrix2[0] += 1e-15
    result3 = core._quantum_avalanche_mix(test_matrix2, test_salt)
    diff_ratio = np.mean(np.abs(result - result3) > 0.1)
    print(f"âœ… Avalanche etkisi: %{diff_ratio*100:.1f} fark (>10% beklenir)")
    
except Exception as e:
    print(f"âŒ Hata: {type(e).__name__}: {e}")
    import traceback
    traceback.print_exc()

# Fonksiyonu MockCore'a ekleyin
MockCore._secure_diffusion_mix = FortifiedKhaCore._secure_diffusion_mix

core = MockCore()
test_matrix = np.random.random(64).astype(np.float64)
test_salt = b"secure_salt_2026_abcdef1234567890"

try:
    result = core._secure_diffusion_mix(test_matrix, test_salt)
    print("âœ… _secure_diffusion_mix hatasÄ±z Ã§alÄ±ÅŸtÄ±")
    print(f"   Input shape: {test_matrix.shape} â†’ Output shape: {result.shape}")
    print(f"   Sample values: {result[:5]}")
    
    # Deterministiklik testi
    result2 = core._secure_diffusion_mix(test_matrix, test_salt)
    assert np.allclose(result, result2), "Deterministiklik hatasÄ±!"
    print("âœ… Deterministiklik doÄŸrulandÄ±")
    
except Exception as e:
    print(f"âŒ Hata: {type(e).__name__}: {e}")
    import traceback
    traceback.print_exc()


def test_parameter_impact():
    print("="*80)
    print("ğŸ§ª PARAMETRE ETKÄ°NLÄ°ÄÄ° TESTÄ°")
    print("="*80)
    
    test_data = b"password123"
    test_data1 = "password123"
    
    # Test 1: Sadece iterations deÄŸiÅŸiyor
    print("\n1ï¸âƒ£  Sadece ITERATIONS deÄŸiÅŸiyor (memory_cost=1MB, time_cost=0):")
    for iters in [1, 2, 3, 5, 10]:
        config = FortifiedConfig(
            iterations=iters,
            components_per_hash=16,
            memory_cost=2**23,  #
            time_cost=0,
        )
        hasher = FortifiedKhaHash256(config)
        
        start = time.perf_counter()
        _ = hasher.hash(test_data)
        elapsed = (time.perf_counter() - start) * 1000
        
        print(f"   iterations={iters:2d} â†’ {elapsed:6.2f} ms {'âš¡' if elapsed < 50 else 'âœ…' if elapsed < 100 else 'ğŸ¢'}")
    
    # Test 2: Sadece memory_cost deÄŸiÅŸiyor
    print("\n2ï¸âƒ£  Sadece MEMORY_COST deÄŸiÅŸiyor (iterations=1, time_cost=0):")
    for mem in [2**16, 2**18, 2**20, 2**22, 2**23, 2**24, 2**26]:
        config = FortifiedConfig(
            iterations=1,
            components_per_hash=16,
            memory_cost=mem,
            time_cost=0,
        )
        hasher = FortifiedKhaHash256(config)
        
        start = time.perf_counter()
        _ = hasher.hash(test_data)
        elapsed = (time.perf_counter() - start) * 1000
        
        mem_mb = mem / (1024*1024)
        print(f"   memory_cost={mem_mb:5.1f} MB â†’ {elapsed:6.2f} ms {'âš¡' if elapsed < 50 else 'âœ…' if elapsed < 100 else 'ğŸ¢'}")
    
    # Test 3: Sadece time_cost deÄŸiÅŸiyor
    print("\n3ï¸âƒ£  Sadece TIME_COST deÄŸiÅŸiyor (iterations=1, memory_cost=1MB):")
    for tc in [0, 50, 100, 200, 500]:
        config = FortifiedConfig(
            iterations=1,
            components_per_hash=16,
            memory_cost=2**23,
            time_cost=tc,
        )
        hasher = FortifiedKhaHash256(config)
        
        start = time.perf_counter()
        _ = hasher.hash(test_data)
        elapsed = (time.perf_counter() - start) * 1000
        
        print(f"   time_cost={tc:3d} ms â†’ {elapsed:6.2f} ms {'âš¡' if elapsed < 50 else 'âœ…' if elapsed < 100 else 'ğŸ¢'}")
    
    # Test 4: hash_password karÅŸÄ±laÅŸtÄ±rmasÄ±
    print("\n4ï¸âƒ£  hash_password() karÅŸÄ±laÅŸtÄ±rmasÄ±:")
    start = time.perf_counter()
    _ = hash_password(test_data1)
    elapsed = (time.perf_counter() - start) * 1000
    print(f"   hash_password() â†’ {elapsed:6.2f} ms")
    
    print("\n" + "="*80)

"""
def quick_hash(data: str | bytes) -> str:

    # Genel amaÃ§lÄ±, hÄ±zlÄ± ve deterministik hash.
    # Kriptografik KDF deÄŸildir.

    data_bytes = data.encode("utf-8") if isinstance(data, str) else data
    hasher = generate_fortified_hasher()
    return hasher.hash(data_bytes, salt=b"")  # sabit salt â†’ deterministik
"""
"""
def quick_hash(data: str | bytes) -> str:
    data_bytes = data.encode("utf-8") if isinstance(data, str) else data
    # Salt, verinin SHA-256'sÄ±ndan tÃ¼retilir â†’ her zaman aynÄ± veri iÃ§in aynÄ± salt
    salt = hashlib.sha256(data_bytes).digest()[:16]
    hasher = generate_fortified_hasher()
    return hasher.hash(data_bytes, salt=salt)
"""
"""
def quick_hash(data: Union[str, bytes]) -> str:

    #Genel amaÃ§lÄ±, hÄ±zlÄ± ve deterministik hash.
    #Kriptografik KDF deÄŸildir.
    #Not: str ve bytes girdileri aynÄ± iÃ§erik iÃ§in aynÄ± hash'i Ã¼retir.

    if isinstance(data, str):
        data = data.encode('utf-8')
    elif not isinstance(data, bytes):
        raise TypeError("Data must be str or bytes")
    
    hasher = generate_fortified_hasher()
    return hasher.hash(data)
"""
"""    
### HÄ±zlÄ± Hash (Genel AmaÃ§)
def quick_hash(data: Union[str, bytes]) -> str:

    #Genel amaÃ§lÄ±, hÄ±zlÄ± ve deterministik hash.
    #Kriptografik KDF deÄŸildir.

    hasher = generate_fortified_hasher()
    return hasher.hash(data)
"""

def benchmark_real_cost():
    """time_cost ve workers'Ä± override test"""
    tests = [
        "fast", "secure", 
        # Manual override
        generate_fortified_hasher_password(iterations=1, time_cost=0),
        generate_fortified_hasher_password(iterations=100, time_cost=0)
    ]
    
    for i, test in enumerate(tests):
        if callable(test):
            hasher = test()
        else:
            hasher = generate_fortified_hasher(test)
        
        start = time.perf_counter()
        hasher.hash(b"test"*1000)  # Uzun input
        elapsed = (time.perf_counter() - start) * 1000
        
        print(f"{test:10} â†’ {elapsed:.1f}ms | workers={hasher.config.max_workers}")

def debug_configs():
    """Config'lerin gerÃ§ekten farklÄ± olduÄŸunu doÄŸrula"""
    for purpose in ["fast", "balanced", "password", "secure"]:
        hasher = generate_fortified_hasher(purpose)
        config = hasher.config
        print(f"{purpose:10} | iter={config.iterations:2} "
              f"c={config.components_per_hash:2} mem={config.memory_cost/1e6:.1f}MB "
              f"time={config.time_cost}")

debug_configs()
"""
def hash_password(password: str, *, is_usb_key: bool = False) -> str:
    hasher = ph_usb if is_usb_key else ph_secure
    return hasher.hash(password)
"""
"""
def hash_password(
    password: str,
    salt: Optional[bytes] = None,
    *,
    is_usb_key: bool = False
) -> str:
    if salt is None:
        salt = secrets.token_bytes(32)  # 32 byte yeterli

    if is_usb_key:
        # Daha hÄ±zlÄ±, dÃ¼ÅŸÃ¼k kaynak
        n, r, p = 2**12, 8, 1   # ~4 MB
    else:
        # GÃ¼venli ama uyumlu
        n, r, p = 2**14, 8, 1   # ~16 MB â€” OpenSSL sÄ±nÄ±rÄ±nÄ±n altÄ±nda

    try:
        digest = hashlib.scrypt(
            password.encode("utf-8"),
            salt=salt,
            n=n,
            r=r,
            p=p,
            dklen=32
        ).hex()
    except ValueError as e:
        if "memory limit exceeded" in str(e):
            raise RuntimeError(
                f"scrypt bellek hatasÄ±. Parametreler: n={n}, r={r}, p={p}. "
                "Sisteminiz OpenSSL scrypt sÄ±nÄ±rÄ±na takÄ±ldÄ±. n deÄŸerini dÃ¼ÅŸÃ¼rÃ¼n."
            ) from e
        raise

    prefix = "SCRYPT-USB$" if is_usb_key else "SCRYPT$"
    return f"{prefix}{salt.hex()}${digest}"
"""
"""
def hash_password(
    password: str,
    salt: Optional[bytes] = None,
    *,
    is_usb_key: bool = False
) -> str:

    Parola/anahtar iÃ§in gÃ¼venli, non-deterministik KDF tabanlÄ± hash Ã¼retir.
    Args:
        password: Hashlenecek parola (str).
        salt: Ä°steÄŸe baÄŸlÄ± tuz. Belirtilmezse 256 byte rastgele tuz Ã¼retilir.
        is_usb_key: True ise daha hÄ±zlÄ± (daha az kaynak tÃ¼keten) konfigÃ¼rasyon kullanÄ±lÄ±r.
    Returns:
        str: Format -> "KHA256[-USB]$<salt_hex>$<digest>"

    # Tuz oluÅŸtur
    if salt is None:
        salt = secrets.token_bytes(256)  # 256 byte = 2048 bit â†’ Ã§ok gÃ¼Ã§lÃ¼

    # KonfigÃ¼rasyon seÃ§
    if is_usb_key:
        config = FortifiedConfig(
            iterations=16,
            components_per_hash=32,
            memory_cost=2**18,  # 256 KB
            time_cost=8
        )
    else:
        config = FortifiedConfig(
            iterations=32,
            components_per_hash=48,
            memory_cost=2**20,  # 1 MB
            time_cost=16
        )

    # Hashle
    hasher = FortifiedKhaHash256(config)
    digest = hasher.hash(password, salt)

    # Formatla
    prefix = "KHA256-USB$" if is_usb_key else "KHA256$"
    return f"{prefix}{salt.hex()}${digest}"
"""
"""
def hash_password(password: str, salt: Optional[bytes] = None, 
                  is_usb_key: bool = False) -> str:

    Parola hashleme iÃ§in birleÅŸtirilmiÅŸ fonksiyon.
    Args:
        password: Hashlenecek parola
        salt: Ã–zel tuz (None ise otomatik Ã¼retilir)
        is_usb_key: USB anahtarÄ± iÃ§in optimize edilmiÅŸ mod

    
    if is_usb_key:
        # USB anahtarlarÄ± iÃ§in optimize edilmiÅŸ (daha hÄ±zlÄ±)
        config = FortifiedConfig()
        config.iterations = 16
        config.components_per_hash = 32
        config.memory_cost = 2**18  # 256KB
        config.time_cost = 8
        hasher = FortifiedKhaHash256(config)
    else:
        # Parolalar iÃ§in gÃ¼venlik maksimum
        hasher = generate_fortified_hasher(
            iterations=32,
            components=48,
            memory_cost=2**20,  # 1 MB
            time_cost=16,
        )
    
    if salt is None:
        salt = secrets.token_bytes(256)
    
    digest = hasher.hash(password, salt)
    
    # TÃ¼r belirteci ekleyerek kullanÄ±m amacÄ±nÄ± iÅŸaretle
    prefix = "KHA256-USB$" if is_usb_key else "KHA256$"
    return f"{prefix}{salt.hex()}${digest}"
"""
"""
def hash_password(password: str, salt: Optional[bytes] = None) -> str:

    #Parola hashleme (KDF modu).
    #YavaÅŸ, bellek-yoÄŸun ve brute-force direnÃ§lidir.

    hasher = generate_fortified_hasher(
        iterations=32,
        components=48,
        memory_cost=2**20,  # 1 MB
        time_cost=16,
    )

    if salt is None:
        salt = secrets.token_bytes(256)

    digest = hasher.hash(password, salt)

    return f"KHA256${salt.hex()}${digest}"

def hash_password(password: str, salt: Optional[bytes] = None) -> str:
    #Åifre hash'leme (gÃ¼venlik maksimum)
    hasher = generate_fortified_hasher()

    # Åifreler iÃ§in Ã¶zel config
    config = FortifiedConfig()
    config.iterations = 32  # Daha fazla iterasyon
    config.components_per_hash = 48  # Daha fazla bileÅŸen
    config.memory_cost = 2**20  # 1MB
    config.time_cost = 16

    secure_hasher = FortifiedKhaHash256(config)

    if salt is None:
        salt = secrets.token_bytes(256)  # Uzun tuz

    return f"KHA256${salt.hex()}${secure_hasher.hash(password, salt)}"
"""


### Universal DoÄŸrulama Fonksiyonu: Parola DoÄŸrulama
def verify_password(stored_hash: str, password: str) -> bool:
    """
    Her iki tÃ¼r hash'i de doÄŸrulayabilen universal fonksiyon
    """
    try:
        # Hash formatÄ±nÄ± parse et
        parts = stored_hash.split("$")
        if len(parts) != 3:
            return False

        prefix, salt_hex, original_digest = parts
        salt = bytes.fromhex(salt_hex)

        # Prefix'e gÃ¶re doÄŸru hasher'Ä± seÃ§
        if prefix == "KHA256-USB":
            # USB anahtarÄ± iÃ§in config
            config = FortifiedConfig()
            config.iterations = 16
            config.components_per_hash = 32
            config.memory_cost = 2**23
            config.time_cost = 8
            hasher = FortifiedKhaHash256(config)
        elif prefix == "KHA256":
            # Normal parola iÃ§in config
            hasher = generate_fortified_hasher(
                iterations=32,
                components=48,
                memory_cost=2**23,
                time_cost=16,
            )
        else:
            return False

        # DoÄŸrulama
        new_digest = hasher.hash(password, salt)
        return secrets.compare_digest(new_digest, original_digest)

    except Exception:
        return False


"""
def verify_password(password: str, stored_hash: str) -> bool:
    #KHA256$<salt>$<hash> formatÄ±nÄ± doÄŸrular.

    try:
        _, salt_hex, expected = stored_hash.split("$")
        salt = bytes.fromhex(salt_hex)
    except ValueError:
        raise ValueError("GeÃ§ersiz KHA256 hash formatÄ±")

    candidate = hash_password(password, salt)
    return secrets.compare_digest(candidate, stored_hash)
"""


def get_hasher_config(purpose: str = "password") -> FortifiedConfig:
    config = FortifiedConfig()

    if purpose == "password":
        config.iterations = 32
        config.components_per_hash = 48
        config.memory_cost = 2**26
        config.time_cost = 16
    elif purpose == "usb_key":
        config.iterations = 16
        config.components_per_hash = 32
        config.memory_cost = 2**24
        config.time_cost = 8
    elif purpose == "session_token":
        config.iterations = 8
        config.components_per_hash = 24
        config.memory_cost = 2**23
        config.time_cost = 4

    return config


"""
def generate_fortified_hasher() -> FortifiedKhaHash256:
    #GÃ¼Ã§lendirilmiÅŸ hasher oluÅŸtur
    config = FortifiedConfig()
    return FortifiedKhaHash256(config)

def quick_hash(data: Union[str, bytes]) -> str:
    #HÄ±zlÄ± hash oluÅŸturma
    hasher = generate_fortified_hasher()
    return hasher.hash(data)
"""
def generate_hwid(components: Union[Dict[str, str], str, bytes]) -> str:
    """
    Deterministik HWID Ã¼retimi â€” kriptografik olarak gÃ¼venli.
    Ubuntu 25.10'de Intel SHA Extensions ile ~0.3 Âµs/op.
    
    Args:
        components: DonanÄ±m bileÅŸenleri dict'i veya raw string/bytes
        
    Returns:
        64 karakterlik SHA-256 hex string (256-bit)
    """
    # 1. Input'u deterministik string'e Ã§evir
    if isinstance(components, dict):
        # Dict sÄ±ralamasÄ± kritik â€” sorted() ile sabit order
        data = "|".join(f"{k}:{v}" for k, v in sorted(components.items()))
    elif isinstance(components, str):
        data = components
    elif isinstance(components, bytes):
        data = components.decode("utf-8", errors="ignore")
    else:
        raise TypeError(f"Beklenmeyen input tipi: {type(components)}")
    
    # 2. SHA-256 ile hash'le (donanÄ±msal hÄ±zlandÄ±rma aktif)
    return hashlib.sha256(data.encode("utf-8")).hexdigest()


def generate_compact_hwid(components: Dict[str, str]) -> bytes:
    """
    Compact HWID (32 byte raw) â€” storage optimizasyonu iÃ§in.
    Hex string yerine %50 daha az yer kaplar.
    """
    data = "|".join(f"{k}:{v}" for k, v in sorted(components.items()))
    return hashlib.sha256(data.encode("utf-8")).digest()  # 32 byte raw

# Ekstra gÃ¼venlik iÃ§in salt eklemek:
def generate_secure_hwid(components: Dict[str, str], salt: str = "my_app_salt_v1") -> str:
    """HWID + sabit salt â†’ tersine mÃ¼hendislik korumasÄ±"""
    data = salt + "|" + "|".join(f"{k}:{v}" for k, v in sorted(components.items()))
    return hashlib.sha256(data.encode("utf-8")).hexdigest()


def hwid_hash(data: Union[str, bytes]) -> str:
    """
    HWID Ã¼retimi iÃ§in optimize edilmiÅŸ hash.
    Ubuntu 25.10'de Intel SHA Extensions ile ~280 ns/op.
    """
    if isinstance(data, str):
        data = data.encode("utf-8")
    return hashlib.sha256(data).hexdigest()


@lru_cache(maxsize=4096)
def hwid_hash_cached(data: str) -> str:
    """
    Tekrarlayan HWID'ler iÃ§in cache'li versiyon.
    Cache hit sonrasÄ± ~30 ns/op (11x hÄ±zlanma).
    âš ï¸  Sadece STR kullanÄ±n â€” bytes cache anahtarÄ± farklÄ± oluÅŸturur!
    """
    return hashlib.sha256(data.encode("utf-8")).hexdigest()

class HardwareSecurityID:
    """
    Args:
        use_mac: MAC adresini dahil et (varsayÄ±lan: False â†’ GDPR uyumlu)
        salt: Tersine mÃ¼hendislik korumasÄ± iÃ§in sabit salt (isteÄŸe baÄŸlÄ±)
    """
    def __init__(self, use_mac: bool = False, salt: Optional[str] = None):
        self.use_mac = use_mac
        self.salt = salt
        self.fingerprint = self._collect_data()
        # âœ… Tek hasher instance'Ä± â€” cache kalÄ±cÄ± olur
        self.hasher = FortifiedKhaHash256(
            deterministic = True,
            config=type('Config', (), {'cache_enabled': True, 'salt_length': 32})()
        )
    
    def _collect_data(self) -> Dict[str, str]:
        """DonanÄ±m parmak izi toplama (GDPR uyumlu)"""
        data = {
            'system': platform.system(),
            'node': platform.node(),
            'machine': platform.machine(),
            'release': platform.release(),
            'user': os.getenv('USER', os.getenv('USERNAME', 'unknown')),
        }
        
        # âš ï¸ MAC adresi GDPR riski taÅŸÄ±r - sadece aÃ§Ä±kÃ§a istenirse ekle
        if self.use_mac:
            try:
                mac_int = uuid.getnode()
                # GerÃ§ek MAC kontrolÃ¼ (unicast bit)
                if 0 < mac_int < (1 << 48) and (mac_int >> 40) % 2 == 0:
                    data['mac'] = f"{mac_int:012x}"[-12:]
                else:
                    data['mac'] = "simulated_mac"
            except Exception:
                data['mac'] = "unavailable"
        
        return data
    
    def get_hardware_id(self) -> str:
        """KHA256 ile deterministik HWID Ã¼retimi + cache koruma"""
        components = [
            self.fingerprint['system'],
            self.fingerprint['node'],
            self.fingerprint['machine'],
            self.fingerprint['release'],
        ]
        
        if self.use_mac and 'mac' in self.fingerprint:
            components.append(self.fingerprint['mac'])
        
        raw = '|'.join(components)
        if self.salt:
            raw = f"{self.salt}|{raw}"
        
        # âœ… ArtÄ±k cache Ã§alÄ±ÅŸan tek hasher kullanÄ±lÄ±yor
        return self.hasher.hash(raw.encode('utf-8'))

# ğŸš€ HWID HESAPLA
# âœ… GDPR UYUMLU: MAC adresi KAPALI (use_mac=False)
hw = HardwareSecurityID(use_mac=False, salt="myapp_v1_2026")
hwid = hw.get_hardware_id()
license_key = f"KHA256_DEFAULT_{hwid}"


class HardwareSecurityID2:
    def __init__(self):
        self.fingerprint = {
            "system": platform.system(),
            "node": platform.node(),
            "processor": platform.processor() or "unknown",
            "uuid": str(uuid.getnode())[-12:],
        }

    def get_hardware_id(self) -> str:
        raw = "|".join(self.fingerprint.values())
        hasher = FortifiedKhaHash256(deterministic = True)
        return hasher.hash(raw.encode("utf-8"))

        # DETERMÄ°NÄ°STÄ°K MOD ZORUNLU
        hasher = FortifiedKhaHash256(deterministic = True)
        hwid = hasher.hash(raw.encode("utf-8"))
        if len(hwid) != 64:
            raise RuntimeError("HWID geÃ§ersiz uzunlukta!")
        return hwid

class SecureKhaHash256:
    def __init__(self):
        pass
    
    def hash(self, data: bytes, salt: bytes) -> bytes:
        # Tek satÄ±r, %100 gÃ¼venli:
        return hashlib.blake2b(data + salt, digest_size=32)
    
    # Test iÃ§in:
    def verify_avalanche(self, n=10000):
        # BLAKE2 zaten NIST onaylÄ±, test etmeye gerek yok
        return {"status": "CRYPTographically SECURE"}


def run_comprehensive_test():
    """KapsamlÄ± gÃ¼venlik testi"""
    print("=" * 80)
    print("KHA - KAPSAMLI GÃœVENLÄ°K TESTÄ°")
    print("=" * 80)

    # Hasher oluÅŸtur
    hasher = generate_fortified_hasher()

    # GÃ¼venlik raporu
    security_report = hasher.get_security_report()
    print("\nGÃœVENLÄ°K RAPORU:")
    print("-" * 40)
    print(f"  Algoritma: {security_report['algorithm']}")
    print(f"  Versiyon: {security_report['version']}")
    print(f"  GÃ¼venlik Seviyesi: {security_report['security_level']}")
    print(f"  Kuantum Direnci: {security_report['features']['quantum_resistance']}")
    print(f"  Bellek SertleÅŸtirme: {security_report['features']['memory_hardening']}")
    print(
        f"  Yan Kanal Koruma: {security_report['features']['side_channel_resistance']}"
    )

    print("\n1. TEMEL FONKSÄ°YON TESTÄ°")
    print("-" * 40)

    test_cases = [
        ("", "BoÅŸ string"),
        ("a", "Tek karakter"),
        ("Merhaba DÃ¼nya!", "Basit metin"),
        ("K" * 1000, "Uzun tekrar"),
        (secrets.token_bytes(128), "Rastgele veri (128 byte)"),
        ("Ä°Ã§erik: Ã¶zel karakterler: Ã¡Ã©Ã­Ã³Ãº Ã± Ã§ ÅŸ ÄŸ Ã¼ Ã¶", "Unicode metin"),
    ]

    for data, desc in test_cases:
        if isinstance(data, bytes):
            preview = data[:24].hex() + "..."
        else:
            preview = data[:24] + "..." if len(data) > 24 else data

        start = time.perf_counter()
        h = hasher.hash(data)
        elapsed = (time.perf_counter() - start) * 1000

        print(f"  {desc:<30} '{preview}'")
        print(f"    â†’ {h[:56]}... ({elapsed:.2f}ms)")

    print("\n2. AVALANCHE TESTÄ° (100 Ã¶rnek)")
    print("-" * 40)

    avalanche_result = hasher.test_avalanche_effect(100)
    print(f"  Ortalama bit deÄŸiÅŸimi: {avalanche_result['avg_bit_change_percent']:.3f}%")
    print(f"  Standart sapma: {avalanche_result['std_deviation']:.3f}")
    print(f"  Hamming mesafesi: {avalanche_result['avg_hamming_distance']:.1f}")
    print(f"  Ä°deal aralÄ±kta: {avalanche_result['in_ideal_range']}")
    print(f"  Durum: {avalanche_result['status']}")

    print("\n3. Ã‡AKIÅMA TESTÄ° (10000 Ã¶rnek)")
    print("-" * 40)

    collision_result = hasher.test_collision_resistance(100)  # 10000
    print(f"  Ã‡akÄ±ÅŸma sayÄ±sÄ±: {collision_result['collisions']}")
    print(f"  Ã‡akÄ±ÅŸma oranÄ±: {collision_result['collision_rate_percent']:.8f}%")
    print(f"  YakÄ±n Ã§akÄ±ÅŸma: {collision_result['near_collisions']}")
    print(f"  Durum: {collision_result['status']}")

    print("\n4. UNIFORMLUK TESTÄ° (10000 Ã¶rnek)")
    print("-" * 40)

    uniformity_result = hasher.test_uniformity(100)  # 10000
    print(f"  Chi-square (bit): {uniformity_result['chi_square_bit']:.1f}")
    print(f"  Chi-square (byte): {uniformity_result['chi_square_byte']:.1f}")
    print(f"  Ortalama run uzunluÄŸu: {uniformity_result['avg_run_length']:.3f}")
    print(f"  Bit uniform mu: {uniformity_result['is_uniform_bit']}")
    print(f"  Byte uniform mu: {uniformity_result['is_uniform_byte']}")
    print(f"  Durum: {uniformity_result['status']}")

    print("\nPERFORMANS Ã–ZETÄ°")
    print("-" * 40)

    stats = hasher.get_stats()
    print(f"  Toplam hash: {stats['hash_count']}")
    print(f"  Ortalama sÃ¼re: {stats.get('avg_time_ms', 0):.2f}ms")
    print(f"  Toplam operasyon: {stats.get('total_operations', 0)}")
    print(f"  KHA baÅŸarÄ± oranÄ±: {stats.get('kha_success_rate', 0):.1f}%")
    print(f"  GÃ¼venlik kontrolleri: {stats.get('security_checks', 0)}")

    print("\n" + "=" * 80)
    print("SONUÃ‡: KHA-256 FORTIFIED")
    print("=" * 80)

    # Final evaluation
    avalanche_ok = avalanche_result["status"] in ["EXCELLENT", "GOOD"]
    collision_ok = collision_result["status"] in ["EXCELLENT", "GOOD"]
    uniformity_ok = uniformity_result["status"] in ["EXCELLENT", "GOOD"]

    if avalanche_ok and collision_ok and uniformity_ok:
        print("âœ“ TÃœM TESTLER BAÅARILI! - ÃœRETÄ°ME HAZIR!")
        print("âœ“ YÃ¼ksek gÃ¼venlik seviyesi saÄŸlandÄ±")
        print("âœ“ Kuantum ve yan kanal saldÄ±rÄ±larÄ±na karÅŸÄ± korumalÄ±")
    elif avalanche_ok and collision_ok:
        print("âœ“ Ä°YÄ° - Ã‡akÄ±ÅŸma ve avalanche testleri baÅŸarÄ±lÄ±")
    else:
        print("âš  Ä°YÄ°LEÅTÄ°RME GEREKLÄ° - BazÄ± testler baÅŸarÄ±sÄ±z")

    return hasher


# ============================================================
# Ã–RNEK KULLANIM
# ============================================================
if __name__ == "__main__":
    print("ğŸ”’ KEÃ‡ECÄ° HASH ALGORÄ°TMASI (KHA-256) - FORTIFIED VERSION")
    print("   Salt zorunlu â€¢ USB varsayÄ±lan â€¢ 2026 gÃ¼venli\n")

    # Sabit test salt'Ä±
    fixed_salt = b"KHA_DEMO_SALT_32BYTES!!"

    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        hasher = run_comprehensive_test()
    else:
        print("âš¡ HIZLI DEMO:\n")
        
        # 1. Basit hasher
        hasher = SimpleKhaHasher()
        
        # Ã–rnek 1: Basit metin
        text = "Merhaba dÃ¼nya! KHA test"
        hash_result = hasher.hash(text, fixed_salt)
        print(f"ğŸ“„ '{text}'")
        print(f"ğŸ”‘ â†’ {hash_result}\n")

        # Ã–rnek 2: Åifre (SALT ZORUNLU!)
        password = "Ã‡okGizliÅifre123!@#"
        password_hash = hash_password_str(password, fixed_salt)
        print(f"ğŸ” '{password}'")
        print(f"ğŸ”‘ â†’ {password_hash[:64]}...\n")

        # Ã–rnek 3: Avalanche (aynÄ± salt!)
        print("ğŸ”¥ AVALANCHE TEST:")
        data1, data2 = "Test123", "Test124"
        h1 = hasher.hash(data1, fixed_salt)
        h2 = hasher.hash(data2, fixed_salt)
        
        h1_bin = bin(int(h1.split('$')[-1], 16))[2:].zfill(256)
        h2_bin = bin(int(h2.split('$')[-1], 16))[2:].zfill(256)
        diff = sum(a != b for a, b in zip(h1_bin, h2_bin))
        
        print(f"  '{data1}' â†’ {h1[:32]}...")
        print(f"  '{data2}' â†’ {h2[:32]}...")
        print(f"  Bit farkÄ±: {diff}/256 (%{diff/2.56:.1f}) âœ…\n")

        # Ã–rnek 4: Performans testi
        print("â±ï¸  PERFORMANS TESTÄ°:")
        test_data = "Performans testi" * 100
        start = time.time()
        result = hasher.hash(test_data, fixed_salt)
        duration = (time.time() - start) * 1000
        
        print(f"  2000+ char â†’ {duration:.1f}ms âœ…")

        # GÃ¼venlik raporu
        print("\nğŸ›¡ï¸  GÃœVENLÄ°K RAPORU:")
        report = hasher.get_security_report()
        print(f"  Versiyon: {report['version']}")
        for key, value in report["features"].items():
            status = "âœ“" if value else "âœ—"
            print(f"  {key.replace('_', ' ').title()}: {status}")
        
        print(f"\nğŸš€ KullanÄ±m: python kha.py --test")
